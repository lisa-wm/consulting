{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09FrEZkpUv0F"
   },
   "source": [
    "# BERT Fine-Tuning (pure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WrhLjZdVN49"
   },
   "source": [
    "*By Asmik Nalmpatian and Lisa Wimmer*\n",
    "\n",
    "*Last edited on 30.12.20* \n",
    "\n",
    "*For our consulting project: Aspect-Based Sentiment Analysis for Twitter Data of German MPs*\n",
    "\n",
    "*Methodology based on: https://arxiv.org/pdf/1810.04805.pdf*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxj_Yq-iWJxb"
   },
   "source": [
    "This notebook is supposed to give an overview over the used functionalities. We will show how to use BERT - Bidirectional Encoder Representations from Transformers - with PyTorch library (huggingface) to fine-tune a pretrained model in tweet classification. \n",
    "\n",
    "The following pretrained BERT models can be used and are available in transformers huggingface: \n",
    "\n",
    "*   *bert-base-german-cased (trained by Deepset.ai)*\n",
    "*   *bert-base-german-dbmdz-cased (trained by by DBMDZ)*\n",
    "*   *bert-base-german-dbmdz-uncased (trained by by DBMDZ)*\n",
    "*   *distilbert-base-german-cased (distilled from DBMDZ)*\n",
    "\n",
    "After using these models to extract (hopefully) high quality features from our text data, we aim to fine-tune them on our specific task using a manually labeled sample of German tweets to gain state of the art predictions.\n",
    "\n",
    "All in all the tweets will be classified into *positive* and *negative* classes using a pretrained BERT model. We will take it, add an untrained layer of neurons on the end and train a new model specifically for classification task. \n",
    "Advantages of Fine-Tuning:  \n",
    "\n",
    "\n",
    "*   Quick because we have already hardly pretrained layers of the network (only 2-4 epochs after adding 1 fully-connected layer on top are enough to train as the authors recommend)\n",
    "*   Less data is sometimes enough to achieve good performance\n",
    "*   Usually preferable results: Because of task-specific adjustments of the weights\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26YQ5UYt1aGw"
   },
   "source": [
    "# Google Colab GPU Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EY5QDtKc4pCe"
   },
   "source": [
    "Otherwise training a large NN may take a very long time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpojrKi87B0j",
    "outputId": "419999ed-1e35-4ed5-cede-f3d71b0bdc2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RLk647UpAUMZ",
    "outputId": "20795ce1-3f02-42ae-f865-fb68b98b4bfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# Identify and specify the GPU as the device\n",
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "-fpUHgyTOUuW",
    "outputId": "1e925a52-7aaf-4967-eeed-715e4a2bb11a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where to save our data\n",
    "import os, sys\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLhki6Q67HB5"
   },
   "source": [
    "# Fine-Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV4Ao1h59Tbj"
   },
   "source": [
    "Install Huggingface Library / transformers package and specify the pretrained transformer model. (Uncased means that the texts have only lowercase letters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630,
     "referenced_widgets": [
      "20cc76b906a74b7b9009795317298e47",
      "265b0a54d14e4000bddadc355786308b",
      "61d05a1121e24fe2ab9b40d8eed443e4",
      "692b204587f7462591b54a55c748005d",
      "41cc6a9d48d34fa8810ab4751d96bf1f",
      "b934c6bf9e4c4f9b98d2b1c852ba0d32",
      "6bd71b2e568840dbafca4f33947c1d01",
      "1e824877cec34845a345695ffda58051"
     ]
    },
    "id": "5ynJrSjrQLQu",
    "outputId": "606a4bc7-a9d3-4e57-8e33-94c9155eedb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
      "\r",
      "\u001b[K     |▏                               | 10kB 24.3MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 20kB 13.6MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 30kB 12.1MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 40kB 11.3MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 51kB 7.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 61kB 7.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 71kB 8.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 81kB 8.9MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 92kB 9.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 102kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 112kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 122kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 133kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 143kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 153kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 163kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 174kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 184kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 194kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 204kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 215kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 225kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 235kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 245kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 256kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 266kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 276kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 286kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 296kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 307kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 317kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 327kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 337kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 348kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 358kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 368kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 378kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 389kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 399kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 409kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 419kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 430kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 440kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 450kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 460kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 471kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 481kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 491kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 501kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 512kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 522kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 532kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 542kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 552kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 563kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 573kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 583kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 593kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 604kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 614kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 624kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 634kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 645kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 655kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 665kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 675kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 686kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 696kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 706kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 716kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 727kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 737kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 747kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 757kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 768kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 778kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 788kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 798kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 808kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 819kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 829kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 839kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 849kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 860kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 870kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 880kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 890kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 901kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 911kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 921kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 931kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 942kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 952kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 962kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 972kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 983kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 993kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 1.0MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 1.0MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 1.0MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 1.0MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.0MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 1.1MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.2MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 1.3MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.4MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.5MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.5MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.5MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.5MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.5MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.5MB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.5MB 7.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
      "Collecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 20.0MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 53.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=70aa5198144ea1ca0ba110c9c86db4dc787d4c5e0c06ca627cdd5bdfd6a92f24\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cc76b906a74b7b9009795317298e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=254728.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "pretrained_model = \"bert-base-german-cased\"\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKXUHB8CIoNV"
   },
   "source": [
    "Load and prepare the tweets and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ejwgMfT7D-x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"data-tweepy-df-subset-labeled-manually.csv\" , delimiter=';',error_bad_lines=False)\n",
    "\n",
    "df['label_binary'] = [1 if label == 'positive' else 0 for label in df.label]\n",
    "df.head()\n",
    "\n",
    "# Get the lists of tweets and their labels.\n",
    "tweets = df.full_text.values\n",
    "labels = df.label_binary.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utKWWD02IyBh"
   },
   "source": [
    "First, we need to tokenize our text to be able to feet it into the BERT model. \n",
    "\n",
    "Below an example of tokenized and raw tweet versions is shown. To tokenize the text we have to specify and use the pre-trained BERT because each model has a fixed vocabulary (containing tokens, so wordpieces) and the BERT tokenizer handles words which are not in the certain vocabulary in a specific way.\n",
    "\n",
    "Each token is then mapped to their index in the tokenizer vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iZL1eSQeVs6-",
    "outputId": "bb46580f-82d0-4ec7-e949-abe821bf0f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  @UweNess @jensspahn Ich halte diese These fuer puren Ableismus.\n",
      "Tokenized:  ['@', 'Uwe', '##Ne', '##ss', '@', 'jen', '##ss', '##pa', '##hn', 'Ich', 'halte', 'diese', 'These', 'f', '##uer', 'pur', '##en', 'Ab', '##lei', '##sm', '##us', '.']\n",
      "Token IDs:  [26991, 14588, 6547, 430, 26991, 3583, 430, 5028, 206, 1671, 15443, 620, 16649, 69, 667, 25143, 7, 226, 445, 6694, 51, 26914]\n"
     ]
    }
   ],
   "source": [
    "# Print the raw tweet.\n",
    "print('Raw: ', tweets[0])\n",
    "\n",
    "# Print the tweet split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(tweets[0]))\n",
    "\n",
    "# Print the tweet mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZJe8-JoKAaL"
   },
   "source": [
    "In the next step we add special tokens to the start *CLS* and end of each tweet *SEP*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "AKR6G5w4dFsy",
    "outputId": "7b0cedfc-0f86-4978-f13e-ab2614bfc73e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-508b279c91d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# For every sentence...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m# `encode` will:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#   (1) Tokenize the sentence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the tweets and map the tokens to their word IDs.\n",
    "input_ids = []\n",
    "\n",
    "# For every tweet...\n",
    "for tweet in tweets:\n",
    "    encoded_tweet = tokenizer.encode(\n",
    "                        tweet,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded tweet to the list.\n",
    "    input_ids.append(encoded_tweet)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', tweets[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gk4o_F6XKIUF"
   },
   "source": [
    "Then we pad and truncate all tweets to a constant fixed length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_tBkChIdyOC",
    "outputId": "df70af98-61a0-4b9a-e287-8f01edaa6b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  91\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(tweet) for tweet in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTtngalseGJs",
    "outputId": "946cf5b5-16c4-4e02-f0b1-81cf0ec6f5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 110 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Set the maximum sequence length.\n",
    "# A bit larger than the maximum training tweet length of 91...\n",
    "MAX_LEN = 110\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# Pad our input tokens with value 0.\n",
    "# \"post\" - pad and truncate at the end of the sequence, as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vstmJJnvOEJ6"
   },
   "source": [
    "Create attention masks which indicates which tokens are words and which are padding (if token ID is 0 then it is padding and the attention mask is set to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RoRYw4_jg4QP"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# For each sentence...\n",
    "for tweet in input_ids:\n",
    "    \n",
    "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
    "    \n",
    "    # Store the attention mask for each tweet.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Vp0fFEsOifw"
   },
   "source": [
    "Now, we use train_test_split to split our data into train, test sets first  and then split the initial train set further into a final train set and validation set for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KHDnNsImhFKd"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 80% for training and 20% for validation.\n",
    "train_inputs1, test_inputs, train_labels1, test_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2020, test_size=0.2)\n",
    "\n",
    "# Do the same for the masks.\n",
    "train_masks1, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2020, test_size=0.2)\n",
    "\n",
    "# Use 20% of train set as validation set \n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs1, train_labels1, \n",
    "                                                                                    test_size=0.2, random_state=2020) \n",
    "\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(train_masks1, train_labels1,\n",
    "                                             random_state=2020, test_size=0.2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTaFTXqFO080"
   },
   "source": [
    "Convert all inputs and labels into torch tensors, the required datatype \n",
    "for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pg71HZ7qifpo"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8bEkw8kO9Zr"
   },
   "source": [
    "The torch DataLoader class enables to create  an iterator for our data in order to save memory during training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oBRWzCgriurl"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Define batch size here to let DataLoader know. \n",
    "# BERT-authors recommend a batch size of 16 or 32 for fine-tuning .\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our test set.\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIEy4SR4R6ch"
   },
   "source": [
    "Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "linear classification layer on top. This is the one for classification tasks in general. *(see for more details https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2fa807a646134ebeb81bb2268b773b4d",
      "8b0354909cd648dcbd800173cf4b06ce",
      "98eecd35db414fcc9a4011f398d2a6d8",
      "84507b06425544e19870a833cc4702b3",
      "abc6d5aac8ed4405bcc61921b2a4995d",
      "75700fbb780b43c9ba8f8c97240d303e",
      "67fbbb4ec13d4f6d8f570cb0c08eecd2",
      "b0dc34e0da784b4cbae71dc30b929c0f",
      "671f3812c4cc4ec59c0465c7c925fbc4",
      "db6346eac37a48f4866933d908662d06",
      "275830e1d7bd41a9bf9edd3036c07d28",
      "56ed65affd6642fcba0f61d58430d52a",
      "aea75ef5f95c4c3a82714cb51c984d4f",
      "d196c69bd1c144c69521fdccbd09dc4c",
      "7ba1ff48824d4f97a7796c2739cd727f",
      "30f689c0a0fb4dea8fe0949bd56eb21f"
     ]
    },
    "id": "_xILaX9ulICZ",
    "outputId": "b1056f08-c3de-4abc-cd03-16524af59b94"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa807a646134ebeb81bb2268b773b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671f3812c4cc4ec59c0465c7c925fbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438869143.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model, \n",
    "    num_labels = 2, # The number of output labels--2 for binary classification. Can be increased for multiclass\n",
    "    output_attentions = False, \n",
    "    output_hidden_states = False, \n",
    ")\n",
    "\n",
    "# Run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wddbSBdwl6MM",
    "outputId": "30583333-b846-4a3a-d721-926939f04999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30000, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# All of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOogCCNSS1_z"
   },
   "source": [
    "Get the optimizer after loading the model to train the hyperparameters. \n",
    "\n",
    "We chose following values based on authors' recommendations:\n",
    "\n",
    "Batch size: 32 \n",
    "Learning rate (Adam): 2e-5\n",
    "Number of epochs: 4\n",
    "\n",
    "*(see for more details on AdamW Optimizer https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "N5YMJeG7m1GW"
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TypGI2W5m5X9"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5fgx-tuPnc8Z"
   },
   "outputs": [],
   "source": [
    "# helper function for calculating accuracy\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fcSWb-YhpNo4"
   },
   "outputs": [],
   "source": [
    "# helper function for formatting elapsed times\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dgc1fHkwTxaf"
   },
   "source": [
    "Let's start the actual training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acrG210Npcb4",
    "outputId": "d263cc20-0923-44da-f987-4155218de8a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.79\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.55\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.47\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epcoh took: 0:00:03\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.84\n",
      "  Validation took: 0:00:00\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "seed_val = 55\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch:\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    ## TRAIN\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # how long does the training epoch take.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Turn on the training mode for the model. \n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data:\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack the batch and load onto the GPU.\n",
    "        # Each batch contains input ids, attention masks, labels. \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Remove any previously calculated gradients before performing a\n",
    "        # backward pass. \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Do a forward pass. \n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        \n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Do a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0. \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step.\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Avg loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Need for plotting the learning curve later.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Avg training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Epoch time: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    ## VALIDATE\n",
    "    # After each training epoch, we measure performance on\n",
    "    # validation set.\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Turn on the evaluation mode of the model.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get logit values predicted for each class.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Accuracy for this batch of validation tweets.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation time: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "yKJGT2uxqsNu",
    "outputId": "81bedbea-2221-477e-ffab-ca25c07007c2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1SUZ9oG8GsGZui91wGkSu+g2EURsIux1xiz6cmaT90Uy5YklsSsu9msiV0MVmxgidgSQxFRUcGOFEHFhgKRInx/GGZDQAEF3hm4fufknMxb7/E5wMXLM/cjqq2trQURERERESkFsdAFEBERERFR8zHAExEREREpEQZ4IiIiIiIlwgBPRERERKREGOCJiIiIiJQIAzwRERERkRJhgCci6mQKCgrg4uKC5cuXv/A15syZAxcXl1as6sW4uLhgzpw5QpdBRNSuVIUugIios2tJEE5KSoK1tXUbVkNERIpOxIWciIiEtXPnznqvT548iU2bNuGVV16Bv79/vX3h4eHQ1NR8qfvV1taisrISKioqUFV9sec4VVVVqKmpgZqa2kvV8rJcXFwwfPhwfP7554LWQUTUnvgEnohIYEOHDq33+smTJ9i0aRN8fHwa7Puj0tJSaGtrt+h+IpHopYO3RCJ5qfOJiOjFcQ48EZGS6Nu3LyZOnIisrCxMnz4d/v7+GDJkCICnQf6rr75CTEwMgoOD4eHhgfDwcCxZsgS//vprves0Ngf+99sOHz6MkSNHwtPTE2FhYfjiiy9QXV1d7xqNzYGv2/bo0SPMmzcPoaGh8PT0xJgxY3DmzJkG7+f+/fuYO3cugoOD4evri0mTJiErKwsTJ05E3759X+rfasuWLRg+fDi8vLzg7++PadOmIT09vcFxR44cwYQJExAcHAwvLy/07t0bb731FnJycuTHFBUVYe7cuejTpw88PDwQGhqKMWPGID4+/qVqJCJ6UXwCT0SkRAoLCzF58mRERERgwIABKC8vBwDcunULW7duxYABAxAdHQ1VVVWkpaXh+++/R3Z2NlauXNms6x89ehQbN27EmDFjMHLkSCQlJWHVqlXQ09PD66+/3qxrTJ8+HYaGhnjzzTfx4MEDrF69Gq+99hqSkpLkfy2orKzE1KlTkZ2djREjRsDT0xMXL17E1KlToaen92L/OL9ZvHgxvv/+e3h5eeGDDz5AaWkpNm/ejMmTJ+Obb75Br169AABpaWn405/+BCcnJ8ycORM6Ojq4ffs2kpOTkZeXB3t7e1RXV2Pq1Km4desWxo0bBzs7O5SWluLixYtIT0/H8OHDX6pWIqIXwQBPRKRECgoK8Le//Q0xMTH1ttvY2ODIkSP1praMHz8ey5Ytw3/+8x9kZmbCy8uryetfuXIFe/bskX9QduzYsRg8eDA2bNjQ7ADftWtXzJ8/X/66S5cueO+997Bnzx6MGTMGwNMn5NnZ2Xjvvffwpz/9SX6ss7MzFi5cCCsrq2bd64+uXbuGlStXws/PD2vXroVUKgUAxMTEICoqCgsWLMCPP/4IFRUVJCUloaamBqtXr4aRkZH8Gm+++Wa9f4+cnBzMmjULM2bMeKGaiIhaG6fQEBEpEX19fYwYMaLBdqlUKg/v1dXVKCkpwb1799CtWzcAaHQKS2P69etXr8uNSCRCcHAwiouLUVZW1qxrTJkypd7rkJAQAEBubq582+HDh6GiooJJkybVOzYmJgY6OjrNuk9jkpKSUFtbi1dffVUe3gHAzMwMI0aMwI0bN5CVlQUA8vvs37+/wRShOnXHpKam4u7duy9cFxFRa+ITeCIiJWJjYwMVFZVG98XGxiIuLg5XrlxBTU1NvX0lJSXNvv4f6evrAwAePHgALS2tFl/DwMBAfn6dgoICmJqaNrieVCqFtbU1Hj582Kx6/6igoAAA4OTk1GBf3bb8/Hx4enpi/PjxSEpKwoIFC7BkyRL4+/ujR48eiI6OhqGhIQDAysoKr7/+OlasWIGwsDC4ubkhJCQEERERzfqLBhFRW+ATeCIiJaKhodHo9tWrV2PhwoUwNTXFwoULsWLFCqxevVreXrG5HYOf9ctBa1xD0boWGxgYYOvWrVi3bh0mTpyIsrIyfPbZZxg4cCBOnTolP+7999/HgQMH8Je//AU2NjbYunUrYmJisHjxYgGrJ6LOjE/giYg6gJ07d8LKygrfffcdxOL/PZs5duyYgFU9m5WVFZKTk1FWVlbvKXxVVRUKCgqgq6v7Qtete/p/+fJl2Nra1tt35cqVescAT3/ZCA4ORnBwMADgwoULGDlyJP7zn/9gxYoV9a47ceJETJw4ERUVFZg+fTq+//57TJs2rd78eSKi9sAn8EREHYBYLIZIJKr3lLu6uhrfffedgFU9W9++ffHkyROsW7eu3vbNmzfj0aNHL3VdkUiElStXoqqqSr799u3b2L59O6ysrNC1a1cAwL179xqc7+DgADU1NfmUo0ePHtW7DgCoqanBwcEBQPOnJhERtSY+gSci6gAiIiKwdOlSzJgxA+Hh4SgtLcWePXteeKXVthYTE4O4uDgsW7YMeXl58jaS+/btg0wme+aHSpvi4OAgfzo+YcIEDBo0CGVlZdi8eTPKy8uxZMkS+RSfTz75BDdv3kRYWBgsLS3x+PFj7N27F2VlZfIFtFJTU/HJJ59gwIABsLe3h5aWFs6dO4etW7fC29tbHuSJiNqTYn5nJyKiFpk+fTpqa2uxdetW/P3vf4eJiQkGDRqEkSNHIjIyUujyGpBKpVi7di0WLVqEpKQk7N27F15eXlizZg0++ugjPH78+IWv/eGHH0Imk2Hjxo1YunQpJBIJvL29sXTpUgQEBMiPGzp0KLZv3474+Hjcu3cP2tracHR0xD//+U8MHDgQAODi4oLw8HCkpaVh9+7dqKmpgYWFBWbOnIlp06a99L8DEdGLENUq2qeKiIio03ry5AlCQkLg5eXV7MWniIg6G86BJyIiQTT2lD0uLg4PHz5E9+7dBaiIiEg5cAoNEREJ4uOPP0ZlZSV8fX0hlUpx6tQp7NmzBzKZDKNHjxa6PCIihcUpNEREJIgdO3YgNjYW169fR3l5OYyMjNCrVy+8++67MDY2Fro8IiKFxQBPRERERKREOAeeiIiIiEiJMMATERERESkRfoi1he7fL0NNTfvPOjIy0sbdu6Xtfl96No6JYuK4KB6OiWLiuCgejoliEmJcxGIRDAy0nrmfAb6FampqBQnwdfcmxcIxUUwcF8XDMVFMHBfFwzFRTIo2LpxCQ0RERESkRBjgiYiIiIiUCAM8EREREZESYYAnIiIiIlIiDPBEREREREqEAZ6IiIiISIkwwBMRERERKREGeCIiIiIiJcIAT0RERESkRLgSq4JLPn8T249exb2HFTDUVcOIXl0Q6m4udFlEREREJBAGeAWWfP4m1u69gMrqGgDA3YcVWLv3AgAwxBMRERF1UpxCo8C2H70qD+91KqtrsP3oVYEqIiIiIiKhMcArsLsPK1q0nYiIiIg6PgZ4BWakq9bodm0NSTtXQkRERESKggFegY3o1QVS1fpDJBIBpb9WYXViNioqnwhUGREREREJhR9iVWB1H1T9fReaYT0ccOt+ORJ+ycXlghK8PtQdtmY6AldKRERERO2FAV7BhbqbI9TdHCYmOigufiTf7iYzxHe7z+Nv69IR08cR/f2tIRKJBKyUiIiIiNoDp9AoKTeZARZMC4KHvRF+OHgZ/9yaiYfllUKXRURERERtjAFeieloSvH2SE+M6++E89fvYd6qNGRfvyd0WURERETUhhjglZxIJEL/ABt8PCkAmmqqWBJ3GtuOXkX1k5qmTyYiIiIipcMA30HYmung08mB6OFtgYTkXHwem4HiB78KXRYRERERtTIG+A5ETaqCKYPc8PpQdxTdLcf81WlIzboldFlERERE1IoY4DugIDczLJgaCEtjLfx313msSmDPeCIiIqKOggG+gzLW18Cc8X6I7maH42eLsGDNCeTefNT0iURERESk0BjgOzAVsRgjejrgw7G+eFxZjb+vT8eBE/mora0VujQiIiIiekEM8J2A6+96xsclXcbX7BlPREREpLQY4DuJup7x48OdkXX9PuatTEMWe8YTERERKR0G+E5EJBKhn781PpkcAE11VSyNO42tR9gznoiIiEiZMMB3Qjam2vh0SiB6+lgiMSUXn23IwG32jCciIiJSCgzwnZSaRAWTI1zxxjAP3LpXjvmr0pCSdVPosoiIiIioCYIG+MrKSixevBhhYWHw8vLC6NGjkZyc3Ozzd+/ejVGjRsHHxwdBQUGYMGECMjMz5fsLCgrg4uLS6H/Hjh1ri7ekdAJcTTF/WiCsTbWxYlcWViZk4XFltdBlEREREdEzqAp58zlz5uDAgQOYNGkSZDIZ4uPjMWPGDKxfvx6+vr7PPferr77C999/jyFDhuCVV15BeXk5Lly4gOLi4gbHDhkyBGFhYfW2ubq6tup7UWbGehqYPc4Xu49fx+5fruNKQQleH+oBmbmO0KURERER0R8IFuAzMzORkJCAuXPnYsqUKQCAYcOGITo6GkuWLEFsbOwzz83IyMB///tfLF++HOHh4U3ey93dHUOHDm2t0jskFbEYw3o4wE1mgBW7s/C3demI6d0F/QNtIBaJhC6PiIiIiH4j2BSaffv2QSKRICYmRr5NTU0No0aNwsmTJ3H79u1nnrtu3Tp4enoiPDwcNTU1KCsra/J+5eXlqKxk7/OmuNg+7Rnv1cUIcYeu4OstmXhYxn83IiIiIkUhWIDPzs6Gvb09tLS06m338vJCbW0tsrOzn3lucnIyPD098eWXX8Lf3x9+fn7o27cvdu3a1ejxX3/9NXx9feHl5YVXXnkFJ06caNX30tFoa0jw1ghPTBjgjOzc+/h0VRrO57BnPBEREZEiEGwKTXFxMczMzBpsNzExAYBnPoEvKSnBgwcPkJCQABUVFcyaNQv6+vqIjY3Fhx9+CA0NDfm0GrFYjLCwMISHh8PU1BS5ublYuXIlpk6dijVr1iAgIKDt3qCSE4lE6OtnDWdrfXy76zyWbjqNQcG2GN7TAaoqbF5EREREJBRRbW1trRA37t+/PxwdHfHtt9/W256fn4/+/fvjk08+wYQJExqcV1RUhN69ewMANm/eDG9vbwBPO9qEh4fDwMAAO3bseOZ9b926haioKDg6OiIuLq713lAH9riyGit3nce+5OtwstHHhxMCYGGs1eR5RERERNT6BHsCr66ujqqqqgbbKyoqADydD9+Yuu3W1tby8A4AUqkUAwcOxLp161BWVtZgak4dMzMzREVFYfPmzfj111+hoaHRorrv3i1FTU37/85jYqKD4uJH7X7fOqN7OcDBTBtr9l7AO0sPY+JAF4S6mwtWjyIQekyocRwXxcMxUUwcF8XDMVFMQoyLWCyCkZH2s/e3Yy31mJiYNDpNpq4NpKmpaaPn6evrQyqVwtjYuME+Y2Nj1NbWorS09Ln3trCwQE1NDR4+fPgClXdeAa6mWDAtCDam2vhudxa+35OFXyvYM56IiIioPQkW4F1dXZGTk9Ogg8yZM2fk+xsjFovh5uaGW7duNdh38+ZNqKioQE9P77n3zs/Pb9Zx1JCRnjr+b5wvhnS3Q/L5m1iw5gSu3+QvQkRERETtRbAAHxERgaqqKmzZskW+rbKyEtu3b4efn5/8A66FhYW4evVqg3OLiopw/Phx+bbS0lLs3bsXvr6+UFdXBwDcu9ewc0pubi4SEhIQEBAgP45apq5n/P+N9UVVdQ3+vu4k9qXmoUaYj1MQERERdSqCzYH39vZGREQElixZguLiYtja2iI+Ph6FhYX47LPP5MfNnj0baWlpuHjxonzb2LFjsWXLFrz99tuYMmUKdHV1sW3bNjx69AgffPCB/LjFixcjPz8fISEhMDU1RV5envyDq7Nnz26/N9tB1fWMX7P3AjYfvoKs3HuYHtUVelpSoUsjIiIi6rAEC/AAsGjRIixbtgw7d+5ESUkJXFxcsGLFCvj7+z/3PA0NDaxbtw6LFi3Chg0b8PjxY7i7u2P16tX1zu3evTvi4uKwYcMGPHr0CLq6uujevTveeustODk5tfXb6xS0NSR4c7gHjpwuRFzSZcxblYZXo93gYW8kdGlEREREHZJgbSSVVWftQtMcBcWl+O/O87hxpwwRwbYY0cF7xivDmHRGHBfFwzFRTBwXxcMxUUzsQkMdmrWJNj6ZHIA+vlbYl5qHf6w/iVv3y4Uui4iIiKhDYYCnViWVqGDiQBe8OdwTxQ9+xfzVJ5B87qbQZRERERF1GAzw1Cb8XUwwf2oQZKba+G5PFr7bzZ7xRERERK2BAZ7ajJGeOj4c54uhYfZIyXraMz6niD3jiYiIiF4GAzy1KRWxGEPD7DF7nB+qn9TgH+vZM56IiIjoZTDAU7twttHH/KlB8HE0xubDV/DV5jMoKa0QuiwiIiIipcMAT+1GW0OCN4Z7YNJAF1zKf4B5q9Jw7tpdocsiIiIiUioM8NSuRCIRevta4dPJAdDRkuLLzWew6dBlVD+pEbo0IiIiIqXAAE+CsDLRxieTAtDHzwr70/Lx9/Uncesee8YTERERNYUBngQjlahg4gAXvDXCE3d+6xl//GyR0GURERERKTQGeBKcn7MJFkwLgsxcBysTsrFi93n2jCciIiJ6BgZ4UgiGuur4v7G+GNbDHqlZtzB/dRquFbJnPBEREdEfMcCTwhCLRRjS3R5zxvuhpqYWn204ib0puewZT0RERPQ7DPCkcJys9TF/WhB8nIyx5chVfLXpNHvGExEREf2GAZ4Ukpa6BG8M88DkCBdcLijBp6vSkHmVPeOJiIiIGOBJYYlEIvTyscInUwKhpyXFsi1nEJd0GVXV7BlPREREnRcDPCk8K2MtfDI5AP38rHHgRD7+sf4kbrJnPBEREXVSDPCkFCSqKhg/wBlvj/DEnZJfseC3nvG1/IArERERdTIM8KRUfH/rGW9v8bRn/He7s9gznoiIiDoVBnhSOoa66pg1xhfDezogLfs25q1Kw9XCEqHLIiIiImoXDPCklMRiEQZ3s8Oc8X6orQU+35CBRPaMJyIiok6AAZ6UmqO1HhZMC4Svswm2HrmKLzedxgP2jCciIqIOjAGelJ6mugR/GuqOKYNccaWgBJ+uTEPm1TtCl0VERETUJhjgqUMQiUTo6W2JT6cEQl9bDcu2ZOKHg+wZT0RERB0PAzx1KJbGWvhksj/6+Vvjx/R8/H1dOorulgldFhEREVGrYYCnDkeiqoLx4c54Z6QX7j2qwII1J/BTZiF7xhMREVGHwABPHZaPkzEWTAuCg4UuVidewH93nUf5Y/aMJyIiIuXGAE8dmoGOGmaN8cWIng5Iv1CM+avTcPUGe8YTERGR8mKApw5PLBYhupsd5kx42jP+sw0ZSEi+zp7xREREpJQY4KnTcLR62jPe38UE245ew9K407j/iD3jiYiISLkwwFOnoqkuwetD3TF1kCuuFpZg3qo0nL7CnvFERESkPBjgqdMRiUTo4W2JeVMCYaCjhn9uzcTGHy+xZzwREREpBQZ46rQsjLTw8SR/9A+wxsGTBewZT0REREqBAZ46NYmqCsb1d8Y7o/7XM/7YGfaMJyIiIsXFAE8EwMfxac/4LpZ6WLO3rmd8ldBlERERETXAAE/0GwMdNfz5FR+M7FXXM/4ErrBnPBERESkYBnii3xGLRYgKtcPcCX4AgM83ZGDPL9dRU8MpNURERKQYGOCJGtHFSg/zpwYhwNUE249dw5K4U+wZT0RERAqBAZ7oGTTVVTFziDumRrriWtHDpz3jL7NnPBEREQmLAZ7oOUQiEXp4Pe0Zb6ijhn9uy0Tsj5dQVf1E6NKIiIiok2KAJ2oGCyMtfDQpAOEBNkg6WYC/rj2J/FuPhC6LiIiIOiEGeKJmkqiKMba/E94d5YUHpRV476uj7BlPRERE7Y4BnqiFvB2NsXB6ENzsDLBm7wX8Zyd7xhMREVH7YYAnegH62mpY+Fo3jOrdBacuFWPeqhO4UsCe8URERNT2GOCJXpBYLEJkiAxzJvhBJAI+j83AbvaMJyIiojbGAE/0krpYPu0ZH+hmivjfesbfe/hY6LKIiIiog2KAJ2oFmuqqeG1wV0yPckNO0SPMW5WGU5eKhS6LiIiIOiAGeKJWIhKJ0N3TAvOmBsJITx3Lt59F7AH2jCciIqLWJWiAr6ysxOLFixEWFgYvLy+MHj0aycnJzT5/9+7dGDVqFHx8fBAUFIQJEyYgMzOz3jE1NTX47rvv0LdvX3h6emLw4MFITExs7bdCJGduqImPJgZgQKANkjIK8Ne16bhxp0zosoiIiKiDEDTAz5kzB2vXrsWQIUPw0UcfQSwWY8aMGTh16lST53711VeYM2cOnJyc8NFHH+HNN9+EjY0NiouLGxy3ZMkShIWF4ZNPPoGlpSXef/997Nu3r63eFhEkqmKM6eeE92K8UFJWib+uOYEjp2+wZzwRERG9NFGtQIkiMzMTMTExmDt3LqZMmQIAqKioQHR0NExNTREbG/vMczMyMjBu3DgsX74c4eHhzzzu1q1b6NevH8aOHYuPPvoIAFBbW4sJEyagqKgIBw8ehFjcst9h7t4tFaTLiImJDoqLufKnImnumDworcD3e7KQdf0+AlxMMHmQK7TUJe1QYefErxXFwzFRTBwXxcMxUUxCjItYLIKRkfaz97djLfXs27cPEokEMTEx8m1qamoYNWoUTp48idu3bz/z3HXr1sHT0xPh4eGoqalBWVnj0xMOHjyIqqoqjBs3Tr5NJBJh7NixuHHjRoPpNkRtQV9bDR+84oOYPl1w6vIdzF+VhssFD4Qui4iIiJSUYAE+Ozsb9vb20NLSqrfdy8sLtbW1yM7Ofua5ycnJ8PT0xJdffgl/f3/4+fmhb9++2LVrV4N7aGtrw97evsE9ACArK6uV3g3R84lFIgwKlmHuBH+IxSJ8HpuBXcdz2DOeiIiIWkxVqBsXFxfDzMyswXYTExMAeOYT+JKSEjx48AAJCQlQUVHBrFmzoK+vj9jYWHz44YfQ0NCQT6spLi6GsbFxi+9B1FYcLHUxf2oQ1u+/iB0/5SDr+n28NrgrDHXVhS6NiIiIlIRgAf7x48eQSBrOA1ZTUwPwdD58Y8rLywEADx48wObNm+Ht7Q0ACA8PR3h4OP7973/LA/zjx48hlUpbfI/ned58pLZmYqIj2L2pcS86Jn+ZFozDJ/Pxn22ZWLDmBN4e7YtQT4tWrq7z4teK4uGYKCaOi+LhmCgmRRsXwQK8uro6qqqqGmyvC9V1IfuP6rZbW1vLwzsASKVSDBw4EOvWrUNZWRm0tLSgrq6OysrKFt/jefghVqrzsmPiKTPAvCmB+HbnefxjTRr6+FnhlT6OkEpUWrHKzodfK4qHY6KYOC6Kh2OimPgh1t8xMTFpdApLXRtIU1PTRs/T19eHVCptdGqMsbExamtrUVpaKr/HnTt3WnwPovZiZqiJjyb5Y2CQDQ5n3MBf16XjRnGp0GURERGRAhMswLu6uiInJ6dBB5kzZ87I9zdGLBbDzc0Nt27darDv5s2bUFFRgZ6eHgDAzc0NpaWlyMnJafQebm5uL/0+iF6WqooYr/R1wvujvfGorBIL16bjyCn2jCciIqLGCRbgIyIiUFVVhS1btsi3VVZWYvv27fDz85N/wLWwsBBXr15tcG5RURGOHz8u31ZaWoq9e/fC19cX6upPPxDYr18/SCQSbNy4UX5cbW0t4uLiYGlpWW8KDpHQPB2MsGBaEJxt9LFu/0V8E38Opb82nGZGREREnZtgc+C9vb0RERGBJUuWoLi4GLa2toiPj0dhYSE+++wz+XGzZ89GWloaLl68KN82duxYbNmyBW+//TamTJkCXV1dbNu2DY8ePcIHH3wgP87c3ByTJk3CqlWrUFFRAU9PTxw8eBDp6en46quvWryIE1Fb09NWw/ujvXEgLR/bjl5Fzuo0vDbYHc42+kKXRkRERApCsAAPAIsWLcKyZcuwc+dOlJSUwMXFBStWrIC/v/9zz9PQ0MC6deuwaNEibNiwAY8fP4a7uztWr17d4NxZs2ZBT08PmzZtwvbt22Fvb4+lS5ciMjKyLd8a0QsTi0SICLaFi60+/rvzPL7YmIEh3e0R3U0GFf7SSURE1OmJajnRtkXYhYbqtMeY/FpRjQ0HLiL5/C04W+vhtSHu7BnfBH6tKB6OiWLiuCgejoliYhcaImoRDTVVzBjsjlej3ZB7uxTzVqXh5MViocsiIiIiATHAEymBbh4WmD81ECb6Gvh3/Fms338RlVVPhC6LiIiIBMAAT6QkzAw08ZeJ/ogIssXhUzfw17XpKGDPeCIiok6HAZ5IiaiqiDG6ryM+GO2NR+WV+OvadBzOKGDPeCIiok6EAZ5ICXk4GGHB9GC42Ohj/YFL+Dd7xhMREXUaDPBESkpPS4r3RntjdB9HnLlyB/NWpeFi3n2hyyIiIqI2xgBPpMTqesb/ZaI/JKpiLPrhFHb8dA1PamqELo2IiIjaCAM8UQdgb6GLeVMCEepujl3Hr2PRxlO4W/JY6LKIiIioDTDAE3UQGmqqeDW6K2ZEd0Xebz3j0y/cFrosIiIiamUM8EQdTKiHORZMDYSZoQa+2XEO6/ZdQAV7xhMREXUYDPBEHZCpgSbmTvDHoGBbHDld+LRn/G32jCciIuoIGOCJOihVFTFi+jjig1e8UfprFRauTcch9ownIiJSegzwRB2ch70RFk4LgqtMHxsOXMK/tp9lz3giIiIlxgBP1AnoaknxXow3xvR1RObVu+wZT0REpMQY4Ik6CbFIhAFBtvh4UgCkqmIs2ngK8cfYM56IiEjZMMATdTIycx3MmxqIbh7m2P3LdXwRewp3Sn4VuiwiIiJqJgZ4ok5IXaqK6dFd8drgrigoLsX8VSfYM56IiEhJMMATdWIh7uaYPy0IZoaa+GbHOazZy57xREREio4BnqiTM9XXwNwJfhgUYotjZwqxcM0J5LNnPBERkcJigCeipz3jezviz6/4oPxxNf66Nh1JJ9kznoiISBExwBORnLu9IRZMC0JXOwPE/ngJy7exZzwREZGiYdaZrkIAACAASURBVIAnonp0taR4d5QXxvRzwtlrT3vGX8hlz3giIiJFwQBPRA2IRCIMCLR52jNeooLFP5zCdvaMJyIiUggM8ET0TDJzHcybEoDunhbY88t1fB6bgTsP2DOeiIhISAzwRPRc6lJVTItyw2tDuqLwThnmrT6BtOxbQpdFRETUaTHAE1GzhHQ1x7ypQbAw0sS3O89jzd5sVFSyZzwREVF7Y4AnomYz1dfAnPF+iAqV4aczRVi49gTybj0SuiwiIqJOhQGeiFpEVUWMkb264M9jfFBeUY2/rUvHwfR89ownIiJqJwzwRPRCutrV9Yw3xMaDl7F821k8Kq8UuiwiIqIOjwGeiF6YrubTnvFj+zvhXM5dfLoqDdnX7wldFhERUYfGAE9EL0UkEiE84GnPeA2pKpbEnca2o1dR/YQ944mIiNoCAzwRtQpbMx3MmxKIMC8LJCTn4ovYDBSzZzwREVGrY4AnolajJlXB1Eg3vD7UHYV3yzB/dRp7xhMREbUyBngianVBbmaYPzUIlkZa+HbneaxKZM94IiKi1sIAT0RtwkRfA7N/6xl/PLMIC9awZzwREVFrYIAnojZT1zN+1hgfPK582jP+R/aMJyIieikM8ETU5tx+6xnvYW+EHw5extdbM/GQPeOJiIheCAM8EbULHU0p3h7piXH9nZB1/R7mrUpDFnvGExERtVirBPjq6mrs378fmzdvRnFxcWtckog6IJFIhP6/9YzXVFPFUvaMJyIiajHVlp6waNEipKamYtu2bQCA2tpaTJ06Fenp6aitrYW+vj42b94MW1vbVi+WiDoGWzMdfDo5ED8kXUJCci6yc+/jtSHuMNXXELo0IiIihdfiJ/A//fQTAgIC5K8PHTqEEydOYPr06Vi6dCkAYMWKFa1XIRF1SGpSFUwZ9LRnfNHdcsxflYaUrJtCl0VERKTwWvwE/ubNm5DJZPLXhw8fhrW1NWbNmgUAuHz5Mnbv3t16FRJRhxbkZgYHC138d/d5rNiVhayc+xgX7gR1aYu/PREREXUKLX4CX1VVBVXV//1gTU1NRbdu3eSvbWxsOA+eiFrEWF8Dc8b7IbqbHY6fLcKCNenIvcme8URERI1pcYA3NzfHqVOnADx92p6fn4/AwED5/rt370JTU7P1KiSiTkFFLMaIng6YNdYXFZXV+Pv6dBw4wZ7xREREf9Tiv1FHRUXhm2++wb1793D58mVoa2ujV69e8v3Z2dn8ACsRvTA3mQEWTAvC6sQLiEu6jKzr9zAt0g26WlKhSyMiIlIILX4CP3PmTAwfPhynT5+GSCTCF198AV1dXQDAo0ePcOjQIYSGhrZ6oUTUedT1jB8f7oys6/cxb1UazrNnPBEREQBAVNuKf5+uqalBWVkZ1NXVIZFIWuuyCuXu3VLU1LT/n/RNTHRQXMw5wYqEY9I+8m+X4tud53DzbjkiQmwxvIcDVFWe/eyB46J4OCaKieOieDgmikmIcRGLRTAy0n72/ta8WXV1NXR0dDpseCei9mdjqo1PpwSip48l9qbk4bMNGbh9v1zosoiIiATT4gB/9OhRLF++vN622NhY+Pn5wcfHB3/+859RVVXVrGtVVlZi8eLFCAsLg5eXF0aPHo3k5OQmz1u+fDlcXFwa/Ne9e/cGxzZ2nIuLC3744YfmvWEiEpyaRAWTI1zxxjAP3LpXjvmrTyDlPHvGExFR59TiD7GuXLkSRkZG8tdXr17FP/7xD9jY2MDa2hqJiYnw9PTElClTmrzWnDlzcODAAUyaNAkymQzx8fGYMWMG1q9fD19f3ybPX7hwIdTV1eWvf///vxcWFoYhQ4bU2+bt7d3k9YlIsQS4msLOQgcrdmdhxe4snM+5h/EDnNkznoiIOpUW/9S7du1ava4ziYmJUFNTw9atW6GtrY0///nP2LFjR5MBPjMzEwkJCZg7d6782GHDhiE6OhpLlixBbGxsk7UMGjRI/gHa53FwcMDQoUObPI6IFJ+xngZmj/PFrp+vY88v13HlRgleH+qBwrtl2H70Ku49rIChrhpG9OqCUHdzocslIiJqdS2eQlNSUgIDAwP5619++QUhISHQ1n460T4oKAgFBQVNXmffvn2QSCSIiYmRb1NTU8OoUaNw8uRJ3L59u8lr1NbWorS0tFl9oh8/foyKioomjyMixaciFmN4Twd8ONYXldU1WLjmBFYlZOPuwwrUArj7sAJr915AMqfZEBFRB9TiAG9gYIDCwkIAQGlpKc6ePYuAgAD5/urqajx58qTJ62RnZ8Pe3h5aWlr1tnt5eaG2thbZ2dlNXqN3797w9/eHv78/5s6diwcPHjR63NatW+Hj4wMvLy8MHjwYP/74Y5PXJiLF5/pbz3hVVTGe/KE7VGV1DbYfvSpQZURERG2nxVNofHx8EBcXB0dHRxw7dgxPnjxBz5495ftzc3Nhamra5HWKi4thZmbWYLuJiQkAPPcJvK6uLiZOnAhvb29IJBKkpKRg06ZNyMrKwpYtWyCV/m/BF19fX0RGRsLa2hpFRUVYt24d3nrrLSxduhTR0dEteetEpIC0NSSoqq5pdN/dh/yrGxERdTwtDvDvvPMOJk2ahPfeew8AMHz4cDg6OgJ4OqXl4MGDCA4ObvI6jx8/brTdpJqaGgA8d7rL5MmT672OiIiAk5MTFi5ciB07dmD06NHyfXFxcfWOHT58OKKjo7F48WJERUVBJBI1WevvPa8nZ1szMdER7N7UOI6JYjAx0EDx/V8bbFeTqOBRZQ0crPQEqIp+j18rionjong4JopJ0calxQHe0dERiYmJyMjIgI6ODgIDA+X7Hj58iMmTJzcrwKurqzfabrIuuNcF+eYaO3YsFi9ejOTk5HoB/o80NTUxZswYLF26FNeuXUOXLl1adB8u5ER1OCaKY1iYPdbuvYDK3z2JF4tFeFJTg3e/PAJPByNEhcrgbKMvYJWdF79WFBPHRfFwTBSTIi7k9EK91/T19dG3b98G2/X09Bo8HX8WExOTRqfJFBcXA0CzpuH8nlgshpmZGUpKSpo81sLCAgCadSwRKb66bjN/7ELj1cUIhzJu4McT+fg8NgNO1nqICpXB08GoxX99IyIiUhQv3Dw5Ly8PSUlJyM/PBwDY2NigX79+sLW1bdb5rq6uWL9+PcrKyup9kPXMmTPy/S1RVVWFoqIieHh4NHlsXc2GhoYtugcRKa5Qd3OEups3eFIyuJsdBgTa4NiZQuxPy8OyLZmwMdVGZIgMAa4mUBG36oLUREREbe6FAvyyZcvw3XffNeg2s3jxYsycORPvvvtuk9eIiIjAqlWrsGXLFnkf+MrKSmzfvh1+fn7yD7gWFhbi119/rTfV5d69ew3C98qVK1FRUYEePXo897j79+9j48aNsLa2hp2dXUveNhEpKTWJCsIDbNDH1wop529hb2ou/rvrPOKPaSAixBbdPSwgUWWQJyIi5dDiAL9161Z8++238PX1xauvvgonJycAwOXLl7Fy5Up8++23sLGxwYgRI557HW9vb0RERGDJkiUoLi6Gra0t4uPjUVhYiM8++0x+3OzZs5GWloaLFy/Kt/Xp0weRkZFwdnaGVCpFamoq9u/fD39//3qdZWJjY5GUlITevXvD0tISt27dwqZNm3Dv3j38+9//bulbJyIlp6oiRpiXBbp5muPUpWIkJOdi3b6L2PlzDgYG2qKXjyU01LiqKxERKTZRbXNWQfqdESNGQCKRIDY2Fqqq9X/QVVdXY/z48aiqqsL27dubvFZFRQWWLVuG3bt3o6SkBC4uLvjggw/QrVs3+TETJ05sEOA//vhjZGRkoKioCFVVVbCyskJkZCRmzpwJdXV1+XE///wzVq5ciUuXLqGkpASamprw8fHBzJkz4e/v35K3LccPsVIdjoliasm41NbWIiv3PhKTc5Gdex9a6qro62eN/gHW0NGUNn0BahZ+rSgmjovi4ZgoJkX8EGuLA7y3tzc++OCDZ35Yde3atfjyyy/lc9k7GgZ4qsMxUUwvOi7XCh8iIfk6Tl2+A6lEjJ7elogIsoWhrnqT59Lz8WtFMXFcFA/HRDEpYoBv8d+KJRIJysvLn7m/rKys0f7uRESKzMFSF2+P9MKNO2XYm5KLQydv4HDGDYS6m2NQiC0sjLSavggREVE7aPGntjw9PbFp0ybcuXOnwb67d+9i8+bN8Pb2bpXiiIjam5WxFl6N7orPZ4agl48lUrNv4ePvUvFN/Fnk3uSTMSIiEl6Ln8C/8cYbmDJlCiIjIzFy5Ej5KqxXrlzB9u3bUVZWhiVLlrR6oURE7clYXwMTBrhgcHd7HEzPx6GMAqRfLIa7vSGiQmRwsdVnL3kiIhJEi+fAA8ChQ4fw17/+FUVFRfW2W1pa4tNPP0Xv3r1bqz6FwznwVIdjopjaalzKH1fj8KkC/HgiHw/Lq9DFUheRoTJ4OxpDzCD/XPxaUUwcF8XDMVFMHWIOPAD07dsXvXv3xrlz51BQUADg6UJO7u7u2Lx5MyIjI5GYmPhiFRMRKSBNdVVEhdohPMAGP58twr7UPCzfdhZWxlqIDJEhqKspF4UiIqJ28cINj8ViMby8vODl5VVv+/3795GTk/PShRERKSKpRAV9/azR09sSJ7JvIzElF9/tyUL8T9cQEWyLME8LSCUqQpdJREQdGFcsISJ6AaoqYoR6mCPY3QxnrtxBYnIuNhy4hF3HryM8wBp9fK2hqc5vsURE1Pr404WI6CWIRSL4OpnAx9EYF/MeICElF9uOXkNiSh76+lkhPMAGulpcFIqIiFoPAzwRUSsQiURwlRnAVWaA6zcfIjE5F4nJuThwIh89vSwxMNgGxnoaQpdJREQdAAM8EVErszPXxRvDPVF0twx7U/Jw5PQNHDl9A8FdzTAoRAYrYy4KRUREL65ZAX716tXNvmBGRsYLF0NE1JFYGGlhWpQbhvWwx760PBw7U4hfzt2Er5MxokLt4GCpK3SJRESkhJoV4L/44osWXZSLmxAR/Y+hrjrG9XfG4G52OJhegKSTBTh1OR1uMgNEhsrQVWbA75tERNRszQrw69ata+s6iIg6PB1NKYb3dEBEsC2Oni7E/hN5WBp3GvYWOogMkcHX2YSLQhERUZOaFeCDgoLaug4iok5DQ00VEcG26OdvhePnbmJfSh7+HX8OFkaaGBQsQ4i7GVRVuCgUERE1jh9iJSISiERVBb19rNDDywLpF4qRkJyLVYnZ2PnzNQwMskUPb0uocVEoIiL6AwZ4IiKBqYjFCO5qhiA3U2RevYuElFxsPHgZu3+5jv4BNujnZwVNdYnQZRIRkYJggCciUhAikQjejsbwdjTGpfwHSEjORfyxa9ibkos+vlYYEGgDPW01ocskIiKBMcATESkgZxt9ONvoI+/WIySm5GJfWh5+TC9AmJcFIoJtYarPRaGIiDorBngiIgVma6aD14d6YHjPcuxNycPPmYU4droQQW6miAyRwdpUW+gSiYionTHAExEpATMDTUwZ5IqhYfY4cCIPR04VIiXrFry7GCEq1A6O1npCl0hERO2EAZ6ISIkY6Kjhlb5OiAq1w6GTBfgxPR//2HASzjb6iA6Vwd3ekItCERF1cAzwRERKSFtDgiFh9hgYZIujZwqxPy0PX24+A1szbUSF2sHf2QRiMYM8EVFHxABPRKTE1KQqGBBog75+Vkg+dxOJqXn4z45zMDPUxKBgW3TzMOeiUEREHQwDPBFRB6CqIkYPb0t097TAyUvFSEi+jjV7L2DnzzkYGGiDnj6WUJfyWz4RUUfA7+ZERB2IWCxCoKspAlxMcD7nHhKScxF36Mr/FoXyt4a2BheFIiJSZgzwREQdkEgkgoeDETwcjHDlRgkSk3Ox8+cc7EvNQy8fSwwMsoWBDheFIiJSRgzwREQdnKOVHt4Z5YWC26VITM3FwfQCHMooQDcPcwwKlsHMUFPoEomIqAUY4ImIOglrU228Ntgdw3o4YH9qHn7KLMJPmUUIdH26KJStmY7QJRIRUTMwwBMRdTKm+hqYONAFQ7rb4UB6Pg5n3EBa9m14OhghKlQGZxt9oUskIqLnYIAnIuqk9LTVENPbEVEhMhzKuIEDJ/LxeWwGHK31EBUig1cXIy4KRUSkgBjgiYg6OU11CaK72SE80AY//bYo1NdbM2Ftoo3IUFsEuppCRcxe8kREioIBnoiIAABqEhX0D7BBb18rpGbdQmJKLlbsykL8sWsYFCxDd09zSFRVhC6TiKjTY4AnIqJ6VFXE6O5pgVAPc5y6dAeJKdexbv9F7DyegwGBNujtYwUNNf74ICISCr8DExFRo8QiEfxdTODnbIzs3PtISM7FlsNXkfBLLvr6WyM8wBo6mlKhyyQi6nQY4ImI6LlEIhG62hmiq50hrhU+RELydez55ToOnMhDT29LRATZwlBXXegyiYg6DQZ4IiJqNgdLXbw90gs37pRhb0ouDmfcwOGMGwh1N8egEFtYGGkJXSIRUYfHAE9ERC1mZayFV6O7YlgPe+xPzcexzEIcP1sEPxcTRIXKYGeuK3SJREQdFgM8ERG9MGM9DYwf4IzB3e3wY3o+DmXcwMmLxXC3M0BkqB1cbbkoFBFRa2OAJyKil6arJcXIXl0wKFiGI6efLgq1+IdTcLDUxdiBrrA31YKYi0IREbUKBngiImo1muqqiAyRob+/NY6fLcLe1Dz8fXUarIy1MCjEFkFuZlBV4aJQREQvgwGeiIhanVSigj5+1ujpY4kLBQ8R9+NFfL8nGzt+ykFEsC3CPC0glXBRKCKiF8EAT0REbUZFLEZvfxu42egh88pdJKRcx4YDl7Dr5xyEB9qgj681NNX5o4iIqCX4XZOIiNqcWCSCj5MxvB2NcCn/ARKSc7Ht6DUkpuSir581wgNsoKvFRaGIiJqDAZ6IiNqNSCSCi60BXGwNcP3mQyQm5yIxORcHTuSjh5cFIoJsYayvIXSZREQKjQGeiIgEYWeuizeGe6Lobhn2pubh6OlCHDlViOCuZogMlcHKmItCERE1hgGeiIgEZWGkhWmRbhgWZo/9afk4euYGks/fhK+TMSJDZehiqSd0iURECoUBnoiIFIKhrjrG9ndCdDcZkk4WIOlkAU5dvgNXW31Ehdqhq50BROwlT0TEAE9ERIpFR1OKYT0cMDDIFkdPF2L/iTws3XQaduY6iAqVwdfZhItCEVGnJmiAr6ysxNdff42dO3fi4cOHcHV1xfvvv4/Q0NDnnrd8+XL861//arDd2NgYx48fb7B9y5YtWLVqFQoKCmBpaYlJkyZh/PjxrfY+iIio9WmoqSIi2Bb9/K1x/FwR9qXk4d/x52BhpIlBwTKEuHNRKCLqnAQN8HPmzMGBAwcwadIkyGQyxMfHY8aMGVi/fj18fX2bPH/hwoVQV1eXv/79/9eJi4vDvHnzEBERgalTpyI9PR0LFy5ERUUFpk2b1qrvh4iIWp9EVYzePlbo6WWJ9Iu3kZCci1WJ2djx8zUMDLJFT29LqHFRKCLqRAQL8JmZmUhISMDcuXMxZcoUAMCwYcMQHR2NJUuWIDY2tslrDBo0CLq6us/c//jxY3z11Vfo168fvv76awDA6NGjUVNTg3/961+IiYmBjo5Oq7wfIiJqW2KxCEFuZgh0NcXZa3eRkJyLHw5exu7j1xEeYI2+/tbQUpcIXSYRUZsT7G+P+/btg0QiQUxMjHybmpoaRo0ahZMnT+L27dtNXqO2thalpaWora1tdH9qaioePHiAcePG1ds+fvx4lJWV4dixYy/3JoiIqN2JRCJ4dTHG3An+mDPeDw6Wuoj/KQcffvMLNh++ggelFUKXSETUpgR7Ap+dnQ17e3toadXv8+vl5YXa2lpkZ2fD1NT0udfo3bs3ysvLoaWlhYEDB2L27NnQ19eX78/KygIAeHh41DvP3d0dYrEYWVlZiIqKaqV3RERE7c3ZRh/ONvrIu/UIiSm52J+Wh4PpBQjzNEdEiAymXBSKiDogwQJ8cXExzMzMGmw3MTEBgOc+gdfV1cXEiRPh7e0NiUSClJQUbNq0CVlZWdiyZQukUqn8HlKptF6oByDf1pyn/EREpPhszXTw+lAPDO9Zjn2pefj5bBGOnilEkJsZIkNksDHVFrpEIqJWI1iAf/z4MSSShnMV1dTUAAAVFc/+E+jkyZPrvY6IiICTkxMWLlyIHTt2YPTo0c+9R919nnePZzEyEu6HgIkJ5+srGo6JYuK4KJ72GhMTEx14OJthasmv2HnsGvYl5yA16xYCu5ohpq8z3OwN26UOZcGvFcXDMVFMijYuggV4dXV1VFVVNdheF6rrgnxzjR07FosXL0ZycrI8wKurq6OysrLR4ysqKlp8DwC4e7cUNTWNz7lvSyYmOiguftTu96Vn45goJo6L4hFqTAaH2KKPtwUOZRTgYHoB/u9fP8HZRh9RoTJ42Bt2+kWh+LWieDgmikmIcRGLRc99aCxYgDcxMWl0CktxcTEANDn//Y/EYjHMzMxQUlJS7x5VVVV48OBBvWk0lZWVePDgQYvvQUREykVbQ4Ih3e0xMNAWR88UYn9aHr7afAa2ZtqIDJEhwMUUYnHnDvJEpHwE60Lj6uqKnJwclJWV1dt+5swZ+f6WqKqqQlFREQwMDOTb3NzcAADnzp2rd+y5c+dQU1Mj309ERB2bmlQFAwJt8MXroZg6yBUVVTX4dud5fPRdCo6dKURVdY3QJRIRNZtgAT4iIgJVVVXYsmWLfFtlZSW2b98OPz8/+QdcCwsLcfXq1Xrn3rt3r8H1Vq5ciYqKCvTo0UO+LSQkBPr6+ti4cWO9Y3/44QdoamqiZ8+erfmWiIhIwamqiNHD2xJ/fzUYbwzzgLpUFWv2XsCc/yZjf1oeHldWC10iEVGTBJtC4+3tjYiICCxZsgTFxcWwtbVFfHw8CgsL8dlnn8mPmz17NtLS0nDx4kX5tj59+iAyMhLOzs6QSqVITU3F/v374e/vj+joaPlx6urqeOedd7Bw4UK8++67CAsLQ3p6Onbt2oVZs2Y9dxEoIiLquMRiEQJcTeHvYoLz1+8hMTkXmw5dwZ5frqOfvzX6B9hAW4OLQhGRYhIswAPAokWLsGzZMuzcuRMlJSVwcXHBihUr4O/v/9zzBg8ejIyMDOzbtw9VVVWwsrLCG2+8gZkzZ0JVtf5bGj9+PCQSCVatWoWkpCRYWFjgo48+wqRJk9ryrRERkRIQiUTwsDeCh70Rrt4oQUJyLnYdv479afno5WOJgUG2MNBpecMDIqK2JKp91jKm1Ch2oaE6HBPFxHFRPMo2JgXFpdibkovUrNsQiYDunuYYFCyDmaGm0KW1KmUbl86AY6KY2IWGiIhIwVmbaGPGYHcM6+GAfWl5+OlMEX7KLEKAiykiQ2SQmStWP2gi6nwY4ImIiBphoq+BiQNcMKSbHQ6k5+Nwxg2cuHAbHg6GiAqRwdlGv9P3kiciYTDAExERPYeethpiejsiKkSGQxk38GN6Pr7YeAqOVnqIDJXBu4sRgzwRtSsGeCIiombQVJcgupsdwgNt8HNmEfal5uKfWzNhbaKFyBAZAt1MoSIWrDszEXUiDPBEREQtoCZRQT9/a/TysURq1i0kpuRixe4sxP90DRHBMoR5mkOiqiJ0mUTUgTHAExERvQBVFTG6e1og1MMcpy/fQULydazffxG7fs7BgCAb9PaxgoYaf8wSUevjdxYiIqKXIBaJ4OdsAl8nY2Tn3kdiSi62HL6KhF9y0dffGv0DrKGrKRW6TCLqQBjgiYiIWoFIJEJXO0N0tTNETtFDJCTnYs8v13EgLQ89vZ8uCmWkpy50mUTUATDAExERtTJ7C128NcIThXfKsDclF4dP3cDhUzcQ4m6GyBAZLIy0hC6RiJQYAzwREVEbsTTWwvTorhjawx770/Lx05lC/HL2JvycTRAZKoO9ha7QJRKREmKAJyIiamPGehoYH+6Mwd3tcDA9H0knb+DkpWJ0tTNAVIgMrjID9pInomZjgCciImonuppSjOjZBYOCZThy6gb2n8jH4rjTsLfQRXSoDN5OxhAzyBNRExjgiYiI2pmGmioGhcjQP8AaP5+9ib0puVi+/SwsjbUQGWKLIDczqKpwUSgiahwDPBERkUAkqiro42uFnt4WOJF9Gwkpufh+Tzbij+UgItgWPbwsIJVwUSgiqo8BnoiISGAqYjFC3M0R1NUMmVfuIiHlOmJ/vITdx3MQHmiDPr7W0FTnj2wieorfDYiIiBSEWCSCj5MxvB2NcCn/ARKSc7Ht6DUkpuSij681wgNtoKfFRaGIOjsGeCIiIgUjEongYmsAF1sD5N58hISUXOxNycWP6fkI87LAoCBbGOtrCF0mEQmEAZ6IiEiBycx18MYwD9y8V469Kbk4droQR08VIrirGSJDbGFloi10iUTUzhjgiYiIlIC5oSamRrphaJg9DpzIx5HTN5B8/iZ8nYwRGSpDF0s9oUskonbCAE9ERKREDHXVMaafE6JCZUg6WYCkkwU4dfkOXG31ERVqh652XBSKqKNjgCciIlJCOppSDOvhgIhgWxw9XYj9aXlYuuk0ZOY6iAqRwc/FhItCEXVQDPBERERKTF2qioFBtujrZ41fzhVhb2oevtlxDuaGmhgUYotQd3MuCkXUwTDAExERdQASVTF6+Vihh5cl0i/eRkJyLlYnXsDOn3MwMNAWPb0toSZVQfL5m9h+9CruPayAoa4aRvTqglB3c6HLJ6IWYIAnIiLqQMRiEYLczPD/7d15eFTV4cbx70wy2beZZAghyyQEsrEkgSoGhaKopZQWrFprWaxaqhXbSpcHqd20Vfu07qhPVbQKj62KslT6U0FBURa1oEFJWAxJSAgkISshK5n7+yNhakzClmUyyfv5yzlzzsy5nBzvm5tzz70gZRifHazk/7YX8K93DvD6tgKS40LZnVdJy0knABW1Tbzwxl4AhXgR8N2tVQAAHzNJREFUD6IALyIiMgiZTCbGJ4YzPjGcA8VtD4Xaue9Yp3rNJ52sfi9PAV7Eg2hRnIiIyCA3OiaMO65N7/b9itomyqrqMQyjH3slIudLV+BFRESGiPAQXypqm7p8786ndhAe4kdqvJU0h5VUh5XQIN9+7qGInA0FeBERkSHiu19P5IU39tLcvgYewMfbzOwpCfh4e5FbWMWufeV8sPsIANERgaQ6rKTGW0mOtRLgp9ggMhBoJoqIiAwRp9a5d7cLzfSJMTidBoWlx8ktrCK3oJIt2SW8vbMYs8lEfFQwqY62K/SjYkKxeHu583BEhiyToQVv56Siog6ns///yez2YMrLj/f790r3NCYDk8Zl4NGYDExnOy4tJ53kHa4hp7CK3MJK8kuO4zQMLN5mRkWHkhZvJdVhI354MGazHhzVE5orA5M7xsVsNhEeHtTt+7oCLyIiIt2yeJtJcVhJcViBkTQ0nWRfUTW5BW2B/rX3DgIH8ff1JiUurH3JjY0R4QGY9CRYkT6hAC8iIiJnzd/Xm4xREWSMigCg9kRz23KbwkpyC6v45EDbVpWhQT5tYd5hJc1hIzzUz53dFhlUFOBFRETkvIUE+jApLZJJaZEAHKtuaF9uU0VOfiU79pQCMMzq37a7TbyNlLgwggN83NltEY+mAC8iIiK9JiLMn6lh/kxNH4FhGBw+dqJ9uU0VO3JKeffTEgBihwW1XZ2Pt5IUG4afjyKJyNnSbBEREZE+YTKZiLEHEWMP4ooLYml1Oik4crztCn1BJZt2FbPh4yK8zCYSRoS49p9PjA7F20vPmhTpjgK8iIiI9Asvs5nE6FASo0P59uR4mltaOXC4xnVD7OvbCvj31gJ8LGaSYsLaHyplIzYyCLNuiBVxUYAXERERt/CxeDEm3saYeBuQSH1jC3sPte1wk1NYyarNeUAegX7epLTvP58abyPS6q8dbmRIU4AXERGRASHAz8KEJDsTkuwAVB1vYm9hW5jPLaxi575yAKzBvu1hvm0Pemuwrzu7LdLvFOBFRERkQLIG+5I1djhZY4djGAZlVQ2u9fPZeRVs/fwoAFHhAe1bVtpIcYQR6Gdxc89F+pYCvIiIiAx4JpOJSFsAkbYALs2MxmkYFJXWtW1XWVjJB58dYdOuw5hM4IgMdq2fHxUTiq/Fy93dF+lVCvAiIiLiccwmE47hwTiGBzNjUhwnW50cLKklp6Btuc2Gj4p4Y8chvL1MjIoOdT0hNiEqGC+zdrgRz6YALyIiIh7P28tMUmwYSbFhzJkCjc0n2V9U0/aE2IIq1ryfz5r38/Hz8SI5NozUeBtpDivR9kDdECseRwFeREREBh0/H2/GJ4YzPjEcgOP1ze073FSSU1hFdl4FACEBlrYdbuJtpDqs2MP83dltkbOiAC8iIiKDXnCADxekDOOClGEAVNQ0una3yS2o4qPcMgAiQv1Ia9/dJtVhJSTQx53dFumSAryIiIgMOeGhfkwZP4Ip40dgGAYlFfVtW1YWVPLx3nK2ZB8BIMYe2Bbm460kx4bh76voJO6nn0IREREZ0kwmE9ERgURHBDJ9YgxOp0Fh6XHXDbHvfnqYjf8twmwykTAi2HV1flR0KBZv3RAr/U8BXkRERORLzGYTCVEhJESF8K2seFpOtvLF4VrXDbH/t72Q9dsKsHibGR3TtsNNWrwNR2QwZrNuiJW+pwAvIiIichoWb6/2B0VZYSrUN55kf1G1aw39a+8d5LX3DhLg601yXJjrhtio8ADtcCN9wq0Bvrm5mUcffZR169ZRW1tLSkoKixcvJisr65w+Z+HChWzZsoUFCxZw1113dXgvOTm5yzZ//OMfuf7668+77yIiIjI0Bfh5kzE6gozREQDUnGh2XZ3PLazikwPHAAgL8nE9ITYt3ootxM+d3ZZBxK0B/s4772TDhg0sWLAAh8PBmjVrWLhwIStXriQzM/OsPuPdd9/lv//972nrXHLJJXznO9/pUJaenn7e/RYRERE5JTTQh4vShnNR2nAAyqobyG1fP/95fiXb95QCEGn1d+0/n+KwEuRvcWe3xYO5LcDv3r2b//znPyxdupQf/vCHAMyZM4dZs2bxwAMP8OKLL57xM5qbm7n//vu5+eabWbZsWbf1Ro4cyezZs3ur6yIiIiLdGhbmz7CMaL6eEY3TMDhcfsK1//z2PUd595PDmIDYyCDS2ne4SYoJc3e3xYO4LcC/+eabWCwWrr32WleZr68v11xzDQ8//DBlZWUMGzbstJ+xYsUKGhsbzxjgARobGzGZTPj6+vZK/0VERETOxGwyETssiNhhQVx5YRwnW50UHDnetn6+oIq3dxbx5keH8DKbSIm3MWpECKkOKyNHhODtpR1upGtuC/C5ubkkJCQQGBjYoXz8+PEYhkFubu5pA3x5eTlPPvkkv//97/H3P/1T01599VVWrlyJYRgkJSXxs5/9jCuuuKJXjkNERETkbHl7mRkVE8qomFC+c3ECTS2tHCiuJregigOHa/j3B/ms+yAfX4sXSbFh7TvcWIkZFoRZN8RKO7cF+PLyciIjIzuV2+12AMrKyk7b/qGHHiIhIeGMS2MyMzOZOXMmMTExHDlyhBUrVnD77bfz4IMPMmvWrPM/ABEREZEe8rV4MTYhnLEJ4djtweQfqmTfoSpy2p8Q+9nBCgCC/C2kOKykOaykxlsZFuavHW6GMLcF+MbGRiyWzjdvnFri0tTU1G3b3bt3s3btWlauXHnGH96XXnqpw+urrrqKWbNm8be//Y1vfetb5/zDHx4edE71e5PdHuy275auaUwGJo3LwKMxGZg0LgNPQpyNhDgbMy5pe11R00D2gXKyDxwj+0A5/93bdoHTbvUnfZSd9NERjB9t1w43fWygzRW3BXg/Pz9aWlo6lZ8K7t2tVTcMg3vvvZcrr7ySr33ta+f8vQEBAXz/+9/nwQcf5ODBgyQmJp5T+4qKOpxO45y/t6fs9mDKy4/3+/dK9zQmA5PGZeDRmAxMGpeBp7sxGeewMs5hZe70UZRWNfzvhtjPSnj740MAjIgIbFtu47CSHBdGgJ92uOkt7pgrZrPptBeN3Rbg7XZ7l8tkysvLAbpd/75x40Z2797N4sWLKS4u7vBeXV0dxcXFRERE4OfX/W+iUVFRANTU1Jxv90VERET6lclkYrgtgOG2AC6dEIPTaVBUVue6Ifb93SW8s7MYkwnihwe7Hig1KjoUH4uXu7svvchtAT4lJYWVK1dy4sSJDjeyZmdnu97vSklJCU6nkxtuuKHTe6tXr2b16tU888wzTJ06tdvvLioqAsBms/XkEERERETcxmw24RgejGN4MN+c5KDlpJODJTXkFratoX/zw0P8Z3th242z0SGuPejjo4LxMmuHG0/mtgA/Y8YMnnvuOVatWuXaB765uZnVq1czYcIE1w2uJSUlNDQ0uJa6XHbZZcTExHT6vEWLFnHppZdyzTXXMGbMGAAqKys7hfSqqir++c9/EhMTQ3x8fN8doIiIiEg/snibSY6zkhxnZc4UaGg6yYHianLanxC7ZstB1gD+vl4kx1rbnhIbbyU6IlA3xHoYtwX49PR0ZsyYwQMPPEB5eTlxcXGsWbOGkpIS7r//fle9JUuW8NFHH7Fv3z4A4uLiiIuL6/IzY2Njufzyy12vX3zxRd555x2mTZvGiBEjKC0t5eWXX6ayspInnniibw9QRERExI38fb0ZnxjB+MQIAGrrm9lb2Bbmcwuq+PSLYwCEBPq0hfn2NfQRYaffnlvcz20BHuCvf/0rjzzyCOvWraOmpobk5GSefvppJk6c2Cufn5mZya5du1i1ahU1NTUEBASQkZHBLbfc0mvfISIiIuIJQgJ8uDA1kgtT21Y5HKtpILf96nxOYRUf5pQCYA/zI9VhIy3eSorDSkiAjzu7LV0wGYbR/1uqeDDtQiOnaEwGJo3LwKMxGZg0LgOPO8fEMAxKjp1w7T+/r6iKhqZWAGLsQaTFt12hT4oNw9/Xrdd/+512oRERERGRAcdkMhFtDyLaHsQVX4ul1emk4Ohx1xX6TbsOs+HjIrzMJhKiQlxPiB05IhSLt26I7W8K8CIiIiLSgZfZTOKIUBJHhDJrcjzNLa18cbh9h5uCKtZvL+D1bQX4eJsZHRvmekJs3LBgzGbdENvXFOBFRERE5LR8LF6kxdtIi7dx9dehvrGFfYeq25bcFFax6t08AAL9vEmJawvzqQ4rw20B2uGmDyjAi4iIiMg5CfCzkJlkJzPJDkB1XZNrd5vcwkp27m97MKc12Pd/O9zE27AG+7qz24OGAryIiIiI9EhYkC9ZY4aTNWY4hmFQVt3gCvS78yrY9vlRAIbbAkiNb9uuMjnOSpC/xc0990wK8CIiIiLSa0wmE5HWACKtAUzLiMZpGBSX1bUF+sIqtn12lM27DmMC4oYHu9bPj44Jw9fi5e7uewQFeBERERHpM2aTibjIYOIig/nGhXGcbHWSf6SW3IK2/ec3fFzEGx8ewtvLROKI0PYr9Dbio4Lx9tION11RgBcRERGRfuPtZWZ0TBijY8L4ziUJNDW3cqC42rUH/br381n7fj6+Pl4kx4a51tDHDAvCrBtiAQV4EREREXEjXx8vxo4MZ+zIcADqGlrYW/i/J8TuzqsAIDjA4trhJs1hxR7mP2R3uFGAFxEREZEBI8jfwtdShvG1lGEAVNY2uvafzy2s5OO9ZQCEh/i5wnyqw0po0NDZ4UYBXkREREQGLFuIHxePi+LicVEYhsHRyvr2MF/Frn3lfLD7CADREYFty23irSTHWgnwG7wxd/AemYiIiIgMKiaTiajwQKLCA5k+MQan06Cw9Hj7lpWVbMku4e2dxZhNJuKjgtv2n3dYGRUTisV78OxwowAvIiIiIh7JbDaREBVCQlQIMy9y0HLSSd7hmvYnxFbyxo5D/Gd7IRZvM6OiQ0mLt5LqsBE/PBiz2XPXzyvAi4iIiMigYPE2k+KwkuKwAiNpaDrJvqJq1xNiX3vvIHAQf19vUuLad7iJtzEiPKDTDbHb9xxl9Xt5VNY2YQvx5btfTyRrzHC3HNdXKcCLiIiIyKDk7+tNxqgIMkZFAFB7orn9gVKV5BZW8cmBYwCEBvm4tqtMc9jYX1zNC2/spfmkE4CK2iZeeGMvwIAI8QrwIiIiIjIkhAT6MCktkklpkQAcq25oX25TRU5+JTv2lAJtS3OcTqND2+aTTla/l6cALyIiIiLiLhFh/kwN82dq+ggMw+DwsRPkFlTxr3cOdFm/orapn3vYNT2fVkRERESGPJPJRIw9iCsuiCU8pOs95bsr728K8CIiIiIiX/Ldryfi490xJvt4m/nu1xPd1KOOtIRGRERERORLTq1z1y40IiIiIiIeImvMcLLGDMduD6a8/Li7u9OBltCIiIiIiHgQBXgREREREQ+iAC8iIiIi4kEU4EVEREREPIgCvIiIiIiIB1GAFxERERHxIArwIiIiIiIeRAFeRERERMSDKMCLiIiIiHgQPYn1HJnNpiH53dI1jcnApHEZeDQmA5PGZeDRmAxM/T0uZ/o+k2EYRj/1RUREREREekhLaEREREREPIgCvIiIiIiIB1GAFxERERHxIArwIiIiIiIeRAFeRERERMSDKMCLiIiIiHgQBXgREREREQ+iAC8iIiIi4kEU4EVEREREPIgCvIiIiIiIB/F2dweGsubmZh599FHWrVtHbW0tKSkpLF68mKysrDO2LS0t5b777mPr1q04nU4uuugili5dSmxsbD/0fPA63zFZtmwZjz/+eKfyiIgItm7d2lfdHRLKyspYsWIF2dnZfP7559TX17NixQomTZp0Vu3z8vK477772LVrFxaLhUsvvZQlS5Zgs9n6uOeDW0/G5c4772TNmjWdytPT03nllVf6ortDwu7du1mzZg0ffvghJSUlhIWFkZmZyR133IHD4Thje51Xel9PxkTnlb7z2Wef8fe//52cnBwqKioIDg4mJSWFRYsWMWHChDO2HwhzRQHeje688042bNjAggULcDgcrFmzhoULF7Jy5UoyMzO7bXfixAkWLFjAiRMnuPXWW/H29ub5559nwYIFrF27ltDQ0H48isHlfMfklHvuuQc/Pz/X6y//t5yf/Px8nnnmGRwOB8nJyXzyySdn3fbo0aPMnTuXkJAQFi9eTH19Pc899xz79+/nlVdewWKx9GHPB7eejAuAv78/d999d4cy/VLVM8uXL2fXrl3MmDGD5ORkysvLefHFF5kzZw6vvvoqiYmJ3bbVeaVv9GRMTtF5pfcVFRXR2trKtddei91u5/jx47z++uvMmzePZ555hosvvrjbtgNmrhjiFtnZ2UZSUpLxj3/8w1XW2NhoXH755cYPfvCD07Z9+umnjeTkZGPPnj2usi+++MJITU01Hnnkkb7q8qDXkzF57LHHjKSkJKOmpqaPezn0HD9+3KisrDQMwzA2btxoJCUlGTt27Dirtn/4wx+MjIwM4+jRo66yrVu3GklJScaqVav6pL9DRU/GZcmSJcbEiRP7sntD0s6dO42mpqYOZfn5+cbYsWONJUuWnLatzit9oydjovNK/6qvrzcmT55s/PjHPz5tvYEyV7QG3k3efPNNLBYL1157ravM19eXa665hp07d1JWVtZt27feeouMjAzS0tJcZYmJiWRlZfHGG2/0ab8Hs56MySmGYVBXV4dhGH3Z1SElKCgIq9V6Xm03bNjAZZddRmRkpKts8uTJxMfHa670UE/G5ZTW1lbq6up6qUcyYcIEfHx8OpTFx8czevRo8vLyTttW55W+0ZMxOUXnlf7h7++PzWajtrb2tPUGylxRgHeT3NxcEhISCAwM7FA+fvx4DMMgNze3y3ZOp5N9+/YxduzYTu+NGzeOgoICGhoa+qTPg935jsmXTZs2jYkTJzJx4kSWLl1KdXV1X3VXzqC0tJSKioou58r48ePPajyl75w4ccI1VyZNmsT9999PU1OTu7s16BiGwbFjx077y5bOK/3rbMbky3Re6Tt1dXVUVlZy8OBBHnroIfbv33/ae94G0lzRGng3KS8v73BV8BS73Q7Q7dXe6upqmpubXfW+2tYwDMrLy4mLi+vdDg8B5zsmACEhIcyfP5/09HQsFgs7duzg5ZdfJicnh1WrVnW6AiN979R4dTdXKioqaG1txcvLq7+7NuTZ7XZ+9KMfkZqaitPpZPPmzTz//PPk5eWxfPlyd3dvUPn3v/9NaWkpixcv7raOziv962zGBHRe6Q+/+c1veOuttwCwWCx8//vf59Zbb+22/kCaKwrwbtLY2NjlDXS+vr4A3V6JOlXe1cQ91baxsbG3ujmknO+YANxwww0dXs+YMYPRo0dzzz33sHbtWr73ve/1bmfljM52rnz1Ly7S9375y192eD1r1iwiIyN59tln2bp162lvIJOzl5eXxz333MPEiROZPXt2t/V0Xuk/ZzsmoPNKf1i0aBHXXXcdR48eZd26dTQ3N9PS0tLtL0cDaa5oCY2b+Pn50dLS0qn81A/HqR+ErzpV3tzc3G1b3aF+fs53TLpz/fXX4+/vz/bt23ulf3JuNFc8y0033QSg+dJLysvLueWWWwgNDeXRRx/FbO7+dK+50j/OZUy6o/NK70pOTubiiy/m6quv5tlnn2XPnj0sXbq02/oDaa4owLuJ3W7vcklGeXk5AMOGDeuyXVhYGD4+Pq56X21rMpm6/NOOnNn5jkl3zGYzkZGR1NTU9Er/5NycGq/u5kp4eLiWzwwgERERWCwWzZdecPz4cRYuXMjx48dZvnz5Gc8JOq/0vXMdk+7ovNJ3LBYL06dPZ8OGDd1eRR9Ic0UB3k1SUlLIz8/nxIkTHcqzs7Nd73fFbDaTlJTE559/3um93bt343A48Pf37/0ODwHnOybdaWlp4ciRIz3eqUPOT2RkJDabrdu5kpqa6oZeSXeOHj1KS0uL9oLvoaamJm699VYKCgp46qmnGDly5Bnb6LzSt85nTLqj80rfamxsxDCMTjnglIE0VxTg3WTGjBm0tLSwatUqV1lzczOrV69mwoQJrpspS0pKOm019Y1vfINPP/2UnJwcV9nBgwfZsWMHM2bM6J8DGIR6MiaVlZWdPu/ZZ5+lqamJKVOm9G3HBYBDhw5x6NChDmVXXnklmzZtorS01FW2fft2CgoKNFf6yVfHpampqcutI5988kkALrnkkn7r22DT2trKHXfcwaeffsqjjz5KRkZGl/V0Xuk/PRkTnVf6Tlf/tnV1dbz11ltERUURHh4ODOy5YjK0sajb/PznP+edd97hhhtuIC4ujjVr1vD555/zwgsvMHHiRADmz5/PRx99xL59+1zt6urquOqqq2hoaODGG2/Ey8uL559/HsMwWLt2rX4z74HzHZP09HRmzpxJUlISPj4+fPjhh7z11ltMnDiRFStW4O2t+8V74lS4y8vLY/369Vx99dXExMQQEhLCvHnzALjssssA2LRpk6vdkSNHmDNnDmFhYcybN4/6+nqeffZZoqKitItDLzifcSkuLuaqq65i1qxZjBw50rULzfbt25k5cyYPP/ywew5mELj33ntZsWIFl156Kd/85jc7vBcYGMjll18O6LzSn3oyJjqv9J0FCxbg6+tLZmYmdrudI0eOsHr1ao4ePcpDDz3EzJkzgYE9VxTg3aipqYlHHnmE119/nZqaGpKTk/nFL37B5MmTXXW6+uGBtj8333fffWzduhWn08mkSZO46667iI2N7e/DGFTOd0x++9vfsmvXLo4cOUJLSwvR0dHMnDmTW265RTd/9YLk5OQuy6Ojo13BsKsAD3DgwAH+8pe/sHPnTiwWC9OmTWPp0qVaqtELzmdcamtr+dOf/kR2djZlZWU4nU7i4+O56qqrWLBgge5L6IFT/2/qypfHROeV/tOTMdF5pe+8+uqrrFu3ji+++ILa2lqCg4PJyMjgpptu4sILL3TVG8hzRQFeRERERMSDaA28iIiIiIgHUYAXEREREfEgCvAiIiIiIh5EAV5ERERExIMowIuIiIiIeBAFeBERERERD6IALyIiIiLiQRTgRURkwJs/f77roVAiIkOdnsMrIjJEffjhhyxYsKDb9728vMjJyenHHomIyNlQgBcRGeJmzZrF1KlTO5WbzfojrYjIQKQALyIyxKWlpTF79mx3d0NERM6SLq+IiMhpFRcXk5yczLJly1i/fj3f/va3GTduHNOmTWPZsmWcPHmyU5u9e/eyaNEiJk2axLhx45g5cybPPPMMra2tneqWl5fz5z//menTpzN27FiysrK48cYb2bp1a6e6paWl/OIXv+CCCy4gPT2dm2++mfz8/D45bhGRgUpX4EVEhriGhgYqKys7lfv4+BAUFOR6vWnTJoqKipg7dy4RERFs2rSJxx9/nJKSEu6//35Xvc8++4z58+fj7e3tqrt582YeeOAB9u7dy4MPPuiqW1xczPXXX09FRQWzZ89m7NixNDQ0kJ2dzbZt27j44otddevr65k3bx7p6eksXryY4uJiVqxYwW233cb69evx8vLqo38hEZGBRQFeRGSIW7ZsGcuWLetUPm3aNJ566inX67179/Lqq68yZswYAObNm8ftt9/O6tWrue6668jIyADg3nvvpbm5mZdeeomUlBRX3TvuuIP169dzzTXXkJWVBcDdd99NWVkZy5cvZ8qUKR2+3+l0dnhdVVXFzTffzMKFC11lNpuNv/3tb2zbtq1TexGRwUoBXkRkiLvuuuuYMWNGp3Kbzdbh9eTJk13hHcBkMvGjH/2It99+m40bN5KRkUFFRQWffPIJV1xxhSu8n6r7k5/8hDfffJONGzeSlZVFdXU177//PlOmTOkyfH/1Jlqz2dxp15yLLroIgMLCQgV4ERkyFOBFRIY4h8PB5MmTz1gvMTGxU9moUaMAKCoqAtqWxHy5/MtGjhyJ2Wx21T106BCGYZCWlnZW/Rw2bBi+vr4dysLCwgCorq4+q88QERkMdBOriIh4hNOtcTcMox97IiLiXgrwIiJyVvLy8jqVffHFFwDExsYCEBMT06H8yw4ePIjT6XTVjYuLw2QykZub21ddFhEZlBTgRUTkrGzbto09e/a4XhuGwfLlywG4/PLLAQgPDyczM5PNmzezf//+DnWffvppAK644gqgbfnL1KlT2bJlC9u2bev0fbqqLiLSNa2BFxEZ4nJycli3bl2X750K5gApKSnccMMNzJ07F7vdzjvvvMO2bduYPXs2mZmZrnp33XUX8+fPZ+7cufzgBz/AbrezefNmPvjgA2bNmuXagQbgd7/7HTk5OSxcuJA5c+YwZswYmpqayM7OJjo6ml//+td9d+AiIh5KAV5EZIhbv34969ev7/K9DRs2uNaeX3bZZSQkJPDUU0+Rn59PeHg4t912G7fddluHNuPGjeOll17iscce41//+hf19fXExsbyq1/9iptuuqlD3djYWF577TWeeOIJtmzZwrp16wgJCSElJYXrrruubw5YRMTDmQz9jVJERE6juLiY6dOnc/vtt/PTn/7U3d0RERnytAZeRERERMSDKMCLiIiIiHgQBXgREREREQ+iNfAiIiIiIh5EV+BFRERERDyIAryIiIiIiAdRgBcRERER8SAK8CIiIiIiHkQBXkRERETEgyjAi4iIiIh4kP8HyA1XQALehWcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVV9-_GMY76z"
   },
   "source": [
    "# Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tocnbPMDRN00",
    "outputId": "520af18b-2131-4e50-d3a2-0717894ea0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 47 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test tweets...'.format(len(test_inputs)))\n",
    "\n",
    "# Turn on the evaluation mode of the model\n",
    "model.eval()\n",
    "\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in test_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Compute gradients, save memory and speed up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eOIrNxOukbY6",
    "outputId": "79791741-4ad2-4741-d46b-a19c356610b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 93 of 233 (39.91%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label_binary.sum(), len(df.label_binary), (df.label_binary.sum() / len(df.label_binary) * 100.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8iNrCwTYa6cI"
   },
   "source": [
    "Performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "9YzWo-1qp3kn"
   },
   "outputs": [],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "# list of keys of the highest scores, i.e. predictions (indices of the maximum values along an axis)\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x7g2bzgb-o9"
   },
   "source": [
    "Calculate F1-Score, Accuracy and Show the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cAoOFsCUwsLq",
    "outputId": "00b0cbb2-28c7-4f64-ed93-f7c9cf432c4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.7980809345014601\n",
      "Accuracy: 0.7872340425531915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "f1_value = f1_score(flat_predictions, flat_true_labels, average=\"weighted\")\n",
    "accuracy = accuracy_score(flat_predictions, flat_true_labels)\n",
    "\n",
    "print(\"F1 Score (Weighted): {}\".format(f1_value))\n",
    "print(\"Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4HRr8IOxxYO",
    "outputId": "fc0f5c86-479c-44d0-fade-5853b9b03f1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['doc_id', 'username', 'retweet_count', 'favorite_count', 'full_text',\n",
       "       'label', 'topic', 'label_binary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "2s22lIKFxrOu"
   },
   "outputs": [],
   "source": [
    "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
    "    \n",
    "    cm = confusion_matrix(y_true=true_labels, \n",
    "                                  y_pred=predicted_labels, \n",
    "                                  labels=classes)\n",
    "    cm_frame = pd.DataFrame(data=cm, \n",
    "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
    "                                                  codes=[[0,0],[0,1]]), \n",
    "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
    "                                                codes=[[0,0],[0,1]])) \n",
    "    return cm_frame   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "aARx5G5vy5vZ",
    "outputId": "2701ede2-1fb1-4ce2-c94c-0f27ebbd1027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Predicted:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Actual:</th>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted:    \n",
       "                   1   0\n",
       "Actual: 1         12   9\n",
       "        0          1  25"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_confusion_matrix(true_labels = flat_true_labels, predicted_labels = flat_predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_Fine-Tuning_pure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1e824877cec34845a345695ffda58051": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20cc76b906a74b7b9009795317298e47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_61d05a1121e24fe2ab9b40d8eed443e4",
       "IPY_MODEL_692b204587f7462591b54a55c748005d"
      ],
      "layout": "IPY_MODEL_265b0a54d14e4000bddadc355786308b"
     }
    },
    "265b0a54d14e4000bddadc355786308b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "275830e1d7bd41a9bf9edd3036c07d28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d196c69bd1c144c69521fdccbd09dc4c",
      "max": 438869143,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aea75ef5f95c4c3a82714cb51c984d4f",
      "value": 438869143
     }
    },
    "2fa807a646134ebeb81bb2268b773b4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98eecd35db414fcc9a4011f398d2a6d8",
       "IPY_MODEL_84507b06425544e19870a833cc4702b3"
      ],
      "layout": "IPY_MODEL_8b0354909cd648dcbd800173cf4b06ce"
     }
    },
    "30f689c0a0fb4dea8fe0949bd56eb21f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41cc6a9d48d34fa8810ab4751d96bf1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "56ed65affd6642fcba0f61d58430d52a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30f689c0a0fb4dea8fe0949bd56eb21f",
      "placeholder": "​",
      "style": "IPY_MODEL_7ba1ff48824d4f97a7796c2739cd727f",
      "value": " 439M/439M [00:23&lt;00:00, 18.7MB/s]"
     }
    },
    "61d05a1121e24fe2ab9b40d8eed443e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b934c6bf9e4c4f9b98d2b1c852ba0d32",
      "max": 254728,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41cc6a9d48d34fa8810ab4751d96bf1f",
      "value": 254728
     }
    },
    "671f3812c4cc4ec59c0465c7c925fbc4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_275830e1d7bd41a9bf9edd3036c07d28",
       "IPY_MODEL_56ed65affd6642fcba0f61d58430d52a"
      ],
      "layout": "IPY_MODEL_db6346eac37a48f4866933d908662d06"
     }
    },
    "67fbbb4ec13d4f6d8f570cb0c08eecd2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "692b204587f7462591b54a55c748005d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1e824877cec34845a345695ffda58051",
      "placeholder": "​",
      "style": "IPY_MODEL_6bd71b2e568840dbafca4f33947c1d01",
      "value": " 255k/255k [00:00&lt;00:00, 436kB/s]"
     }
    },
    "6bd71b2e568840dbafca4f33947c1d01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75700fbb780b43c9ba8f8c97240d303e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ba1ff48824d4f97a7796c2739cd727f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84507b06425544e19870a833cc4702b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0dc34e0da784b4cbae71dc30b929c0f",
      "placeholder": "​",
      "style": "IPY_MODEL_67fbbb4ec13d4f6d8f570cb0c08eecd2",
      "value": " 433/433 [00:23&lt;00:00, 18.1B/s]"
     }
    },
    "8b0354909cd648dcbd800173cf4b06ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98eecd35db414fcc9a4011f398d2a6d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75700fbb780b43c9ba8f8c97240d303e",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abc6d5aac8ed4405bcc61921b2a4995d",
      "value": 433
     }
    },
    "abc6d5aac8ed4405bcc61921b2a4995d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "aea75ef5f95c4c3a82714cb51c984d4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b0dc34e0da784b4cbae71dc30b929c0f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b934c6bf9e4c4f9b98d2b1c852ba0d32": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d196c69bd1c144c69521fdccbd09dc4c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db6346eac37a48f4866933d908662d06": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
