{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_ASC_Task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SguFaicljwiG"
      },
      "source": [
        "# BERT **ASPECT SENTIMENT CLASSIFICATION** TASK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHKI5zclT_wC"
      },
      "source": [
        "**Prepare GPU:**\n",
        "\n",
        "1. Check: Edit --> Notebook settings -> Hardware accelerator -> *GPU* \n",
        "\n",
        "\n",
        "2. Datasets are uploaded in *content*-folder: \n",
        "\n",
        "*   predictions_ae.json\n",
        "*   test_set_final.csv\n",
        "\n",
        "3. Datasets are uploaded in *MyDrive*-folder:\n",
        "\n",
        "\n",
        "*   germeval_pt folder\n",
        "*   train_asc_task.json\n",
        "*   test_asc_task.json\n",
        "*   dev_asc_task.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_WquHzdJg8r",
        "outputId": "3b16f37b-da1e-4112-9a55-083fc590bc07"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOLxa8-jKn5X",
        "outputId": "b3d43d6d-98e3-4616-b150-1c09c41e5e63"
      },
      "source": [
        "# Identify and specify the GPU as the device\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNs085AsKrGE"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovra0b6QIu2G"
      },
      "source": [
        "# **Install packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HIelG_zKt6u"
      },
      "source": [
        "#!pip install pytorch_pretrained_bert\n",
        "#!pip install transformers\n",
        "#!pip install nltk\n",
        "import os\n",
        "import logging\n",
        "import argparse\n",
        "import random\n",
        "import json\n",
        "import sklearn.metrics\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "import nltk\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#from transformers import BertForSequenceClassification \n",
        "\n",
        "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
        "from pytorch_pretrained_bert.modeling import BertModel, BertPreTrainedModel, BertForSequenceClassification\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "\n",
        "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
        "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
        "                    level = logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEpEtwZnJDbf"
      },
      "source": [
        "# **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADJHFjW4KxfM"
      },
      "source": [
        "def warmup_linear(x, warmup=0.002):\n",
        "    if x < warmup:\n",
        "        return x/warmup\n",
        "    return 1.0 - x\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "# specifically for asc task\n",
        "\n",
        "def create_examples(lines, set_type):\n",
        "    examples = []\n",
        "    for (i, ids) in enumerate(lines[\"data\"]):\n",
        "        guid = \"%s-%s\" % (set_type, ids )\n",
        "        text_a = lines[\"data\"][ids]['term']\n",
        "        text_b = lines[\"data\"][ids]['sentence']\n",
        "        label = lines[\"data\"][ids]['polarity']\n",
        "        examples.append(\n",
        "            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label) )\n",
        "    return examples   \n",
        "\n",
        "def read_json(input_file):\n",
        "    \"\"\"Reads a json file for tasks in sentiment analysis.\"\"\"\n",
        "    with open(input_file) as f:\n",
        "        return json.load(f)\n",
        "        \n",
        "def get_train_examples(data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return create_examples(\n",
        "        read_json(data_dir), \"train\")\n",
        "\n",
        "def get_dev_examples(data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return create_examples(\n",
        "        read_json(data_dir), \"dev\")    \n",
        "\n",
        "def get_test_examples(data_dir):\n",
        "    \"\"\"See base class.\"\"\"\n",
        "    return create_examples(\n",
        "        read_json(data_dir), \"test\")    \n",
        "    \n",
        "class BertForSequenceLabeling(BertPreTrainedModel):\n",
        "    def __init__(self, config, num_labels=3):\n",
        "        super(BertForSequenceLabeling, self).__init__(config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, num_labels)\n",
        "        self.apply(self.init_bert_weights)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None):\n",
        "        sequence_output, _ = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=False)\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        logits = self.classifier(sequence_output)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-1)\n",
        "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            return loss\n",
        "        else:\n",
        "            return logits\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer, mode):\n",
        "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\" #check later if we can merge this function with the SQuAD preprocessing \n",
        "    label_map = {}\n",
        "    for (i, label) in enumerate(label_list):\n",
        "        label_map[label] = i\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if mode!=\"ae\":\n",
        "            tokens_a = tokenizer.tokenize(example.text_a)\n",
        "        else: #only do subword tokenization.\n",
        "            tokens_a, labels_a, example.idx_map= tokenizer.subword_tokenize([token.lower() for token in example.text_a], example.label )\n",
        "\n",
        "        tokens_b = None\n",
        "        if example.text_b:\n",
        "            tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "        if tokens_b:\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
        "\n",
        "        tokens = []\n",
        "        segment_ids = []\n",
        "        tokens.append(\"[CLS]\")\n",
        "        segment_ids.append(0)\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "            segment_ids.append(0)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        segment_ids.append(0)\n",
        "\n",
        "        if tokens_b:\n",
        "            for token in tokens_b:\n",
        "                tokens.append(token)\n",
        "                segment_ids.append(1)\n",
        "            tokens.append(\"[SEP]\")\n",
        "            segment_ids.append(1)\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "            segment_ids.append(0)\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "\n",
        "        if mode!=\"ae\":\n",
        "            label_id = label_map[example.label]\n",
        "        else:\n",
        "            label_id = [-1] * len(input_ids) #-1 is the index to ignore\n",
        "            #truncate the label length if it exceeds the limit.\n",
        "            lb=[label_map[label] for label in labels_a]\n",
        "            if len(lb) > max_seq_length - 2:\n",
        "                lb = lb[0:(max_seq_length - 2)]\n",
        "            label_id[1:len(lb)+1] = lb\n",
        "\n",
        "        features.append(\n",
        "                InputFeatures(\n",
        "                        input_ids=input_ids,\n",
        "                        input_mask=input_mask,\n",
        "                        segment_ids=segment_ids,\n",
        "                        label_id=label_id))\n",
        "    return features\n",
        "\n",
        "class ABSATokenizer(BertTokenizer):     \n",
        "    def subword_tokenize(self, tokens, labels): # for AE\n",
        "        split_tokens, split_labels= [], []\n",
        "        idx_map=[]\n",
        "        for ix, token in enumerate(tokens):\n",
        "            sub_tokens=self.wordpiece_tokenizer.tokenize(token)\n",
        "            for jx, sub_token in enumerate(sub_tokens):\n",
        "                split_tokens.append(sub_token)\n",
        "                if labels[ix]==\"B\" and jx>0:\n",
        "                    split_labels.append(\"I\")\n",
        "                else:\n",
        "                    split_labels.append(labels[ix])\n",
        "                idx_map.append(ix)\n",
        "        return split_tokens, split_labels, idx_map  \n",
        " \n",
        "\n",
        "### Evaluation part\n",
        "\n",
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    cm = confusion_matrix(y_true=true_labels, \n",
        "                                  y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "    cm_frame = pd.DataFrame(data=cm, \n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
        "                                                  codes=[[0,0],[0,1]]), \n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
        "                                                codes=[[0,0],[0,1]])) \n",
        "    return cm_frame   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj7d_aEXJnKa"
      },
      "source": [
        "# **Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryocy13eLI8p"
      },
      "source": [
        "train_batch_size = 16           \n",
        "num_train_epochs = 4      \n",
        "max_seq_length = 250\n",
        "learning_rate = 2e-5\n",
        "warmup_proportion = 0.1\n",
        "\n",
        "do_valid = True\n",
        "pretrained_model = \"./drive/MyDrive/BERT_Files/germeval_pt/\" # tweets_unlabeled_pt, base_german_cased_dbmdz, \"bert-base-german-cased\" , tweets_unlabeled_pt ./drive/MyDrive/BERT_Files/germeval_pt/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Xb11uU4JsRx"
      },
      "source": [
        "# **Training Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jthYcSLfLJpc",
        "outputId": "4f9d9c1f-4cd4-4f49-ac27-76212558ee75"
      },
      "source": [
        "label_list = [\"negative\", \"positive\"] \n",
        "\n",
        "tokenizer = ABSATokenizer.from_pretrained(pretrained_model)\n",
        "train_examples = get_train_examples(data_dir = \"./drive/MyDrive/BERT_Files/BERT_ASC_Task/train_asc_task.json\")\n",
        "num_train_steps = int(len(train_examples) / train_batch_size) * num_train_epochs\n",
        "\n",
        "train_features = convert_examples_to_features(examples = train_examples, \n",
        "                                              label_list = label_list, \n",
        "                                              max_seq_length = max_seq_length, \n",
        "                                              tokenizer = tokenizer, \n",
        "                                              mode = \"asc\")\n",
        "logger.info(\"***** Running training *****\")\n",
        "logger.info(\"  Num examples = %d\", len(train_examples))\n",
        "logger.info(\"  Batch size = %d\", train_batch_size)\n",
        "logger.info(\"  Num steps = %d\", num_train_steps)\n",
        "\n",
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
        "\n",
        "train_data = TensorDataset(all_input_ids, all_segment_ids, all_input_mask, all_label_ids)\n",
        "\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=train_batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:15:40 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file ./drive/MyDrive/BERT_Files/germeval_pt/vocab.txt\n",
            "03/19/2021 22:15:41 - INFO - __main__ -   ***** Running training *****\n",
            "03/19/2021 22:15:41 - INFO - __main__ -     Num examples = 778\n",
            "03/19/2021 22:15:41 - INFO - __main__ -     Batch size = 16\n",
            "03/19/2021 22:15:41 - INFO - __main__ -     Num steps = 192\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_rHFMS0Jx6I"
      },
      "source": [
        "# **Validation Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3eiIs-fbcMc",
        "outputId": "f5536b7b-9f23-417c-daad-ef7c43f66fc4"
      },
      "source": [
        "valid_examples = get_dev_examples(data_dir = \"./drive/MyDrive/BERT_Files/BERT_ASC_Task/dev_asc_task.json\")\n",
        "valid_features= convert_examples_to_features(\n",
        "    valid_examples, label_list,  max_seq_length, tokenizer, \"asc\")\n",
        "valid_all_input_ids = torch.tensor([f.input_ids for f in valid_features], dtype=torch.long)\n",
        "valid_all_segment_ids = torch.tensor([f.segment_ids for f in valid_features], dtype=torch.long)\n",
        "valid_all_input_mask = torch.tensor([f.input_mask for f in valid_features], dtype=torch.long)\n",
        "valid_all_label_ids = torch.tensor([f.label_id for f in valid_features], dtype=torch.long)\n",
        "valid_data = TensorDataset(valid_all_input_ids, valid_all_segment_ids, valid_all_input_mask, valid_all_label_ids)\n",
        "\n",
        "logger.info(\"***** Running validations *****\")\n",
        "logger.info(\"  Num orig examples = %d\", len(valid_examples))\n",
        "logger.info(\"  Num split examples = %d\", len(valid_features))\n",
        "logger.info(\"  Batch size = %d\",  train_batch_size)\n",
        "\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size= train_batch_size)    \n",
        "\n",
        "best_valid_loss=float('inf')\n",
        "valid_losses=[]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:15:44 - INFO - __main__ -   ***** Running validations *****\n",
            "03/19/2021 22:15:44 - INFO - __main__ -     Num orig examples = 194\n",
            "03/19/2021 22:15:44 - INFO - __main__ -     Num split examples = 194\n",
            "03/19/2021 22:15:44 - INFO - __main__ -     Batch size = 16\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OXQy-EoJ7tJ"
      },
      "source": [
        "# **Optimization & Actual Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxPjhpcQbzyl",
        "outputId": "62c9a20e-4dd5-464a-da7e-5a8f8012ecd1"
      },
      "source": [
        "    model = BertForSequenceClassification.from_pretrained(pretrained_model, \n",
        "                                                          num_labels = 2) # \"https://int-deepset-models-bert.s3.eu-central-1.amazonaws.com/pytorch/bert-base-german-cased.tar.gz\", num_labels = len(label_list))\n",
        "    model.cuda()\n",
        " \n",
        "    # Prepare optimizer\n",
        "\n",
        "    \n",
        "    optimizer = BertAdam(model.parameters(),\n",
        "                         lr=learning_rate,\n",
        "                         eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:15:47 - INFO - pytorch_pretrained_bert.modeling -   loading archive file ./drive/MyDrive/BERT_Files/germeval_pt/\n",
            "03/19/2021 22:15:47 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "03/19/2021 22:15:58 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "03/19/2021 22:15:58 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'qa_outputs.weight', 'qa_outputs.bias']\n",
            "03/19/2021 22:15:59 - WARNING - pytorch_pretrained_bert.optimization -   t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEZNlTj0oC0G"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "t_total = len(train_dataloader) * num_train_epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = t_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxwHM-jFolUF"
      },
      "source": [
        "# helper function for formatting elapsed times\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SokYwO3vIkq",
        "outputId": "8625864b-b70d-4add-aa99-9cce3ba296e8"
      },
      "source": [
        "# global_step = 0\n",
        "# model.train()\n",
        "# for _ in range(num_train_epochs):\n",
        "#     for step, batch in enumerate(train_dataloader):\n",
        "#         batch = tuple(t.cuda() for t in batch)\n",
        "#         input_ids, segment_ids, input_mask, label_ids = batch\n",
        "#         loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "#         loss.backward()\n",
        "\n",
        "#         lr_this_step = learning_rate * warmup_linear(global_step/t_total, warmup_proportion)\n",
        "#         for param_group in optimizer.param_groups:\n",
        "#             param_group['lr'] = lr_this_step\n",
        "#         optimizer.step()\n",
        "#         optimizer.zero_grad()\n",
        "#         global_step += 1\n",
        "#         #>>>> perform validation at the end of each epoch .\n",
        "#     if do_valid:\n",
        "#         model.eval()\n",
        "#         with torch.no_grad():\n",
        "#             losses=[]\n",
        "#             valid_size=0\n",
        "#             for step, batch in enumerate(valid_dataloader):\n",
        "#                 batch = tuple(t.cuda() for t in batch) # multi-gpu does scattering it-self\n",
        "#                 input_ids, segment_ids, input_mask, label_ids = batch\n",
        "#                 loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "#                 losses.append(loss.data.item()*input_ids.size(0) )\n",
        "#                 valid_size+=input_ids.size(0)\n",
        "#             valid_loss=sum(losses)/valid_size\n",
        "#             logger.info(\"validation loss: %f\", valid_loss)\n",
        "#             valid_losses.append(valid_loss)\n",
        "#         if valid_loss<best_valid_loss:\n",
        "#             torch.save(model, \"model.pt\")\n",
        "#             best_valid_loss=valid_loss\n",
        "#         model.train()\n",
        "# if do_valid:\n",
        "#     with open(\"valid.json\", \"w\") as fw:\n",
        "#         json.dump({\"valid_losses\": valid_losses}, fw)\n",
        "# else:\n",
        "#     torch.save(model, \"model.pt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 18:47:29 - INFO - __main__ -   validation loss: 0.406666\n",
            "03/19/2021 18:48:15 - INFO - __main__ -   validation loss: 0.354458\n",
            "03/19/2021 18:49:01 - INFO - __main__ -   validation loss: 0.327326\n",
            "03/19/2021 18:49:47 - INFO - __main__ -   validation loss: 0.394943\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj49PLkJf9QH"
      },
      "source": [
        "# helper function for calculating accuracy\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH3NrVGscmkI",
        "outputId": "f8eae3a7-4ff7-4cfe-d303-31fc8f16f334"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 55\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "#global_step = 0\n",
        "#model.train()\n",
        "for epoch_i in range(0, num_train_epochs):\n",
        "\n",
        "   ## TRAIN\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_train_epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # how long does the training epoch take.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Turn on the training mode for the model. \n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        batch = tuple(t.cuda() for t in batch)\n",
        "        \n",
        "        input_ids, segment_ids, input_mask, label_ids = batch\n",
        "        \n",
        "        # Remove any previously calculated gradients before performing a\n",
        "        # backward pass. \n",
        "        model.zero_grad()  \n",
        "\n",
        "        # Do a forward pass. \n",
        "\n",
        "        loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "        \n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end.\n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        # Do a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0. \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        " \n",
        "        # Update parameters and take a step.\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Avg loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Need for plotting the learning curve later.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Avg training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Epoch time: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "\n",
        "        #>>>> perform validation at the end of each epoch .\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        losses=[]\n",
        "        valid_size=0\n",
        "        for step, batch in enumerate(valid_dataloader):\n",
        "            batch = tuple(t.cuda() for t in batch) # multi-gpu does scattering it-self\n",
        "            input_ids, segment_ids, input_mask, label_ids = batch\n",
        "            loss = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            losses.append(loss.data.item()*input_ids.size(0) )\n",
        "            valid_size+=input_ids.size(0)\n",
        "        valid_loss=sum(losses)/valid_size\n",
        "        logger.info(\"validation loss: %f\", valid_loss)\n",
        "        valid_losses.append(valid_loss)\n",
        "    if valid_loss<best_valid_loss:\n",
        "        torch.save(model, \"model.pt\")\n",
        "        best_valid_loss=valid_loss\n",
        "    model.train()\n",
        "with open(\"valid.json\", \"w\") as fw:\n",
        "        json.dump({\"valid_losses\": valid_losses}, fw)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.42\n",
            "  Epoch time: 0:00:43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:17:09 - INFO - __main__ -   validation loss: 0.265672\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.17\n",
            "  Epoch time: 0:00:42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:17:56 - INFO - __main__ -   validation loss: 0.253996\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.03\n",
            "  Epoch time: 0:00:43\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:18:43 - INFO - __main__ -   validation loss: 0.408720\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.01\n",
            "  Epoch time: 0:00:42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:19:29 - INFO - __main__ -   validation loss: 0.374914\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAMoFG6e3bfU"
      },
      "source": [
        "\n",
        "# ## VALIDATE\n",
        "#     # After each training epoch, we measure performance on\n",
        "#     # validation set.\n",
        "\n",
        "#     t0 = time.time()\n",
        "\n",
        "#     # Turn on the evaluation mode of the model.\n",
        "#     model.eval()\n",
        "\n",
        "#     # Tracking variables \n",
        "#     eval_loss, eval_accuracy = 0, 0\n",
        "#     nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "#     # Evaluate data for one epoch\n",
        "#     for batch in valid_dataloader:\n",
        "        \n",
        "#         # Add batch to GPU\n",
        "#         batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "#         # Unpack the inputs from our dataloader\n",
        "#         input_ids, segment_ids, input_mask, label_ids = batch\n",
        "        \n",
        "        \n",
        "#         with torch.no_grad():        \n",
        "\n",
        "#             # Forward pass, calculate logit predictions.\n",
        "#             outputs = model(input_ids, \n",
        "#                             segment_ids, \n",
        "#                             input_mask)\n",
        "        \n",
        "#         # Get logit values predicted for each class.\n",
        "#         logits = outputs[0]\n",
        "\n",
        "#         # Move logits and labels to CPU\n",
        "#         logits = logits.detach().cpu().numpy()\n",
        "#         label_ids = label_ids.to('cpu').numpy()\n",
        "        \n",
        "#         # Accuracy for this batch of validation tweets.\n",
        "#         tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "#         # Accumulate the total accuracy.\n",
        "#         eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "#         # Number of batches\n",
        "#         nb_eval_steps += 1\n",
        "\n",
        "#     # Report the final accuracy for this validation run.\n",
        "#     print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "#     print(\"  Validation time: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "# print(\"\")\n",
        "# print(\"Training complete!\")\n",
        "\n",
        "# step = list(enumerate(valid_dataloader))[0][0]\n",
        "# batch = list(enumerate(valid_dataloader))[0][1]\n",
        "# batch = tuple(t.cuda() for t in batch) # multi-gpu does scattering it-self\n",
        "# input_ids, segment_ids, input_mask, label_ids = batch\n",
        "# loss = model(input_ids, segment_ids, input_mask)\n",
        "# logits = loss[0]\n",
        "# logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJFcHTbtI1yy"
      },
      "source": [
        "# **Final Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ualbw4LZf9"
      },
      "source": [
        "This is the End to End Analysis, the combined AE and ASC tasks will be evaluated in this section: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTjYxW70EUA5"
      },
      "source": [
        "\n",
        "1.   Insert original Tweets without topics and labels: tweets\n",
        "2.   Insert predicted and post-processed aspects: y_pred_aspects\n",
        "3.   Insert tweets in tokenized form during AE task: pred_json[\"raw_X\"]\n",
        "4.   Result: Aspect Extraction. Fill in the topic-column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRXcN20LH22B"
      },
      "source": [
        "Prepare test examples based on topics, gained due to AE Task    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPJUx-9U2OED"
      },
      "source": [
        "eval_batch_size = 16\n",
        "eval_examples = get_test_examples(data_dir = \"./drive/MyDrive/BERT_Files/BERT_ASC_Task/test_asc_task.json\")\n",
        "eval_features = convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer, \"asc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axEqYuBZdaH0",
        "outputId": "33cd8e1d-7c32-46dd-d38c-45f78a5f377f"
      },
      "source": [
        "\n",
        "\n",
        "logger.info(\"***** Running evaluation *****\")\n",
        "logger.info(\"  Num examples = %d\", len(eval_examples))\n",
        "logger.info(\"  Batch size = %d\", eval_batch_size)\n",
        "all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
        "eval_data = TensorDataset(all_input_ids, all_segment_ids, all_input_mask, all_label_ids)\n",
        "# Run prediction for full data\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size= eval_batch_size)\n",
        "\n",
        "model = torch.load(\"model.pt\" )\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "full_logits=[]\n",
        "full_label_ids=[]\n",
        "for step, batch in enumerate(eval_dataloader):\n",
        "    batch = tuple(t.cuda() for t in batch)\n",
        "    input_ids, segment_ids, input_mask, label_ids = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids, segment_ids, input_mask)\n",
        "\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = label_ids.cpu().numpy()\n",
        "\n",
        "    full_logits.extend(logits.tolist() )\n",
        "    full_label_ids.extend(label_ids.tolist() )\n",
        "\n",
        "with open(\"predictions_asc.json\", \"w\") as fw:\n",
        "    json.dump({\"logits\": full_logits, \"label_ids\": full_label_ids}, fw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/19/2021 22:20:17 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/19/2021 22:20:17 - INFO - __main__ -     Num examples = 243\n",
            "03/19/2021 22:20:17 - INFO - __main__ -     Batch size = 16\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AixrI4WeNbe"
      },
      "source": [
        "# **Evaluation Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "d4fSpYE8eQDG",
        "outputId": "bd67b28e-2eb7-4bd6-e460-c5aaef09780a"
      },
      "source": [
        "# Various evaluation metrics\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "with open( \"predictions_asc.json\" ) as f:\n",
        "    results=json.load(f)\n",
        "y_true=results['label_ids']\n",
        "y_pred=[np.argmax(logit) for logit in results['logits'] ]\n",
        "p_macro, r_macro, f_macro, _=sklearn.metrics.precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "f_macro = 2*p_macro*r_macro/(p_macro+r_macro)\n",
        "acc = 100*sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "f_mac = 100*f_macro \n",
        "\n",
        "f1_value = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Confusion Matrix\n",
        "display_confusion_matrix(true_labels = y_true, predicted_labels = y_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Predicted:</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Actual:</th>\n",
              "      <th>1</th>\n",
              "      <td>47</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted:     \n",
              "                   1    0\n",
              "Actual: 1         47   20\n",
              "        0          7  169"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j051qBHB8Pas",
        "outputId": "e5af7b5f-4aa8-484d-ecd4-446cf3e6481d"
      },
      "source": [
        "f1_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8848988012126244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsxnENAk8Q94",
        "outputId": "1f141248-817d-4be6-bca4-75f418aca27b"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}