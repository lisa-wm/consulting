{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify train data\n",
    "train_data = \"\"\n",
    "## specify validation data\n",
    "dataset = \"\"\n",
    "# specify column for ratings (non-negative intefer scale)\n",
    "score = \"\"\n",
    "# specify column for original scores\n",
    "score_og = \"\"\n",
    "# specify for text\n",
    "text = \"\"\n",
    "\n",
    "## model_no (cf. training.py)\n",
    "model_no = 0\n",
    "# model from which epoch?\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 127] Die angegebene Prozedur wurde nicht gefunden. Error loading \"C:\\Users\\NALMPI\\anaconda3\\lib\\site-packages\\torch\\lib\\c10_cuda.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a8b838ddfbe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### importing libraries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m  \u001b[1;31m# ML lib. allows computation of tensors on GPUs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m  \u001b[1;31m# to time execution time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWinError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrerror\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34mf' Error loading \"{dll}\" or one of its dependencies.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0mis_loaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 127] Die angegebene Prozedur wurde nicht gefunden. Error loading \"C:\\Users\\NALMPI\\anaconda3\\lib\\site-packages\\torch\\lib\\c10_cuda.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "### importing libraries\n",
    "import torch  # ML lib. allows computation of tensors on GPUs\n",
    "import os\n",
    "import json\n",
    "import time  # to time execution time\n",
    "import pandas as pd  # data analysis and manipulation\n",
    "import numpy as np  # for mathematical operations\n",
    "import scikitplot as skplt  # import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "from transformers import BertTokenizer  # tokenizes sequences of strings\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "# create tensors from data and make them accesible for model\n",
    "from transformers import BertForSequenceClassification  # our model\n",
    "from sklearn.metrics import f1_score  # for model evaluation\n",
    "\n",
    "# helper function\n",
    "# flat_values function\n",
    "def flat_values(preds, labels):\n",
    "  '''\n",
    "  Creates an array of maxima for each element in a list of arrays.\n",
    "  Creates array from list.\n",
    "  :param preds: list of arrays of numeric values (e.g. prediction scores)\n",
    "  :param labels: list of arrays (potentially with only one element) of numerric values\n",
    "  :return pred_flat: array of the maxima of the respective arrays in preds\n",
    "  :return labels_flat: flattened list (e..g transformed to np.array while preserving every element of\n",
    "                       the original arrays of the list)\n",
    "  '''\n",
    "  # list of keys of the highest scores, i.e. predictions\n",
    "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "  # list of true labels\n",
    "  labels_flat = labels.flatten()\n",
    "  return pred_flat, labels_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-dbdc044e9cd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/processed/{}.csv\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# sample size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv(\"./data/processed/{}.csv\".format(dataset))\n",
    "\n",
    "# sample size\n",
    "n_val = len(df)\n",
    "\n",
    "# load model specs\n",
    "with open(\n",
    "    \"./data/temp/training/{}/model_specs_{}.json\".format(dataset, model_no)\n",
    ") as f:\n",
    "    model_parameters = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_specs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-785fc2824d7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model_type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mMAX_LEN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"MAX_LEN\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BATCH_SIZE\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"LR\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mEPS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_specs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"EPS\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_specs' is not defined"
     ]
    }
   ],
   "source": [
    "model_type = model_specs[\"model_type\"]\n",
    "MAX_LEN = model_specs[\"MAX_LEN\"]\n",
    "BATCH_SIZE = model_specs[\"BATCH_SIZE\"]\n",
    "LR = model_specs[\"LR\"]\n",
    "EPS = model_specs[\"EPS\"]\n",
    "device_name = model_specs[\"device_name\"]\n",
    "\n",
    "# create folder to store results from this file\n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Creating directory: \" + directory)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createFolder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c579ba94ca3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcreateFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./results/sentiment_analysis/evaluation/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcreateFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./results/sentiment_analysis/evaluation/{}/\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# specify device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'createFolder' is not defined"
     ]
    }
   ],
   "source": [
    "createFolder(\"./results/sentiment_analysis/evaluation/\")\n",
    "createFolder(\"./results/sentiment_analysis/evaluation/{}/\".format(dataset))\n",
    "\n",
    "# specify device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4e492c33306e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# define tokenizers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## encode text data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m encoded_data_val = tokenizer.batch_encode_plus(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BertTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# define tokenizers\n",
    "tokenizer = BertTokenizer.from_pretrained(model_type, do_lower_case=True)\n",
    "\n",
    "## encode text data\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[text].values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    pad_to_max_length=True,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "## prepare input for model\n",
    "input_ids_val = encoded_data_val[\"input_ids\"]\n",
    "attention_masks_val = encoded_data_val[\"attention_mask\"]\n",
    "labels_val = torch.tensor(df[score].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TensorDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-28161d95e683>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# TensorDataset combines prepared model inputs in a tensor for the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_masks_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m dataloader_val = DataLoader(\n\u001b[0;32m      5\u001b[0m     \u001b[0mdataset_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSequentialSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TensorDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# TensorDataset combines prepared model inputs in a tensor for the model\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset_val, sampler=SequentialSampler(dataset_val), batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "## load the number of labels required for initial model\n",
    "NUM_LABELS = np.load(\n",
    "    \"./data/temp/training/{}/num_labels.npy\".format(train_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertForSequenceClassification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d0d659c73509>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = BertForSequenceClassification.from_pretrained(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnum_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_LABELS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BertForSequenceClassification' is not defined"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_type,\n",
    "    num_labels=NUM_LABELS,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=True,\n",
    ")\n",
    "\n",
    "## overwrite model parameters with finetuned parameters\n",
    "model.load_state_dict(\n",
    "    torch.load(\n",
    "        f\"./results/sentiment_analysis/training/{train_data}/BERT_{model_no}_epoch_{epoch}.model\"\n",
    "    )\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "## set model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    # track batch loss\n",
    "    val_loss_set = []\n",
    "    # initiate cumulative loss\n",
    "    loss_val_total = 0\n",
    "    # initiate arrays for predicted and true labels\n",
    "    predictions, true_vals = [], []\n",
    "    # evlaution loop\n",
    "    for batch in dataloader_val:\n",
    "        # add batch to GPU\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        # Unpack the inputs from  dataloader\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[2],\n",
    "        }\n",
    "        # Telling the model not to compute or store gradients,\n",
    "        # saving memory and speeding up validation\n",
    "        with torch.no_grad():\n",
    "            # forward pass: calculate logit predictions\n",
    "            outputs = model(**inputs)\n",
    "        # the output consists of the batch loss (index [0])\n",
    "        # and the predicted scores for all labels (index [1])\n",
    "        loss = outputs[0]\n",
    "        val_loss_set.append(loss.item())\n",
    "        logits = outputs[1]\n",
    "        # cumulative loss over all batches\n",
    "        loss_val_total += loss.item()\n",
    "        # send model outputs to cpu and transform to np.array\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs[\"labels\"].cpu().numpy()\n",
    "        # store predictions and true labels\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    # divide cumulative batch loss by number of batches\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    # predictions and true_vals are lists of arrays\n",
    "    # concatenate to create arrays of values\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "\n",
    "    return loss_val_avg, predictions, true_vals, val_loss_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-336549c89f74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# evaluate model in validation dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mwall_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate model in validation dataset\n",
    "start = time.time()\n",
    "val_loss, predictions, true_vals, val_loss_set = evaluate(dataloader_val)\n",
    "end = time.time()\n",
    "wall_time = end - start\n",
    "\n",
    "# compute and print validation loss and f1 score\n",
    "predictions_flat, labels_flat = flat_values(predictions, true_vals)\n",
    "val_f1 = f1_score(predictions_flat, labels_flat, average=\"weighted\")\n",
    "print(\"Validation loss: {}\".format(val_loss))\n",
    "print(\"F1 Score (Weighted): {}\".format(val_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8b94e5fee092>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions_flat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions_flat' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = predictions_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skplt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-564a38ab55c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# confusion matrix of validation data after final epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m skplt.metrics.plot_confusion_matrix(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscore_og\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Confusion Matrix\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m plt.savefig(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'skplt' is not defined"
     ]
    }
   ],
   "source": [
    "# confusion matrix of validation data after final epoch\n",
    "skplt.metrics.plot_confusion_matrix(\n",
    "    df[score_og], predictions, title=\"Confusion Matrix\"\n",
    ")\n",
    "plt.savefig(\n",
    "    \"./results/sentiment_analysis/evaluation/{}/conf_model_{}_epoch_{}.png\".format(\n",
    "        dataset, model_no, epoch\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "accuracy = np.sum(predictions_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# load or create a table where results for different models are stored\n",
    "# shall be used with one test set and differet models (model numbers)\n",
    "# helpful for hyperparameter tuning\n",
    "try:\n",
    "    evaluation_table = pd.read_csv(\n",
    "        \"./results/sentiment_analysis/evaluation/evaluation_table.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "except:\n",
    "    col_names = [\n",
    "        \"Model\",\n",
    "        \"Batch Size\",\n",
    "        \"Max Length\",\n",
    "        \"Optimizer\",\n",
    "        \"Learning Rate\",\n",
    "        \"Tolerance\",\n",
    "        \"n\",\n",
    "        \"validation loss (epoch 1)\",\n",
    "        \"validation loss (epoch 2)\",\n",
    "        \"validation loss (epoch 3)\",\n",
    "        \"validation loss (epoch 4)\",\n",
    "        \"f1 score (epoch 1)\",\n",
    "        \"f1 score (epoch 2)\",\n",
    "        \"f1 score (epoch 3)\",\n",
    "        \"f1 score (epoch 4)\",\n",
    "        \"data\",\n",
    "        \"training data\",\n",
    "        \"gpu\",\n",
    "    ]\n",
    "    evaluation_table = pd.DataFrame(columns=col_names)\n",
    "\n",
    "# insert values into the respective row of info table\n",
    "if epoch == 1:\n",
    "    evaluation_table.loc[model_no] = [\n",
    "        model_type,\n",
    "        BATCH_SIZE,\n",
    "        MAX_LEN,\n",
    "        \"AdamW\",\n",
    "        LR,\n",
    "        EPS,\n",
    "        n_val,\n",
    "        val_loss,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        val_f1,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        dataset,\n",
    "        train_data,\n",
    "        device_name,\n",
    "    ]\n",
    "elif epoch == 2:\n",
    "    evaluation_table.loc[model_no] = [\n",
    "        model_type,\n",
    "        BATCH_SIZE,\n",
    "        MAX_LEN,\n",
    "        \"AdamW\",\n",
    "        LR,\n",
    "        EPS,\n",
    "        n_val,\n",
    "        \"n/a\",\n",
    "        val_loss,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        val_f1,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        dataset,\n",
    "        train_data,\n",
    "        device_name,\n",
    "    ]\n",
    "elif epoch == 3:\n",
    "    evaluation_table.loc[model_no] = [\n",
    "        model_type,\n",
    "        BATCH_SIZE,\n",
    "        MAX_LEN,\n",
    "        \"AdamW\",\n",
    "        LR,\n",
    "        EPS,\n",
    "        n_val,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        val_loss,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        val_f1,\n",
    "        \"n/a\",\n",
    "        dataset,\n",
    "        train_data,\n",
    "        device_name,\n",
    "    ]\n",
    "elif epoch == 4:\n",
    "    evaluation_table.loc[model_no] = [\n",
    "        model_type,\n",
    "        BATCH_SIZE,\n",
    "        MAX_LEN,\n",
    "        \"AdamW\",\n",
    "        LR,\n",
    "        EPS,\n",
    "        n_val,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        val_loss,\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        \"n/a\",\n",
    "        val_f1,\n",
    "        dataset,\n",
    "        train_data,\n",
    "        device_name,\n",
    "    ]\n",
    "else:\n",
    "    print(\"Error: Check epoch\")\n",
    "\n",
    "evaluation_table.to_csv(\n",
    "    \"./results/sentiment_analysis/evaluation/evaluation_table.csv\", index=False\n",
    ")\n",
    "\n",
    "\n",
    "# plot evaluation performance\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title(\"Validation loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(val_loss_set)\n",
    "# plt.show()\n",
    "plt.savefig(\n",
    "    \"./results/sentiment_analysis/evaluation/{}/val_loss_{}_{}.png\".format(\n",
    "        dataset, model_no, epoch\n",
    "    )\n",
    ")\n",
    "\n",
    "# plot validation losses last 20\n",
    "l = n_val / BATCH_SIZE\n",
    "l1 = int(l - 20)\n",
    "l2 = int(l - 1)\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.title(\"Validation Loss - Last 20 Batches\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(val_loss_set[l1:l2])\n",
    "# plt.show()\n",
    "plt.savefig(\n",
    "    \"./results/sentiment_analysis/evaluation/{}/val_loss20_{}_{}.png\".format(\n",
    "        dataset, model_no, epoch\n",
    "    )\n",
    ")\n",
    "\n",
    "# createFolder('data/evaluated/')\n",
    "df.to_csv(\n",
    "    \"./data/processed/{}_wpredictions_{}_{}.csv\".format(\n",
    "        dataset, model_no, epoch\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
