{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09FrEZkpUv0F"
      },
      "source": [
        "***\n",
        "# Demo: BERT Fine-Tuning (pure)\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WrhLjZdVN49"
      },
      "source": [
        "*By Asmik Nalmpatian and Lisa Wimmer â€“ for Intro to NLP*\n",
        "\n",
        "*Methodology based on: https://arxiv.org/pdf/1810.04805.pdf*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shmCbiSwlDNV"
      },
      "source": [
        "![Logo_Consulting.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4RDgRXhpZgAATU0AKgAAAAgABAE7AAIAAAAHAAAISodpAAQAAAABAAAIUpydAAEAAAAOAAAQyuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5BTE1QSQAAAAWQAwACAAAAFAAAEKCQBAACAAAAFAAAELSSkQACAAAAAzQ1AACSkgACAAAAAzQ1AADqHAAHAAAIDAAACJQAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjAzOjIxIDIxOjQwOjE1ADIwMjE6MDM6MjEgMjE6NDA6MTUAAABOAEEATABNAFAASQAAAP/hCxlodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIxLTAzLTIxVDIxOjQwOjE1LjQ0OTwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5OQUxNUEk8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA9QHmAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+jy6g4Jo8xfX9KhmYKzMxwoGST2rg9Z8TXF7M0VnI0NsDgFThn9yf6VvRoSrO0Tnr4iFCN5HoJmjHVwKTz4v+ei/nXkZZiclmJ+tGW9TXb/Z/wDe/A8/+0v7v4/8A9c8+L/nov50efF/z0X868jy3qaMt6mn/Z/978A/tL+7+P8AwD1zz4v+ei/nR58X/PRfzryPLepoy3qaP7P/AL34B/aX938f+AeuefF/z0X86PPi/wCei/nXkeW9TRlvU0f2f/e/AP7S/u/j/wAA9c8+L/nov50efF/z0X868jy3qaMt6mj+z/734B/aX938f+AeuefF/wA9F/Ojz4v+ei/nXkeW9TRlvU0f2f8A3vwD+0v7v4/8A9c8+L/nov50efF/z0X868jy3qaMt6mj+z/734B/aX938f8AgHrnnxf89F/Ojz4v+ei/nXkeW9TRlvU0f2f/AHvwD+0v7v4/8A9c8+L/AJ6L+dHnxf8APRfzryPLepoy3qaP7P8A734B/aX938f+AeuefF/z0X86PPi/56L+deR5b1NGW9TR/Z/978A/tL+7+P8AwD1zz4v+ei/nR58X/PRfzryPLepoy3qaP7P/AL34B/aX938f+AeuefF/z0X86PPi/wCei/nXkeW9TRlvU0f2f/e/AP7S/u/j/wAA9c8+L/nov50vnxHo4/OvIst6mjcw7kfjS/s/+9+Af2l/d/H/AIB695i+v6UB1JwDXnGk+I7rT5VWZ2nt+jIxyVHqDXoFtKk6xyxMGRxuUjuMVx1qEqL1O+hiIV1puWaKKK5zpCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAMPxTM0Oh3RQ4LAJn2JGa4fR7Nb/AFa3tpPuO3zY7gDJ/lXaeL/+QFP/ALyfzrlPDH/Ix23/AAL/ANBNethXy4eUl5/keNi1zYqEXtp+Z3sdtBDGI4oY0RRgAKOKf5Uf9xf++RTqK8q7PYshvlR/3F/75FHlR/3F/wC+RTqKLsLIb5Uf9xf++RR5Uf8AcX/vkU6ii7CyG+VH/cX/AL5FHlR/3F/75FOoouwshvlR/wBxf++RR5Uf9xf++RTqKLsLIb5Uf9xf++RR5Uf9xf8AvkU6ii7CyG+VH/cX/vkUeVH/AHF/75FOoouwshvlR/3F/wC+RR5Uf9xf++RTqKLsLIb5Uf8AcX/vkUeVH/cX/vkU6ii7CyG+VH/cX/vkUeVH/cX/AL5FOoouwshvlR/3F/75FHlR/wBxf++RTqKLsLIb5Uf9xf8AvkUeVH/cX/vkU6ii7CyG+VH/AHF/75FNeCGRCrxIykYIKg5qSii7CyPOvEFjHp2sSQwDEbAOo/u57V1ng2ZpdFRW58uRlH06/wBa53xh/wAh8/8AXFf61veCf+QQ3/XZv5CvVrtywsW/I8fDpRxckttTpqKKK8k9kKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5/xf/yAp/8AeT+dcp4Y/wCRjtv+Bf8AoJrq/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAqOe4htojJcSLEg/iY4rH1rxLDpu6C3Amue4/hT6/4Vxd5fXN/MZbuVpG7Z6D6DtXbQwk6nvS0RwYjGwpPljqzrbzxlaRErZxPcH+8flX/GsefxfqcufL8qEf7KZP61hUV6UMLRj0ueVPGVp9behpN4h1ZjzeyD6AD+lKniPVkPF45/3gD/SsyitvZU/5V9xj7ar/ADP7zorfxlfRkfaIoph3wNprasfFen3ZCzFrZz2k+7+dcHRWE8HSlsrHRTxtaG7v6nq6sGUMpDKeQQetLXm+ma1eaW48h90WeYn5U/4V3OlaxbatDugO2RR88TdV/wAR715dfCzpa7o9bD4uFbTZl+iiiuU7AooooAKKKKACiiigAooooAKKKKAOE8Yf8h8/9cV/rW94J/5BDf8AXZv5CsHxh/yHz/1xX+tb3gn/AJBDf9dm/kK9Wt/ukfkePR/32XzOmoooryj2AorM1bWo9LmgRl3mQ5cDqq+taEM0c8KywsHRhkMO9W6clFSa0ZEakZScU9UPoooqCwooooAKKKKACiiigAooooAKKKKACiisDV/EqWzNBY4klHBkPKr/AImtKdKdWXLFGVWrClHmmzauLmG1j33Eqxr6scVjXPiy0iJFtHJOfX7orlLi5mupTJcSNI57sair1qeAgvjdzx6uYzfwKx0Eni+6P+rt4VHuSaYPFt8DzFAf+An/ABrCorp+q0f5Tl+t1/5jpofGDZ/f2gI9Uf8AxrVtPEOn3ZCiXynP8Mox+vSuEorKeBoy20NoY+tHfU9OByMjkUVwOn6zeacwEUm+PvG/I/8ArV12mazbamuEPlzAfNGx5/D1rzK2EnS13R6tDGU62mzNCioJ721th+/uI4/ZmGay7rxVZQ5FuHuG9htH5msYUak/hRvOtTp/FI26jFxE1wYFkUyqMlQckD3ri73xHfXeVV/Ij/ux9fzrofDunGysPMmGJpzubPUDsK3qYZ0oc03r2OenilWqctNadWa9FFFcZ2nP+L/+QFP/ALyfzrlPDH/Ix23/AAL/ANBNdX4v/wCQFP8A7yfzrlPDH/Ix23/Av/QTXq4f/dZ/P8jx8V/vcPl+Z6FRRRXlHsBXOeJPEBslNnZN/pDD53H/ACzHp9a0tb1MaVprTDBlb5YlPc+v4V507tLIzyMWdjlie5r0MHh1N88tjzcbiXTXs4bsaSSSSck9SaKKK9k8IKKKKACiiigAooooAKltrmW0uFmt3KSKcgioqKGk1ZjTad0ejaLrEer2m4YSZOJE9Pce1aVeY6bfy6bfJcw/w8Mv95e4r0q3njureOeE7kkUMprwsVQ9lK62Z9Dg8R7aNpbokooorjO0KKKKACiiigAooooAKKKKAOE8Yf8AIfP/AFxX+tb3gn/kEN/12b+QrB8Yf8h8/wDXFf61veCf+QQ3/XZv5CvVrf7pH5Hj0f8AfZfM6aiiorqTybOaQfwIzfkK8tK7seu3ZXOF1m7+2atPJnKq2xfoOKk0fWZdLl2tl7dj8yenuKzM55PWivpnSi4eza0PlVWmqntE9T0m3uYruBZrdw6N0IqWvPdO1O40ybfA2VP34z0au103VbbU4swttkA+aNuo/wAa8TEYWVJ3WqPew2LjWVnoy7RRRXGdoUUUUAFFFFABRRRQAUUVn61qH9naa8in963yx/X1/CqhFzkorqROahFyfQyfEWtlWaxs2wekrg9P9kVy9KSWJJOSTkk96SvpKNKNKPLE+YrVpVp80gooorUxCiiigAooooAKUEg5BwfUUlFABRRWrpv9lW22e/laaQciFEJA+vrUzlyq9rlwhzu17F3w/oRmdby8XEQ5jQ/xH1PtXWVzk3i+FRi3tXb03kL/AI1UTW9W1W5FvZ7Ii3XYv3R6kmvIq0a9aXPPRHs0q2HoR5Iavy6nXUVBZ232W3CGRpX6vI5yWNFec7J6Hpq7WpjeL/8AkBT/AO8n865Twx/yMdt/wL/0E11fi/8A5AU/+8n865Twx/yMdt/wL/0E16mH/wB1n8/yPIxX+9w+X5noVFFQ3k/2WymnP/LNC35CvLSu7HrtpK7OH8U3/wBs1ho1OYrf5F579z/n0rFpWYuxZuWY5J96SvpacFCCiuh8rUm6k3J9QoooqzM3fDehJqkjz3Wfs8ZxtBxvPp9Kv+IPDVvBZNd6ehQxDLx5JBHqK1vC8YTw7blR97cx+uTWnNGJYJI26MpU/iK8WpiZqu2nome9SwlN0EmtWtzyqlVS7BVGWY4AHc0hGCR6Vo6BGsuv2ivyPMzj6DNexKXLFy7HhwjzSUe51Fj4TsY7MLeoZZ2HzNuI2n0GK5XWdMbStQaAktGRujY9xXpNct43iHk2kv8AEGZfwxmvJwuInKraT3PaxeGpxo3irWOQooor2Dwwrr/Bl+WjlsZD9z95H9O4/wA+tchV/Q7r7JrVtJnCl9jfQ8VhiKftKTR0Yap7Oqmek0UUV86fThRRRQAUUUUAFFFFABRRRQBwnjD/AJD5/wCuK/1re8E/8ghv+uzfyFYPjD/kPn/riv8AWt7wT/yCG/67N/IV6tb/AHSPyPHo/wC+y+Z01VtRUvpdyo6mJv5VZpGUMpVuhGDXlxdmmetJXTR5lRU11A1rdywP1jYrUNfVJpq6PkmmnZhT45HhkWSJ2R1OQynBFMooFsdRpnioHbFqQwennKP5j/CukilSaMPE6uh6MpyDXmdWbO/ubGTfaysnqOoP1FedWwMZaw0f4Hp0MwlDSpqvxPRaK5yx8WRPhb+Ixt/fTkfl1ret7qC6j320qSL6qc15dSjUp/Ej16denVXuMlooorE2CiiigArj/FdyZNSSAH5YU6e5/wDrYrsK4DW2L65dE9nx+Qr0MBG9W/ZHnZjJqkl3ZQooor2zwAooooAKKKKACiiigAooooAKKK1NG0V9VZnLiOFDhj3J9BUznGEeaWxcISqS5YrUqWNhPqFwIrdcn+Jj0UepruNM0yHTLfy4huc/fkI5Y1NaWcFjAIraMIo/M+5qevCxGKlW0WiPfwuEjRXM9ZBRRRXGdxz/AIv/AOQFP/vJ/OuU8Mf8jHbf8C/9BNdX4v8A+QFP/vJ/OuU8Mf8AIx23/Av/AEE16uH/AN1n8/yPHxX+9w+X5noVZHiiQx+HrjH8W1fzIrXrE8W/8i/J/wBdF/nXBQ1qx9T0cQ7UZejOCooor6M+XCiiigB6zSquFkdR6BiKXz5v+e0n/fZqOilZDuwpQxVsqSCOhBxU0djdyrmO1mYeojJpstrcQf6+CSMf7aEUc0XpcfLJK9hPPm/57Sf99mmtI7/fdmx03MTTaKLIV2FFABJAAyT0A71vab4TvLsCS6P2aI9mGWP4dvxqZ1IU1eTLp0p1HaCuYNTW9tcTODbQSSEHI2ITXfWXhzTbLBEAlcfxy/N+nStNQFUKoCgdABivPnj47RR6VPLpbzlYEJKKSMEgZBpaKK8k9kKKKKACiiigAooooAKKKKAOE8Yf8h8/9cV/rW94J/5BDf8AXZv5CsHxh/yHz/1xX+tb3gn/AJBDf9dm/kK9Wt/ukfkePR/32XzOmoooryj2Dl/FWmnct/EOOFlx29D/AE/KuZr0ySNJY2jkUMjDBB7iuG1nR5NMnyuWt3PyP6exr2cFiFJezlv0PDx2GcZe1js9zMooor0jywooooAKfHI8Th4nZGHQqcGmUUAbFt4m1C3wJGWdf+mg5/MVrW/i62fi5gkiPqvzCuRormnhaM90dcMZWhs/vPQINa064x5d3GD6Odp/WrqurjKMGHqDmvMqckjxnMbsp/2TiuWWXR+zI645lL7UT0yuE8QxGLXJ/R8OPxFQR6rfxfcvJh7F8/zqK6vJ72QSXUnmOo2gkAcVphsLOjPmvdGeKxcK9PlSsyCiiiu880KKKKACiiigAooooAKKKKACuv8ACK402Y+sv9BXIV2vhZNuig/3pGP9P6VxY52o/M78vV6/yNmiiivBPoQooooA5/xf/wAgKf8A3k/nXKeGP+Rjtv8AgX/oJrq/F/8AyAp/95P51ynhj/kY7b/gX/oJr1cP/us/n+R4+K/3uHy/M9CrM8Rwmfw/dAdVUP8Akc1p0yaJZ4Xif7rqVP0NebCXLJS7Hq1I88HHueVUVJPC1vcSQyDDRsVP4VHX0yd9T5Rqzswoop0cbSyLHGMs5CqPUmgRc0vSrjVrryoBtVeXkPRRXcadoNjpyjy4hJL3lkGSf8Km0vTo9M09LeMDcBl2/vN3NXK8LEYqVR2jsfQ4bCRpRvJXkFIwDKVYBgeoIzmlorjO4wdV8LWt4rSWYFvP14+631Hb8K5KHSb2bUTZLCRMp+YHoo9SfSvS6QKoYsFAY8E45NdlLGVKcWnqcNbBU6klJadzK0jw/a6WocgTXHeRh0+g7VrVFdXUNnbtNcyCONepNcVq3im5vS0VmWt4OmQfmb6ntUwp1cTK/wCJdSrSwseX8Dqb/XbDTsrPMGk/55x/M3/1qwbnxrISRZ2iqP70rZP5CuWor0qeCpR+LU8qpj6svh0NiTxVqznidU9ljFRjxJqwP/H43/fK/wCFZdFdHsaS+yvuOb29V/af3m5D4t1SM/O0co9GTH8q1LTxrExC3ts0f+3Gdw/KuPorOWFoy6GkMXWh9r7z1C0v7W/j32kyyDuAeR9RVivKoZpLeUSQSNG69GU4NdZo3iwSMsGqYVjwsw4B+vp9a8+tgpQ1hqj06GPjN8s9H+B1NFAORkcg9DRXnnpBRRRQBwnjD/kPn/riv9a3vBP/ACCG/wCuzfyFYPjD/kPn/riv9a3vBP8AyCG/67N/IV6tb/dI/I8ej/vsvmdNUV0WFnMYzhxG20jscVLQRkEHoa8tOzueu1dWOQtPFl1GALqJZx/eHyt/hWl/wkel3kJiu0dVYYZXTI/SuUu4DbXk0LdY3K1DXvywlGfvJW9D52OMrw91u/qXtRtrSGTfYXSzQseF6Mv+NUaKK6oppWbuckmpO6VgooopkhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXf6HF5OiWqnglN358/1rg44zLKka9XYKPxr0mNBFEka9FUKPwrzMwl7sYnrZbH3pSHUUUV457QUUUUAc/4v/5AU/8AvJ/OuU8Mf8jHbf8AAv8A0E11fi//AJAU/wDvJ/OuU8Mf8jHbf8C/9BNerh/91n8/yPHxX+9w+X5noVFFFeUewcX4w04w3q3sY+Sbh/Zh/iP5VzdeoX1nHqFlJbTD5XHX+6exrza9s5bC8e3uBh0PXsR6ivbwdZThyPdHg46g4T51s/zIKs6ddrY6hFcvF5oiO4JnGT2qtRXa0pKzPPi3F3R1v/CcD/nwP/f3/wCtR/wnA/58D/39/wDrVyVFc31Oh2/M6/rtf+b8Edb/AMJwP+fA/wDf3/61A8bbmCrp5JJwAJev6VyVdD4R00XN813KMx2/3c93/wDrVnUw9CnBya/M1pYnE1ZqClv5I7SFneFGlTy3IyyZztPpmmXV1FZWr3Fw22NBkn19qmrhPE+rm/vjbwt/o8Bxx/E3c/0rzKFF1p26Hq4iuqFO/Upavq8+rXW+QlYlP7uPPCj/ABrPoor34xUVyxPm5SlOXNLcKKKKokKKKKACiiigAooooA6Pw54hNo62d6+YGOEcn/Vn0+n8q7WvJ67bwpq5u7Y2Vw2ZYRlCf4l/+tXlYzDpL2kfmexgcS2/ZT+X+R0VFFFeWeucJ4w/5D5/64r/AFre8E/8ghv+uzfyFYPjD/kPn/riv9a3vBP/ACCG/wCuzfyFerW/3SPyPHo/77L5nTUUUV5R7ByXiuxMd0l4g+SQbX9mHT9P5Vz1ekXdrHe2r28wyjjH0964C/sZtPu2gnHI5VuzD1Fe5gq6nDke6PAx1Bwn7RbP8ytRRRXeecFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAGp4dtvtOtRZHyxZkP4dP1xXdVz/hO08uzkumHMrbV+g/+v/KugrwcbU56rXY+iwNPkopvrqFFFFcR3BRRRQBz/i//AJAU/wDvJ/OuU8Mf8jHbf8C/9BNdX4v/AOQFP/vJ/OuU8Mf8jHbf8C/9BNerh/8AdZ/P8jx8V/vcPl+Z6FRRRXlHsBWZreixavbY4S4Qfu5P6H2rToqoylCXNHcicIzjyy2PLLq1ms7hoLlCki9Qf51FXpmo6Va6pD5d0nI+644ZfpXF6n4avdPJeNTcQj+NByPqK9uhi4VFaWjPBxGDnSd46ox6KKK7DhCvR9Bs/sOiwRkfOy73+p5rgdPt/tWpW8HXzJFB+mea9P8ApXmZhPRQPWy2Gsp/IzPEF/8A2fo8rocSyfu0+p7/AJV51XS+NLrffQWwPEabyPc//WFc1W+Dp8tK/c58dU561uwUUUV2HCFXYtH1Ce1+0RWsjRYyGA6j2HejSLMX+rW9u/3GbLfQcmvSlAVQqgAAYAHauLE4l0WoxWp34XCKunKT0PKKK3PFditpq/mRrhLhd+B/e71h11U5qpBSXU5KkHTm4PoSQQS3MyxQRtJI3RVHJqa802708r9sgaLd0J6H8a6nwbZLHYyXjDMkrFFPoo/+vW1qlkmoabNbuASykqfRh0NcVTGclXktod9PA89Hnvq9jzKijGOD1or0DzAqxYXj2F9Fcx9Y2yR6juPyqvRSaTVmNNp3R6tHIssSSRnKuoZT6g06sXwrdG40KNW+9Cxj/DqP51tV81UjyTcex9VTn7SCl3OE8Yf8h8/9cV/rW94J/wCQQ3/XZv5CsHxh/wAh8/8AXFf61veCf+QQ3/XZv5CvSrf7pH5Hl0f99l8zpqKKK8o9gKqahp0GpW/lTjkcq46qat0VUZOLuiZRUlaWxwOpaPdaaxMi74s8SqOPx9Kz69EGo2Mu5PtMJIJVlZgPwway73RtHny6zx2zeqSDH5V69LGParE8WrgVvSkrHH0VcvrO3tWxBfR3PPRVPH49Kp16MZKSujzZRcXZhRRRTJCiiigAooooAKKKKACiiigAooooAKKKKACiiigAqSCF7m4jhjGXkYKKjrpfCmn7ne+lXhfljz69z/T86yrVFSg5G1Ck6tRQR0ltAlraxwR/djUKKloor5ptt3Z9SkkrIKKKKQwooooA5/xf/wAgKf8A3k/nXKeGP+Rjtv8AgX/oJrq/F/8AyAp/95P51ynhj/kY7b/gX/oJr1cP/us/n+R4+K/3uHy/M9Coooryj2AooooAKKKKAKF5oun3xJuLZd5/jX5W/MVkT+CrdmJt7qSMejqG/wAK6aitoV6sPhZhPD0qmsonNaZ4Vl0/VIrprmORIyTtCkHpiulooqalWVV3kVSpQpLlged+JJPN8Q3X+ywX8gKy6v65n+3rzP8Az1NUK+hpK1OK8kfNVnepJ+bCiiitDIv6LqCaXqS3MsbSKFI2qeea6P8A4Ta1/wCfOb/voVxtFc9TD06kuaSOmliatKPLB6Gxr+tRaw0BiheLygQd5BznHpWPRRWsIRhHljsY1JyqScpbnS6R4og03TI7WS2kdkJyysMHJzV3/hNrX/nzm/76FcbRWEsJSk22jpjjK0YqKew523SMw4BJOKbRRXUcYUUUUAdb4IkO28izxlWA/MV1dcf4J/4+bv8A3F/ma7CvBxitWZ9HgnehH+upwnjD/kPn/riv9a3vBP8AyCG/67N/IVg+MP8AkPn/AK4r/Wt7wT/yCG/67N/IV1Vv90j8jjo/77L5nTUUUV5R7AUUUUAcd4o077Pffao1/dz9fZv/AK/+NYWK9HvLSK+tXt5hlXHX0PrXBX9hNp100M491bsw9RXuYOupw5HujwMdh3TnzrZlWiiiu884KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiilALMAoJJOAB3oAsWNnJf3iW8XVjyf7o7mvQbeBLW3SGEYRBgCs7QdJGm2m+Uf6RKMv8A7I9K1a8HGV/az5Y7I+hwWH9lDmluwoooriO8KKKKACiiigDn/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmur8X/wDICn/3k/nXKeGP+Rjtv+Bf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigDz3xPF5XiG4/29rj8RWTXVeNbQiS2u1HBBjY+/Uf1rla+iw0ualFnzOKhyVpIKKKK3OYnSyupUDxW0zqejLGSDTv7Ovf8Anzn/AO/R/wAK63wdfCXTntGPzwNkDPVT/wDXros15tXGTpzcXE9WjgYVYKalueYf2de/8+c//fo/4Uf2de/8+c//AH6P+Fen5ozWX9oS/lNf7Nj/ADHmH9nXv/PnP/36P+FH9nXv/PnP/wB+j/hXp+aM0f2hL+UP7Nj/ADHlctvPb48+GSPd03qRn86jrd8WXwu9X8lDlLddn/Au/wDhWFXp05OcFJrc8qrFQm4xd7BRRRWhkdf4JhIgu5j0ZlQfgM/1rqayvDdp9k0KAMMNJmRs+/T9MVq187iJc9WTPp8NDkoxTOE8Yf8AIfP/AFxX+tb3gn/kEN/12b+QrB8Yf8h8/wDXFf61veCf+QQ3/XZv5Cu6t/ukfkefR/32XzOmoooryj2AooooAKrX1hBqNuYrlcj+Fh1U+oqzRTjJxd0KUVJWZwupaBd6eSyqZoezoOn1HasuvTqoXeiWF4S0sAVz/GnymvUpZhpaojya2XXd6b+TOAorqZ/B6E5trpl9pFz+orD1HTTpsgje4ilfuqE5X61308RSqO0XqedUw1WkryWhSooorc5wooooAKKKKACiiigAooooAKKKKACuq8OaIY9t9drh+sSHt7mo9B8P5K3d+nHWOIj9T/hXUV5WLxX/AC7h8z2MHhP+XlT5IKKKK8k9gKKKKACiiigAooooA5/xf/yAp/8AeT+dcp4Y/wCRjtv+Bf8AoJrq/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigClq1gNS0ua3/iIyh9GHSvNWVkYq4KspwQexr1euP8WaOY5TqNuvyP/rgOx/vfjXo4Gtyv2b6nl4+g5R9pHocvRRRXsHiFmwvpdOvUuYD8y9QejDuDXoem6nb6pbCW2bn+ND1Q+9eZ1Jb3E1rMJbaRonHRlOK5cRhlWV9mdmGxUqDtuj1SiuLtfGd3GoW6gjn/ANoHaf8ACrJ8brt+WxOfeT/61eW8HWT2PWWOoNXudXWHr/iCPToWt7Zg90wxxz5fuff2rnr7xXqF2pSIrbIf+ef3vzrEJJJJOSepNdVHAtPmqfcclfHprlpfeKSSSScknJJ70lFFeoeQFXtH086lqkUGPkzukPoo6/4VSALEBRkk4AHeu/8ADmkf2XY7ph/pE2C/+yOy1zYmsqUPNnXhaDrVPJbmuAFAAGABgCloor58+kOE8Yf8h8/9cV/rW94J/wCQQ3/XZv5CsHxh/wAh8/8AXFf61veCf+QQ3/XZv5CvVrf7pH5Hj0f99l8zpqKa8iR48x1XPTccZpPOi/56J/30K8uzPXuh9FRm5gX700Y+rCoX1Oxj+/dwj/gYpqMnshOcVuy1RWXL4k0yLpOZD6IpNZ1x4vQZFras3oZGx+graOGrS2iYSxVGO8jpaqXmqWdgv+kzKrdkHLH8K4+68QahdZBm8pT/AAxDH69azSSSSSST1Jrtp5e96j+44amZLamvvN3UfFFxc5jswYI/738R/wAKwiSSSTknqT3pKK9KnShTVoo8upVnVd5u4UUUVoZBRRRQAUUUUAFFFFABRRV/TtHutSbMS7Ys8yN0/D1qZSjBXk7FRhKb5Yq7KUcbyyKkal3Y4CqMk11ujeHFtttxfAPN1WPqE/xNaGm6PbaYn7pd8pHzSN1P+FX68fEY1z92noj28NgVD3qmrCiiivOPTCiiigAooooAKKKKACiiigDn/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmur8X/wDICn/3k/nXKeGP+Rjtv+Bf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigAproskbJIoZWGCCOCKdRQBwWveH5NNkM9sC9ox69TH7H296xK9XZQ6lWAKkYII61y+reEQ5abSyEPUwsePwPb6V62Hxia5an3njYnAtPmpfcchRUtxbTWspjuYmicdmGKir0001dHlNNOzCiiigQUUUUAFABJAAyT0Aq5YaTeak+LWEle8jcKPxrs9H8OW2mYlkxPc/wB8jhfoP61zVsTCktdX2OqhhalZ6aLuUvDnhw2xW9v1/fdY4z/B7n3rpqKK8OpUlVlzSPoKVKNKPLEKKKKzNThPGH/IfP8A1xX+tb3gn/kEN/12b+QrB8Yf8h8/9cV/rW94J/5BDf8AXZv5CvVrf7pH5Hj0f99l8zo5YY54zHMiyIeqsMiufv8AwnE+X09/LP8AzzflfwPUV0dFefTrTpP3WelVo06qtNHnV3p11Yti6gZB2bGVP41Wr01lDKVYAg9QR1rKu/Den3WWWMwOe8ZwPy6V6dPME9KiPLq5bJa0395w9Fb9z4Tu48m2lSYeh+U/4VlXGm3trnz7aRR67cj8xXdCtTn8Mjz50KtP4olWiiitTEKKKKACiiigAooooAKKtW+nXl1/qLaRx67cD8zWra+E7qTBupUhX0HzH/Csp1qcPiZtChVqfDEwKuWWl3l+3+jwkr3duFH411tn4dsLTDGMzOP4pef06VqgBQABgDoBXBUzBbU0ehSy5vWo/uMHT/C1vb4e8b7RJ/d6KP8AGt1VCqFUAAdAB0paK8ypVnUd5M9WnShSVoKwUUUVmahRRRQAUUUUAFFFFABRRRQAUUUUAc/4v/5AU/8AvJ/OuU8Mf8jHbf8AAv8A0E11fi//AJAU/wDvJ/OuU8MHHiK2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigAooooAKKKKAIp7aC6j2XMSSr6Ouaxbnwfp8xJgaS3J7Kcj8jW/RWkKs4fC7GU6NOp8auchJ4IlH+qvUP+8hFRDwTeZ5uoMfRv8K7Siuj65W7nP9RodvxOTi8Ec/v73j0SP/E1q2nhjTLU7jCZ29ZTn9Ola9FZyxNWW8jSGFow1URFUIoVAFUdABgCloornOkKKKKACiiigDhPGH/IfP8A1xX+tb3gn/kEN/12b+QrB8X/APIfP/XFf61veCf+QQ3/AF2b+Qr1a3+6R+R49H/fZfM6aiiivKPYCiiigAooooAglsbWf/XW8T+7IKpyeHdMk/5d9h/2GIrTorSNScfhbM5UqcviijDbwnYH7rzL/wACB/pUZ8IWva4mH5f4V0FFaLFVl9oyeEoP7Jz48IWve4m/T/CpF8J2A+887f8AAgP6VuUUfWqz+0CwlBfZMuPw5pkf/Lvv/wB9yauw2NpB/qbaJPcIKnorOVWct2zWNKnH4YoKKKKzNAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAM3WbP+0NOuLYfedfl+o5FebRSzWV4siZjmhfPI6EV6pJ/rDWLq3hy11RjKCYJ+7qMhvqK7sLiI07wnszz8ZhpVbThujOj8bR+WPOs33452OMfrTv+E2t/wDnzl/76FUm8FXYb5bqAj3BFJ/whV7/AM/MH6/4VvyYPv8Amc3Pju35F7/hNrf/AJ85f++hR/wm1v8A8+cv/fQqj/whV7/z8wfr/hR/whV7/wA/MH6/4UcmD7/mPnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KR/G0O0+XZSFu25xiqX/CFXv/AD8wfr/hSjwVeZ5uoAPoaOTB9/zDnx3b8jCvLubULx7ibmSQ9AOnoBXoXh2xbT9KghkGJGy7j0J7VS0rwvbadIJpm+0TrypIwq/QVvR/6wVjisRGaUIbI3wmGlTbqVN2T0UUVwHohRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//2Q==)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxj_Yq-iWJxb"
      },
      "source": [
        "This notebook is supposed to give an overview over the used functionalities. We will show how to use BERT - Bidirectional Encoder Representations from Transformers - with PyTorch library (huggingface) to fine-tune a pretrained model in tweet classification. \n",
        "\n",
        "The following pretrained BERT models can be used and are available in transformers huggingface: \n",
        "\n",
        "*   *bert-base-german-cased*\n",
        "*   *bert-base-german-dbmdz-cased*\n",
        "*   *bert-base-german-dbmdz-uncased*\n",
        "*   *distilbert-base-german-cased*\n",
        "\n",
        "After using these models to extract (hopefully) high quality features from our text data, we aim to fine-tune them on our specific task using a manually labeled sample of German tweets to gain state of the art predictions.\n",
        "\n",
        "All in all the tweets will be classified into *positive* and *negative* classes using a pretrained BERT model. We will take it, add an untrained layer of neurons on the end and train a new model specifically for the classification task. \n",
        "\n",
        "\n",
        "Advantages of fine-tuning:  \n",
        "\n",
        "*   Fast, because we already have pretrained layers of the network (only 2-4 epochs after adding 1 fully connected layer on top are enough to train as the authors recommend)\n",
        "*   Less data is sometimes enough to achieve good performance\n",
        "*   Usually preferable results: because of task-specific adjustments of the weights\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGC297qbdzRf"
      },
      "source": [
        "## Prepare GPU\n",
        "\n",
        "1. Check: Edit --> Notebook settings -> Hardware accelerator -> *GPU* \n",
        "\n",
        "2. You will need access to the following files: *data_germeval_2017.tsv*, *data_labeled_processed.csv*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA2b3QYDMKSG"
      },
      "source": [
        "## Data\n",
        "\n",
        "1. On the left command pane, move to the `Files` section.\n",
        "2. Select 'Upload to the session storage'.\n",
        "3. Upload the `data_germeval_2017.tsv` and `data_labeled_processed.csv` data from the course website (the data will vanish as soon as you terminate the colab session)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv04gWs2Yheg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac35e03-3a9a-44bf-d901-6eafe303bb66"
      },
      "source": [
        "# Where are you now?\n",
        "import os, sys\n",
        "print(\"My current working directory is in folder: \", os.getcwd(), \".\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My current working directory is in folder:  /content .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26YQ5UYt1aGw"
      },
      "source": [
        "## Google Colab GPU Connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY5QDtKc4pCe"
      },
      "source": [
        "Otherwise training a large NN may take a very long time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpojrKi87B0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f077eba0-abb0-4873-c7c8-455ea2b8c46c"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLk647UpAUMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e39dfa8-dbef-4920-a51a-bc93a91c4401"
      },
      "source": [
        "# Identify and specify the GPU as the device\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLhki6Q67HB5"
      },
      "source": [
        "## Fine-Tuning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV4Ao1h59Tbj"
      },
      "source": [
        "Install Huggingface Library / transformers package and specify the pretrained transformer model. (Uncased means that the texts have only lowercase letters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtnIk5ybq1v6"
      },
      "source": [
        "### Load pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ynJrSjrQLQu"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "pretrained_model = \"bert-base-german-cased\"                                          \n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_model) # Additionally do lower case for pretrained uncased models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr-IYbltg_em"
      },
      "source": [
        "### Pre-process data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKXUHB8CIoNV"
      },
      "source": [
        "Load and prepare the tweets and labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNnv3aRgczlM"
      },
      "source": [
        "# Prepare path to the dataset contaning tweets\n",
        "filename_tweets = \"data_labeled_processed.csv\"                                                    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ejwgMfT7D-x"
      },
      "source": [
        "# Load the dataset into a pandas dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv(filename_tweets, delimiter = ',', header = 0)                                    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeDjf_3ndl4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f0ff3b-d531-4de6-bc78-0a7439204a5c"
      },
      "source": [
        "# Look at the shape of the dataframe\n",
        "df.shape                                                                                         "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(498, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mryi3QOLdjQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "d6bc8a3c-c866-412b-fa8b-a431c1128873"
      },
      "source": [
        "# Look at the first rows of the dataframe\n",
        "df.head()                                                                                        "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>twitter_username</th>\n",
              "      <th>twitter_available</th>\n",
              "      <th>twitter_created_at</th>\n",
              "      <th>twitter_full_text_topic</th>\n",
              "      <th>twitter_full_text</th>\n",
              "      <th>twitter_retweet_count</th>\n",
              "      <th>twitter_favorite_count</th>\n",
              "      <th>twitter_followers_count</th>\n",
              "      <th>twitter_location</th>\n",
              "      <th>twitter_word_count</th>\n",
              "      <th>twitter_year</th>\n",
              "      <th>twitter_month</th>\n",
              "      <th>twitter_week</th>\n",
              "      <th>twitter_time_index_month</th>\n",
              "      <th>twitter_time_index_week</th>\n",
              "      <th>twitter_emojis</th>\n",
              "      <th>twitter_hashtags</th>\n",
              "      <th>twitter_tags</th>\n",
              "      <th>label</th>\n",
              "      <th>topic</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABaerbock15156546001</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-01-11T07:10:00Z</td>\n",
              "      <td>Habe mir das Gro Ko-Sondierungspapier zu Klima...</td>\n",
              "      <td>Habe mir das Gro Ko-Sondierungspapier zu Klima...</td>\n",
              "      <td>111</td>\n",
              "      <td>233</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>32</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#GroKo|#Klima|#Klimadiplomatie|#Merkel|#kohlea...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>239</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABaerbock15210084001</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-03-14T06:20:00Z</td>\n",
              "      <td>Auch weltweit sieht man, dass Angela Merkel s ...</td>\n",
              "      <td>Auch weltweit sieht man, dass Angela Merkel s ...</td>\n",
              "      <td>24</td>\n",
              "      <td>96</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>27</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Merkel|#GroKo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>203</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABaerbock15216341401</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-03-21T12:09:00Z</td>\n",
              "      <td>Der groessten globalen Herausforderung, der Kl...</td>\n",
              "      <td>Der groessten globalen Herausforderung, der Kl...</td>\n",
              "      <td>39</td>\n",
              "      <td>153</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>38</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Klimakrise|#Regierungserklaerung|#Koalitionsv...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>284</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABaerbock15252349801</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-05-02T04:23:00Z</td>\n",
              "      <td>Wir brauchen eine andere Verkehrspolitik - weg...</td>\n",
              "      <td>Wir brauchen eine andere Verkehrspolitik - weg...</td>\n",
              "      <td>49</td>\n",
              "      <td>213</td>\n",
              "      <td>94139</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>38</td>\n",
              "      <td>2018</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Verkehrspolitik</td>\n",
              "      <td>25</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABaerbock15256297201</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-05-06T18:02:00Z</td>\n",
              "      <td>Das ist die Leistung von Hunderten Wahlkaempfe...</td>\n",
              "      <td>Das ist die Leistung von Hunderten Wahlkaempfe...</td>\n",
              "      <td>39</td>\n",
              "      <td>301</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>40</td>\n",
              "      <td>2018</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#kwsh|#kow18|#Kommunalwahl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>positive</td>\n",
              "      <td>Kommunalpolitik</td>\n",
              "      <td>251</td>\n",
              "      <td>266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 doc_id twitter_username  ...  from   to\n",
              "0  ABaerbock15156546001        ABaerbock  ...   239  251\n",
              "1  ABaerbock15210084001        ABaerbock  ...   203  215\n",
              "2  ABaerbock15216341401        ABaerbock  ...   284  296\n",
              "3  ABaerbock15252349801        ABaerbock  ...    25   40\n",
              "4  ABaerbock15256297201        ABaerbock  ...   251  266\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUb6n3OueE5u"
      },
      "source": [
        "# Convert labels to numeric: 1 for \"positive\", 0 for \"negative\" and call the column \"label_binary\"\n",
        "df['label_binary'] = [1 if label == \"positive\" else 0 for label in df.label]                      "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWqiYQB_dlBw"
      },
      "source": [
        "# Drop NA values in the column \"label\"\n",
        "df = df.dropna(subset=['label'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrOvWVj0dolR"
      },
      "source": [
        "# Get the lists of tweets and their labels.\n",
        "tweets = df.twitter_full_text.values\n",
        "labels = df.label_binary.values"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_4pZEWFfT90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1c938907-a540-42da-da03-5a94ac83dcaf"
      },
      "source": [
        "# Print the second tweet in the dataframe (Take care of right indexing!)\n",
        "tweets[1]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Auch weltweit sieht man, dass Angela Merkel s Gro Ko 3.0 nicht klimatauglich ist, sondern vielmehr das Pariser Abkommen unterlaeuft. Auch aussenpolitisch fatal. Daher Klimasofortprogramm jetzt auflegen!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QiOSbaOfkRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb92e216-5126-4dff-b148-ce8440599f72"
      },
      "source": [
        "# Is the sentiment expressed in this tweet negative or positive? Check by printing the label.\n",
        "labels[1]                                                                                         "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow1HwkWUhPMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b287063-d1f3-4b56-e824-35637cfe401b"
      },
      "source": [
        "# Count the occurrences of positive and negative tweets\n",
        "import numpy as np\n",
        "np.count_nonzero(labels == 1)                                                                     "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugeeuOiwkJiF"
      },
      "source": [
        "GermEval Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm-y_1C6iFZE"
      },
      "source": [
        "# Prepare path to the dataset containg GermEval texts\n",
        "filename_germeval = \"data_germeval_2017.tsv\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKmrPBtTja5r"
      },
      "source": [
        "# Load the dataset into a pandas dataframe\n",
        "import pandas as pd\n",
        "germeval = pd.read_csv(filename_germeval, \n",
        "                   sep='\\t',\n",
        "                   header=None, \n",
        "                   names = [\"full_text\", \"0\", \"label\", \"2\"])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NHjRwmajlHC"
      },
      "source": [
        "# Further preprocessing\n",
        "germeval['label_binary'] = [1 if label == 'positive' else 0 for label in germeval.label]\n",
        "germeval = germeval.loc[lambda x: x['label'] != \"neutral\"]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-3Xsv0PJ0X0"
      },
      "source": [
        "# Get the lists of tweets and their labels -> Use only the first 99 rows\n",
        "tweets_germeval = germeval.full_text.values[0:99]\n",
        "labels_germeval = germeval.label_binary.values[0:99]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKWWD02IyBh"
      },
      "source": [
        "First, we need to tokenize our text to be able to feed it into the BERT model. \n",
        "\n",
        "Below an example of tokenized and raw tweet versions is shown. To tokenize the text we have to specify and use the pretrained BERT because each model has a fixed vocabulary (containing tokens, so wordpieces) and the BERT tokenizer handles words which are not in the certain vocabulary in a specific way.\n",
        "\n",
        "Each token is then mapped to its index in the tokenizer vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZL1eSQeVs6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce0dbd0-b18c-4666-ba9f-dcec719ada18"
      },
      "source": [
        "# Print the raw tweet.\n",
        "print('Raw: ', tweets[0])\n",
        "\n",
        "# Print the tweet split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(tweets[0]))\n",
        "\n",
        "# Print the tweet mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw:  Habe mir das Gro Ko-Sondierungspapier zu Klima nochmal genau angeschaut. Krass: De facto wird sogar das Kyoto-Protokoll, der Meilenstein der Klimadiplomatie fuer nichtig erklaert! Frau Merkel, das geht so nicht! Nachbessern! kohleausstieg\n",
            "Tokenized:  ['Hab', '##e', 'mir', 'das', 'Gro', 'Ko', '-', 'Son', '##die', '##rung', '##sp', '##ap', '##ier', 'zu', 'Klima', 'noch', '##mal', 'genau', 'angesch', '##aut', '.', 'Kras', '##s', ':', 'De', 'fa', '##ct', '##o', 'wird', 'sogar', 'das', 'Ky', '##oto', '-', 'Protokoll', ',', 'der', 'Meilen', '##stein', 'der', 'Klima', '##di', '##plomat', '##ie', 'f', '##uer', 'nichtig', 'erk', '##la', '##ert', '!', 'Frau', 'Merkel', ',', 'das', 'geht', 'so', 'nicht', '!', 'Nach', '##besser', '##n', '!', 'ko', '##hle', '##auss', '##ti', '##eg']\n",
            "Token IDs:  [9689, 26897, 3667, 93, 951, 673, 26935, 1343, 2930, 23620, 168, 425, 97, 81, 6914, 357, 446, 2971, 16745, 956, 26914, 26237, 26902, 26964, 576, 20568, 1920, 26910, 292, 2215, 93, 13235, 9857, 26935, 10252, 26918, 21, 17930, 1407, 21, 6914, 3748, 13461, 12, 69, 667, 20719, 895, 129, 335, 26982, 946, 5654, 26918, 93, 1398, 181, 149, 26982, 326, 4379, 26898, 26982, 7424, 2039, 10685, 15099, 640]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZJe8-JoKAaL"
      },
      "source": [
        "In the next step we add special tokens to the start *CLS* and end of each tweet *SEP*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKR6G5w4dFsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "279da006-26fe-4ccd-b98d-b32b6530f2ab"
      },
      "source": [
        "# Tokenize all of the tweets and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every tweet...\n",
        "for tweet in tweets:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded tweet to the list.\n",
        "    input_ids.append(encoded_tweet)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Habe mir das Gro Ko-Sondierungspapier zu Klima nochmal genau angeschaut. Krass: De facto wird sogar das Kyoto-Protokoll, der Meilenstein der Klimadiplomatie fuer nichtig erklaert! Frau Merkel, das geht so nicht! Nachbessern! kohleausstieg\n",
            "Token IDs: [3, 9689, 26897, 3667, 93, 951, 673, 26935, 1343, 2930, 23620, 168, 425, 97, 81, 6914, 357, 446, 2971, 16745, 956, 26914, 26237, 26902, 26964, 576, 20568, 1920, 26910, 292, 2215, 93, 13235, 9857, 26935, 10252, 26918, 21, 17930, 1407, 21, 6914, 3748, 13461, 12, 69, 667, 20719, 895, 129, 335, 26982, 946, 5654, 26918, 93, 1398, 181, 149, 26982, 326, 4379, 26898, 26982, 7424, 2039, 10685, 15099, 640, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ_QN3DKkUFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95c800a-dcbb-4722-e17a-81d4e89b513c"
      },
      "source": [
        "# Do the same for GermEval \n",
        "input_ids_germeval = []\n",
        "\n",
        "# For every tweet...\n",
        "for tweet_germeval in tweets_germeval:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet_germeval, # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded tweet to the list.\n",
        "    input_ids_germeval.append(encoded_tweet)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets_germeval[0])\n",
        "print('Token IDs:', input_ids_germeval[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  @nordschaf theoretisch kannste dir Ã¼berall im KÃ¶lner Stadtbereich was suchen. Mit der KVB + S-Bahn kommt man Ã¼berall fix hin.\n",
            "Token IDs: [3, 26991, 3194, 17051, 23888, 479, 116, 14843, 10151, 106, 8104, 560, 1859, 961, 8083, 26914, 304, 21, 20578, 26925, 26986, 24, 26935, 1621, 1471, 478, 10151, 19004, 461, 26914, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk4o_F6XKIUF"
      },
      "source": [
        "Then we pad and truncate all tweets to a constant fixed length "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_tBkChIdyOC",
        "outputId": "6aea341a-d9b8-4478-aa4b-96bea33e5f38"
      },
      "source": [
        "print('Max sentence length: ', max([len(tweet) for tweet in input_ids]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTux34E5kYND",
        "outputId": "fc1af17c-dd0f-4d40-c09a-77fa5c49665f"
      },
      "source": [
        "print('Max sentence length for GermEval data: ', max([len(tweet_germeval) for tweet_germeval in input_ids_germeval]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length for GermEval data:  698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTtngalseGJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b98c6c-5f7b-4e66-8cc7-7cb8e6e9b95d"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# A bit larger than the maximum training tweet length of 91/110... (with germeval 3202/3300 -> bert has a max length limit of tokens = 512, we cut the longer texts off and only use the first 512 Tokens)\n",
        "MAX_LEN = 250\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" - pad and truncate at the end of the sequence, as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Pad our input tokens with value 0 for Germeval data \n",
        "input_ids_germeval = pad_sequences(input_ids_germeval, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 250 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vstmJJnvOEJ6"
      },
      "source": [
        "Create attention masks which indicates which tokens are words and which are padding (if token ID is 0 then it is padding and the attention mask is set to 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoRYw4_jg4QP"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for tweet in input_ids:\n",
        "    \n",
        "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
        "    \n",
        "    # Store the attention mask for each tweet.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yinz_P3vk1oJ"
      },
      "source": [
        "# Create attention masks for Germeval data \n",
        "attention_masks_germeval = []\n",
        "\n",
        "# For each sentence...\n",
        "for tweet_germeval in input_ids_germeval:\n",
        "    \n",
        "    att_mask = [int(token_id > 0) for token_id in tweet_germeval]\n",
        "    \n",
        "    # Store the attention mask for each tweet.\n",
        "    attention_masks_germeval.append(att_mask)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vp0fFEsOifw"
      },
      "source": [
        "Now, we use train_test_split to split our data into train, test sets first  and then split the initial train set further into a final train set and validation set for training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UT0FM31qLDR"
      },
      "source": [
        "### Perform train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV4b99xCgEsu"
      },
      "source": [
        "# Without-GermEval-case\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "train_inputs2, test_inputs, train_labels2, test_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state = 2021, test_size = 0.2, stratify = labels)      \n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks2, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state = 2021, test_size = 0.2, stratify = labels)                      \n",
        "\n",
        "\n",
        "# Use 20% of train set as validation set \n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs2, train_labels2, \n",
        "                                                                                    test_size = 0.2, random_state = 2021)  \n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(train_masks2, train_labels2,                                        \n",
        "                                             random_state=2020, test_size=0.2)    "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPxoRdC5-7YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab8e1df-747f-41ad-e069-a025364774d2"
      },
      "source": [
        "# How many training tweets do you have? \n",
        "len(train_inputs)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lUovm-xmGbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5020b3-948e-4567-def2-910f9e169956"
      },
      "source": [
        "# How many test tweets do you have? \n",
        "len(test_inputs)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTBu9v-qteI"
      },
      "source": [
        "### Train with GermEval data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHDnNsImhFKd"
      },
      "source": [
        "# Use additional Germeval data for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "train_inputs1, test_inputs, train_labels1, test_labels = train_test_split(input_ids, labels,                               \n",
        "                                                            random_state=42, test_size=0.2, stratify = labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks1, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=42, test_size=0.2, stratify = labels)\n",
        "\n",
        "# Mix train_inputs1, train_labels1, train_masks1 with germeval data\n",
        "train_inputs2 = np.concatenate((train_inputs1, input_ids_germeval), axis=0)\n",
        "train_labels2 = np.concatenate((train_labels1, labels_germeval), axis=None)\n",
        "train_masks2  = np.concatenate((train_masks1, attention_masks_germeval), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# Use 20% of train set as validation set \n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs2, train_labels2,           \n",
        "                                                                                    test_size=0.2, random_state=2020) \n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(train_masks2, train_labels2,                                         \n",
        "                                             random_state=2020, test_size=0.2)    "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTaFTXqFO080"
      },
      "source": [
        "Convert all inputs and labels into torch tensors, the required datatype \n",
        "for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg71HZ7qifpo"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFLnUkVxsCTS"
      },
      "source": [
        "### Set hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDKmSSbxrwbg"
      },
      "source": [
        "We chose the following values based on authors' recommendations:\n",
        "\n",
        "* Batch size: 16\n",
        "* Learning rate (Adam): 2e-5\n",
        "* Number of epochs: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SQQwH_VrL63"
      },
      "source": [
        "# Define batch size here to let DataLoader know. \n",
        "# BERT-authors recommend a batch size of 16 or 32 for fine-tuning.\n",
        "batch_size = 16"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LXM1YHwrRQC"
      },
      "source": [
        "# Define the learning rate \n",
        "learning_rate = 2e-5"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJka_WQrms8"
      },
      "source": [
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeutTU9Hr0pB"
      },
      "source": [
        "The torch DataLoader class enables to create  an iterator for our data in order to save memory during training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBRWzCgriurl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIEy4SR4R6ch"
      },
      "source": [
        "Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "linear classification layer on top. This is the one for classification tasks in general. *(see for more details https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xILaX9ulICZ"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    pretrained_model, \n",
        "    num_labels = 2, # The number of output labels--2 for binary classification. Can be increased for multiclass\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False \n",
        ")\n",
        "\n",
        "# Run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wddbSBdwl6MM"
      },
      "source": [
        "# All of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOogCCNSS1_z"
      },
      "source": [
        "Get the optimizer after loading the model. \n",
        "\n",
        "*(see for more details on AdamW Optimizer https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5YMJeG7m1GW"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate, \n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TypGI2W5m5X9"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fgx-tuPnc8Z"
      },
      "source": [
        "# helper function for calculating accuracy\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcSWb-YhpNo4"
      },
      "source": [
        "# helper function for formatting elapsed times\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTwfA1dVrJFv"
      },
      "source": [
        "### Fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgc1fHkwTxaf"
      },
      "source": [
        "Let's start the actual training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acrG210Npcb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6de7f58e-426b-462a-e339-5246b719415b"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 55\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch:\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    ## TRAIN\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # how long does the training epoch take.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Turn on the training mode for the model. \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data:\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack the batch and load onto the GPU.\n",
        "        # Each batch contains input ids, attention masks, labels. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Remove any previously calculated gradients before performing a\n",
        "        # backward pass. \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Do a forward pass. \n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. \n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Do a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0. \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step.\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Avg loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Need for plotting the learning curve later.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Avg training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Epoch time: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    ## VALIDATE\n",
        "    # After each training epoch, we measure performance on\n",
        "    # validation set.\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Turn on the evaluation mode of the model.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get logit values predicted for each class.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Accuracy for this batch of validation tweets.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation time: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.54\n",
            "  Epoch time: 0:00:10\n",
            "  Accuracy: 0.80\n",
            "  Validation time: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.36\n",
            "  Epoch time: 0:00:10\n",
            "  Accuracy: 0.82\n",
            "  Validation time: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.21\n",
            "  Epoch time: 0:00:10\n",
            "  Accuracy: 0.85\n",
            "  Validation time: 0:00:01\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.11\n",
            "  Epoch time: 0:00:10\n",
            "  Accuracy: 0.87\n",
            "  Validation time: 0:00:01\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKJGT2uxqsNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "e6a792c6-3c4c-481b-ea55-286edd1ad3ec"
      },
      "source": [
        "# Visualize the training results\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVV9-_GMY76z"
      },
      "source": [
        "## Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tocnbPMDRN00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2484553-e241-4932-9a44-7b830a4cac06"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test tweets...'.format(len(test_inputs)))\n",
        "\n",
        "# Turn on the evaluation mode of the model\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Compute gradients, save memory and speed up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 100 test tweets...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOIrNxOukbY6",
        "outputId": "fde2be1e-b692-4bca-9265-053502b4ab63"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label_binary.sum(), len(df.label_binary), (df.label_binary.sum() / len(df.label_binary) * 100.0)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 106 of 498 (21.29%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iNrCwTYa6cI"
      },
      "source": [
        "Performance measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YzWo-1qp3kn"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd4kOBthmifT"
      },
      "source": [
        "# List of keys of the highest scores, i.e. predictions (indices of the maximum values along an axis)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGWTUvMEmjqv"
      },
      "source": [
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x7g2bzgb-o9"
      },
      "source": [
        "F1 score, accuracy and confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAoOFsCUwsLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4442d26-820a-4485-9319-e13cdca67568"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "# F1-Score (weighted)\n",
        "f1_value = f1_score(flat_predictions, flat_true_labels, average=\"weighted\")\n",
        "\n",
        "# Accuracy Score\n",
        "accuracy = accuracy_score(flat_predictions, flat_true_labels)                        \n",
        "\n",
        "print(\"F1 Score (Weighted): {}\".format(f1_value))\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score (Weighted): 0.8737888198757764\n",
            "Accuracy: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s22lIKFxrOu"
      },
      "source": [
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    cm = confusion_matrix(y_true=true_labels, \n",
        "                                  y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "    cm_frame = pd.DataFrame(data=cm, \n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
        "                                                  codes=[[0,0],[0,1]]), \n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
        "                                                codes=[[0,0],[0,1]])) \n",
        "    return cm_frame   "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aARx5G5vy5vZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fe146570-15af-43a4-9c8a-86dcf366591a"
      },
      "source": [
        "confusion_mat = display_confusion_matrix(true_labels = flat_true_labels, predicted_labels = flat_predictions)\n",
        "confusion_mat"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Predicted:</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Actual:</th>\n",
              "      <th>1</th>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted:    \n",
              "                   1   0\n",
              "Actual: 1         13   8\n",
              "        0          5  74"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    }
  ]
}