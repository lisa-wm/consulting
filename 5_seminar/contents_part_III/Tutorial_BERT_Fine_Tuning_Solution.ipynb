{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial_BERT_Fine-Tuning_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "95955dce3dc24593808009d06898abb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78a71bdbbbe14aa295c1a0e034ee551c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7b93b2b2e9eb4af6ab7d7e6e9ab46922",
              "IPY_MODEL_e2eaf2690510405fba3d50b68f204be7"
            ]
          }
        },
        "78a71bdbbbe14aa295c1a0e034ee551c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b93b2b2e9eb4af6ab7d7e6e9ab46922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8f20a1e25444e4f9643e720b1666dc4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d6a708802fe54ae6b6b4abd8d779c1a4"
          }
        },
        "e2eaf2690510405fba3d50b68f204be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0dbb83e6294c488eabeee5c879a2fef2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:08&lt;00:00, 49.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5071e20e95a4ff886b798bad08b7f78"
          }
        },
        "a8f20a1e25444e4f9643e720b1666dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d6a708802fe54ae6b6b4abd8d779c1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dbb83e6294c488eabeee5c879a2fef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5071e20e95a4ff886b798bad08b7f78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "154f2c1d04914a96a040ca62533aa748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_055a5f9146ac41a985914c77bfca9406",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69db14ae7e1a49e1be4c1872ab896512",
              "IPY_MODEL_8e72f756a09a4872b107cdb15212eb35"
            ]
          }
        },
        "055a5f9146ac41a985914c77bfca9406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69db14ae7e1a49e1be4c1872ab896512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_87c333568cdf44c58776827668195b4f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 438869143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 438869143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f9e04da47024e16a1f2fd204a8228ae"
          }
        },
        "8e72f756a09a4872b107cdb15212eb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2039b0a49e3e4e51874847fdb4acdae0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 439M/439M [00:08&lt;00:00, 50.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9183019ccf524c4a99fc416025ca35f3"
          }
        },
        "87c333568cdf44c58776827668195b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f9e04da47024e16a1f2fd204a8228ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2039b0a49e3e4e51874847fdb4acdae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9183019ccf524c4a99fc416025ca35f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09FrEZkpUv0F"
      },
      "source": [
        "# BERT Fine-Tuning (pure)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WrhLjZdVN49"
      },
      "source": [
        "*By Asmik Nalmpatian and Lisa Wimmer*\n",
        "\n",
        "*Last edited on 27.03.21* \n",
        "\n",
        "*For our consulting project: Aspect-Based Sentiment Analysis for Twitter Data of German MPs*\n",
        "\n",
        "*Methodology based on: https://arxiv.org/pdf/1810.04805.pdf*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shmCbiSwlDNV"
      },
      "source": [
        "![Logo_Consulting.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4RDgRXhpZgAATU0AKgAAAAgABAE7AAIAAAAHAAAISodpAAQAAAABAAAIUpydAAEAAAAOAAAQyuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5BTE1QSQAAAAWQAwACAAAAFAAAEKCQBAACAAAAFAAAELSSkQACAAAAAzQ1AACSkgACAAAAAzQ1AADqHAAHAAAIDAAACJQAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjAzOjIxIDIxOjQwOjE1ADIwMjE6MDM6MjEgMjE6NDA6MTUAAABOAEEATABNAFAASQAAAP/hCxlodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIxLTAzLTIxVDIxOjQwOjE1LjQ0OTwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5OQUxNUEk8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA9QHmAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+jy6g4Jo8xfX9KhmYKzMxwoGST2rg9Z8TXF7M0VnI0NsDgFThn9yf6VvRoSrO0Tnr4iFCN5HoJmjHVwKTz4v+ei/nXkZZiclmJ+tGW9TXb/Z/wDe/A8/+0v7v4/8A9c8+L/nov50efF/z0X868jy3qaMt6mn/Z/978A/tL+7+P8AwD1zz4v+ei/nR58X/PRfzryPLepoy3qaP7P/AL34B/aX938f+AeuefF/z0X86PPi/wCei/nXkeW9TRlvU0f2f/e/AP7S/u/j/wAA9c8+L/nov50efF/z0X868jy3qaMt6mj+z/734B/aX938f+AeuefF/wA9F/Ojz4v+ei/nXkeW9TRlvU0f2f8A3vwD+0v7v4/8A9c8+L/nov50efF/z0X868jy3qaMt6mj+z/734B/aX938f8AgHrnnxf89F/Ojz4v+ei/nXkeW9TRlvU0f2f/AHvwD+0v7v4/8A9c8+L/AJ6L+dHnxf8APRfzryPLepoy3qaP7P8A734B/aX938f+AeuefF/z0X86PPi/56L+deR5b1NGW9TR/Z/978A/tL+7+P8AwD1zz4v+ei/nR58X/PRfzryPLepoy3qaP7P/AL34B/aX938f+AeuefF/z0X86PPi/wCei/nXkeW9TRlvU0f2f/e/AP7S/u/j/wAA9c8+L/nov50vnxHo4/OvIst6mjcw7kfjS/s/+9+Af2l/d/H/AIB695i+v6UB1JwDXnGk+I7rT5VWZ2nt+jIxyVHqDXoFtKk6xyxMGRxuUjuMVx1qEqL1O+hiIV1puWaKKK5zpCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAMPxTM0Oh3RQ4LAJn2JGa4fR7Nb/AFa3tpPuO3zY7gDJ/lXaeL/+QFP/ALyfzrlPDH/Ix23/AAL/ANBNethXy4eUl5/keNi1zYqEXtp+Z3sdtBDGI4oY0RRgAKOKf5Uf9xf++RTqK8q7PYshvlR/3F/75FHlR/3F/wC+RTqKLsLIb5Uf9xf++RR5Uf8AcX/vkU6ii7CyG+VH/cX/AL5FHlR/3F/75FOoouwshvlR/wBxf++RR5Uf9xf++RTqKLsLIb5Uf9xf++RR5Uf9xf8AvkU6ii7CyG+VH/cX/vkUeVH/AHF/75FOoouwshvlR/3F/wC+RR5Uf9xf++RTqKLsLIb5Uf8AcX/vkUeVH/cX/vkU6ii7CyG+VH/cX/vkUeVH/cX/AL5FOoouwshvlR/3F/75FHlR/wBxf++RTqKLsLIb5Uf9xf8AvkUeVH/cX/vkU6ii7CyG+VH/AHF/75FNeCGRCrxIykYIKg5qSii7CyPOvEFjHp2sSQwDEbAOo/u57V1ng2ZpdFRW58uRlH06/wBa53xh/wAh8/8AXFf61veCf+QQ3/XZv5CvVrtywsW/I8fDpRxckttTpqKKK8k9kKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5/xf/yAp/8AeT+dcp4Y/wCRjtv+Bf8AoJrq/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAqOe4htojJcSLEg/iY4rH1rxLDpu6C3Amue4/hT6/4Vxd5fXN/MZbuVpG7Z6D6DtXbQwk6nvS0RwYjGwpPljqzrbzxlaRErZxPcH+8flX/GsefxfqcufL8qEf7KZP61hUV6UMLRj0ueVPGVp9behpN4h1ZjzeyD6AD+lKniPVkPF45/3gD/SsyitvZU/5V9xj7ar/ADP7zorfxlfRkfaIoph3wNprasfFen3ZCzFrZz2k+7+dcHRWE8HSlsrHRTxtaG7v6nq6sGUMpDKeQQetLXm+ma1eaW48h90WeYn5U/4V3OlaxbatDugO2RR88TdV/wAR715dfCzpa7o9bD4uFbTZl+iiiuU7AooooAKKKKACiiigAooooAKKKKAOE8Yf8h8/9cV/rW94J/5BDf8AXZv5CsHxh/yHz/1xX+tb3gn/AJBDf9dm/kK9Wt/ukfkePR/32XzOmoooryj2AorM1bWo9LmgRl3mQ5cDqq+taEM0c8KywsHRhkMO9W6clFSa0ZEakZScU9UPoooqCwooooAKKKKACiiigAooooAKKKKACiisDV/EqWzNBY4klHBkPKr/AImtKdKdWXLFGVWrClHmmzauLmG1j33Eqxr6scVjXPiy0iJFtHJOfX7orlLi5mupTJcSNI57sair1qeAgvjdzx6uYzfwKx0Eni+6P+rt4VHuSaYPFt8DzFAf+An/ABrCorp+q0f5Tl+t1/5jpofGDZ/f2gI9Uf8AxrVtPEOn3ZCiXynP8Mox+vSuEorKeBoy20NoY+tHfU9OByMjkUVwOn6zeacwEUm+PvG/I/8ArV12mazbamuEPlzAfNGx5/D1rzK2EnS13R6tDGU62mzNCioJ721th+/uI4/ZmGay7rxVZQ5FuHuG9htH5msYUak/hRvOtTp/FI26jFxE1wYFkUyqMlQckD3ri73xHfXeVV/Ij/ux9fzrofDunGysPMmGJpzubPUDsK3qYZ0oc03r2OenilWqctNadWa9FFFcZ2nP+L/+QFP/ALyfzrlPDH/Ix23/AAL/ANBNdX4v/wCQFP8A7yfzrlPDH/Ix23/Av/QTXq4f/dZ/P8jx8V/vcPl+Z6FRRRXlHsBXOeJPEBslNnZN/pDD53H/ACzHp9a0tb1MaVprTDBlb5YlPc+v4V507tLIzyMWdjlie5r0MHh1N88tjzcbiXTXs4bsaSSSSck9SaKKK9k8IKKKKACiiigAooooAKltrmW0uFmt3KSKcgioqKGk1ZjTad0ejaLrEer2m4YSZOJE9Pce1aVeY6bfy6bfJcw/w8Mv95e4r0q3njureOeE7kkUMprwsVQ9lK62Z9Dg8R7aNpbokooorjO0KKKKACiiigAooooAKKKKAOE8Yf8AIfP/AFxX+tb3gn/kEN/12b+QrB8Yf8h8/wDXFf61veCf+QQ3/XZv5CvVrf7pH5Hj0f8AfZfM6aiiorqTybOaQfwIzfkK8tK7seu3ZXOF1m7+2atPJnKq2xfoOKk0fWZdLl2tl7dj8yenuKzM55PWivpnSi4eza0PlVWmqntE9T0m3uYruBZrdw6N0IqWvPdO1O40ybfA2VP34z0au103VbbU4swttkA+aNuo/wAa8TEYWVJ3WqPew2LjWVnoy7RRRXGdoUUUUAFFFFABRRRQAUUVn61qH9naa8in963yx/X1/CqhFzkorqROahFyfQyfEWtlWaxs2wekrg9P9kVy9KSWJJOSTkk96SvpKNKNKPLE+YrVpVp80gooorUxCiiigAooooAKUEg5BwfUUlFABRRWrpv9lW22e/laaQciFEJA+vrUzlyq9rlwhzu17F3w/oRmdby8XEQ5jQ/xH1PtXWVzk3i+FRi3tXb03kL/AI1UTW9W1W5FvZ7Ii3XYv3R6kmvIq0a9aXPPRHs0q2HoR5Iavy6nXUVBZ232W3CGRpX6vI5yWNFec7J6Hpq7WpjeL/8AkBT/AO8n865Twx/yMdt/wL/0E11fi/8A5AU/+8n865Twx/yMdt/wL/0E16mH/wB1n8/yPIxX+9w+X5noVFFQ3k/2WymnP/LNC35CvLSu7HrtpK7OH8U3/wBs1ho1OYrf5F579z/n0rFpWYuxZuWY5J96SvpacFCCiuh8rUm6k3J9QoooqzM3fDehJqkjz3Wfs8ZxtBxvPp9Kv+IPDVvBZNd6ehQxDLx5JBHqK1vC8YTw7blR97cx+uTWnNGJYJI26MpU/iK8WpiZqu2nome9SwlN0EmtWtzyqlVS7BVGWY4AHc0hGCR6Vo6BGsuv2ivyPMzj6DNexKXLFy7HhwjzSUe51Fj4TsY7MLeoZZ2HzNuI2n0GK5XWdMbStQaAktGRujY9xXpNct43iHk2kv8AEGZfwxmvJwuInKraT3PaxeGpxo3irWOQooor2Dwwrr/Bl+WjlsZD9z95H9O4/wA+tchV/Q7r7JrVtJnCl9jfQ8VhiKftKTR0Yap7Oqmek0UUV86fThRRRQAUUUUAFFFFABRRRQBwnjD/AJD5/wCuK/1re8E/8ghv+uzfyFYPjD/kPn/riv8AWt7wT/yCG/67N/IV6tb/AHSPyPHo/wC+y+Z01VtRUvpdyo6mJv5VZpGUMpVuhGDXlxdmmetJXTR5lRU11A1rdywP1jYrUNfVJpq6PkmmnZhT45HhkWSJ2R1OQynBFMooFsdRpnioHbFqQwennKP5j/CukilSaMPE6uh6MpyDXmdWbO/ubGTfaysnqOoP1FedWwMZaw0f4Hp0MwlDSpqvxPRaK5yx8WRPhb+Ixt/fTkfl1ret7qC6j320qSL6qc15dSjUp/Ej16denVXuMlooorE2CiiigArj/FdyZNSSAH5YU6e5/wDrYrsK4DW2L65dE9nx+Qr0MBG9W/ZHnZjJqkl3ZQooor2zwAooooAKKKKACiiigAooooAKKK1NG0V9VZnLiOFDhj3J9BUznGEeaWxcISqS5YrUqWNhPqFwIrdcn+Jj0UepruNM0yHTLfy4huc/fkI5Y1NaWcFjAIraMIo/M+5qevCxGKlW0WiPfwuEjRXM9ZBRRRXGdxz/AIv/AOQFP/vJ/OuU8Mf8jHbf8C/9BNdX4v8A+QFP/vJ/OuU8Mf8AIx23/Av/AEE16uH/AN1n8/yPHxX+9w+X5noVZHiiQx+HrjH8W1fzIrXrE8W/8i/J/wBdF/nXBQ1qx9T0cQ7UZejOCooor6M+XCiiigB6zSquFkdR6BiKXz5v+e0n/fZqOilZDuwpQxVsqSCOhBxU0djdyrmO1mYeojJpstrcQf6+CSMf7aEUc0XpcfLJK9hPPm/57Sf99mmtI7/fdmx03MTTaKLIV2FFABJAAyT0A71vab4TvLsCS6P2aI9mGWP4dvxqZ1IU1eTLp0p1HaCuYNTW9tcTODbQSSEHI2ITXfWXhzTbLBEAlcfxy/N+nStNQFUKoCgdABivPnj47RR6VPLpbzlYEJKKSMEgZBpaKK8k9kKKKKACiiigAooooAKKKKAOE8Yf8h8/9cV/rW94J/5BDf8AXZv5CsHxh/yHz/1xX+tb3gn/AJBDf9dm/kK9Wt/ukfkePR/32XzOmoooryj2Dl/FWmnct/EOOFlx29D/AE/KuZr0ySNJY2jkUMjDBB7iuG1nR5NMnyuWt3PyP6exr2cFiFJezlv0PDx2GcZe1js9zMooor0jywooooAKfHI8Th4nZGHQqcGmUUAbFt4m1C3wJGWdf+mg5/MVrW/i62fi5gkiPqvzCuRormnhaM90dcMZWhs/vPQINa064x5d3GD6Odp/WrqurjKMGHqDmvMqckjxnMbsp/2TiuWWXR+zI645lL7UT0yuE8QxGLXJ/R8OPxFQR6rfxfcvJh7F8/zqK6vJ72QSXUnmOo2gkAcVphsLOjPmvdGeKxcK9PlSsyCiiiu880KKKKACiiigAooooAKKKKACuv8ACK402Y+sv9BXIV2vhZNuig/3pGP9P6VxY52o/M78vV6/yNmiiivBPoQooooA5/xf/wAgKf8A3k/nXKeGP+Rjtv8AgX/oJrq/F/8AyAp/95P51ynhj/kY7b/gX/oJr1cP/us/n+R4+K/3uHy/M9CrM8Rwmfw/dAdVUP8Akc1p0yaJZ4Xif7rqVP0NebCXLJS7Hq1I88HHueVUVJPC1vcSQyDDRsVP4VHX0yd9T5Rqzswoop0cbSyLHGMs5CqPUmgRc0vSrjVrryoBtVeXkPRRXcadoNjpyjy4hJL3lkGSf8Km0vTo9M09LeMDcBl2/vN3NXK8LEYqVR2jsfQ4bCRpRvJXkFIwDKVYBgeoIzmlorjO4wdV8LWt4rSWYFvP14+631Hb8K5KHSb2bUTZLCRMp+YHoo9SfSvS6QKoYsFAY8E45NdlLGVKcWnqcNbBU6klJadzK0jw/a6WocgTXHeRh0+g7VrVFdXUNnbtNcyCONepNcVq3im5vS0VmWt4OmQfmb6ntUwp1cTK/wCJdSrSwseX8Dqb/XbDTsrPMGk/55x/M3/1qwbnxrISRZ2iqP70rZP5CuWor0qeCpR+LU8qpj6svh0NiTxVqznidU9ljFRjxJqwP/H43/fK/wCFZdFdHsaS+yvuOb29V/af3m5D4t1SM/O0co9GTH8q1LTxrExC3ts0f+3Gdw/KuPorOWFoy6GkMXWh9r7z1C0v7W/j32kyyDuAeR9RVivKoZpLeUSQSNG69GU4NdZo3iwSMsGqYVjwsw4B+vp9a8+tgpQ1hqj06GPjN8s9H+B1NFAORkcg9DRXnnpBRRRQBwnjD/kPn/riv9a3vBP/ACCG/wCuzfyFYPjD/kPn/riv9a3vBP8AyCG/67N/IV6tb/dI/I8ej/vsvmdNUV0WFnMYzhxG20jscVLQRkEHoa8tOzueu1dWOQtPFl1GALqJZx/eHyt/hWl/wkel3kJiu0dVYYZXTI/SuUu4DbXk0LdY3K1DXvywlGfvJW9D52OMrw91u/qXtRtrSGTfYXSzQseF6Mv+NUaKK6oppWbuckmpO6VgooopkhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXf6HF5OiWqnglN358/1rg44zLKka9XYKPxr0mNBFEka9FUKPwrzMwl7sYnrZbH3pSHUUUV457QUUUUAc/4v/5AU/8AvJ/OuU8Mf8jHbf8AAv8A0E11fi//AJAU/wDvJ/OuU8Mf8jHbf8C/9BNerh/91n8/yPHxX+9w+X5noVFFFeUewcX4w04w3q3sY+Sbh/Zh/iP5VzdeoX1nHqFlJbTD5XHX+6exrza9s5bC8e3uBh0PXsR6ivbwdZThyPdHg46g4T51s/zIKs6ddrY6hFcvF5oiO4JnGT2qtRXa0pKzPPi3F3R1v/CcD/nwP/f3/wCtR/wnA/58D/39/wDrVyVFc31Oh2/M6/rtf+b8Edb/AMJwP+fA/wDf3/61A8bbmCrp5JJwAJev6VyVdD4R00XN813KMx2/3c93/wDrVnUw9CnBya/M1pYnE1ZqClv5I7SFneFGlTy3IyyZztPpmmXV1FZWr3Fw22NBkn19qmrhPE+rm/vjbwt/o8Bxx/E3c/0rzKFF1p26Hq4iuqFO/Upavq8+rXW+QlYlP7uPPCj/ABrPoor34xUVyxPm5SlOXNLcKKKKokKKKKACiiigAooooA6Pw54hNo62d6+YGOEcn/Vn0+n8q7WvJ67bwpq5u7Y2Vw2ZYRlCf4l/+tXlYzDpL2kfmexgcS2/ZT+X+R0VFFFeWeucJ4w/5D5/64r/AFre8E/8ghv+uzfyFYPjD/kPn/riv9a3vBP/ACCG/wCuzfyFerW/3SPyPHo/77L5nTUUUV5R7ByXiuxMd0l4g+SQbX9mHT9P5Vz1ekXdrHe2r28wyjjH0964C/sZtPu2gnHI5VuzD1Fe5gq6nDke6PAx1Bwn7RbP8ytRRRXeecFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAGp4dtvtOtRZHyxZkP4dP1xXdVz/hO08uzkumHMrbV+g/+v/KugrwcbU56rXY+iwNPkopvrqFFFFcR3BRRRQBz/i//AJAU/wDvJ/OuU8Mf8jHbf8C/9BNdX4v/AOQFP/vJ/OuU8Mf8jHbf8C/9BNerh/8AdZ/P8jx8V/vcPl+Z6FRRRXlHsBWZreixavbY4S4Qfu5P6H2rToqoylCXNHcicIzjyy2PLLq1ms7hoLlCki9Qf51FXpmo6Va6pD5d0nI+644ZfpXF6n4avdPJeNTcQj+NByPqK9uhi4VFaWjPBxGDnSd46ox6KKK7DhCvR9Bs/sOiwRkfOy73+p5rgdPt/tWpW8HXzJFB+mea9P8ApXmZhPRQPWy2Gsp/IzPEF/8A2fo8rocSyfu0+p7/AJV51XS+NLrffQWwPEabyPc//WFc1W+Dp8tK/c58dU561uwUUUV2HCFXYtH1Ce1+0RWsjRYyGA6j2HejSLMX+rW9u/3GbLfQcmvSlAVQqgAAYAHauLE4l0WoxWp34XCKunKT0PKKK3PFditpq/mRrhLhd+B/e71h11U5qpBSXU5KkHTm4PoSQQS3MyxQRtJI3RVHJqa802708r9sgaLd0J6H8a6nwbZLHYyXjDMkrFFPoo/+vW1qlkmoabNbuASykqfRh0NcVTGclXktod9PA89Hnvq9jzKijGOD1or0DzAqxYXj2F9Fcx9Y2yR6juPyqvRSaTVmNNp3R6tHIssSSRnKuoZT6g06sXwrdG40KNW+9Cxj/DqP51tV81UjyTcex9VTn7SCl3OE8Yf8h8/9cV/rW94J/wCQQ3/XZv5CsHxh/wAh8/8AXFf61veCf+QQ3/XZv5CvSrf7pH5Hl0f99l8zpqKKK8o9gKqahp0GpW/lTjkcq46qat0VUZOLuiZRUlaWxwOpaPdaaxMi74s8SqOPx9Kz69EGo2Mu5PtMJIJVlZgPwway73RtHny6zx2zeqSDH5V69LGParE8WrgVvSkrHH0VcvrO3tWxBfR3PPRVPH49Kp16MZKSujzZRcXZhRRRTJCiiigAooooAKKKKACiiigAooooAKKKKACiiigAqSCF7m4jhjGXkYKKjrpfCmn7ne+lXhfljz69z/T86yrVFSg5G1Ck6tRQR0ltAlraxwR/djUKKloor5ptt3Z9SkkrIKKKKQwooooA5/xf/wAgKf8A3k/nXKeGP+Rjtv8AgX/oJrq/F/8AyAp/95P51ynhj/kY7b/gX/oJr1cP/us/n+R4+K/3uHy/M9Coooryj2AooooAKKKKAKF5oun3xJuLZd5/jX5W/MVkT+CrdmJt7qSMejqG/wAK6aitoV6sPhZhPD0qmsonNaZ4Vl0/VIrprmORIyTtCkHpiulooqalWVV3kVSpQpLlged+JJPN8Q3X+ywX8gKy6v65n+3rzP8Az1NUK+hpK1OK8kfNVnepJ+bCiiitDIv6LqCaXqS3MsbSKFI2qeea6P8A4Ta1/wCfOb/voVxtFc9TD06kuaSOmliatKPLB6Gxr+tRaw0BiheLygQd5BznHpWPRRWsIRhHljsY1JyqScpbnS6R4og03TI7WS2kdkJyysMHJzV3/hNrX/nzm/76FcbRWEsJSk22jpjjK0YqKew523SMw4BJOKbRRXUcYUUUUAdb4IkO28izxlWA/MV1dcf4J/4+bv8A3F/ma7CvBxitWZ9HgnehH+upwnjD/kPn/riv9a3vBP8AyCG/67N/IVg+MP8AkPn/AK4r/Wt7wT/yCG/67N/IV1Vv90j8jjo/77L5nTUUUV5R7AUUUUAcd4o077Pffao1/dz9fZv/AK/+NYWK9HvLSK+tXt5hlXHX0PrXBX9hNp100M491bsw9RXuYOupw5HujwMdh3TnzrZlWiiiu884KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiilALMAoJJOAB3oAsWNnJf3iW8XVjyf7o7mvQbeBLW3SGEYRBgCs7QdJGm2m+Uf6RKMv8A7I9K1a8HGV/az5Y7I+hwWH9lDmluwoooriO8KKKKACiiigDn/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmur8X/wDICn/3k/nXKeGP+Rjtv+Bf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigDz3xPF5XiG4/29rj8RWTXVeNbQiS2u1HBBjY+/Uf1rla+iw0ualFnzOKhyVpIKKKK3OYnSyupUDxW0zqejLGSDTv7Ovf8Anzn/AO/R/wAK63wdfCXTntGPzwNkDPVT/wDXros15tXGTpzcXE9WjgYVYKalueYf2de/8+c//fo/4Uf2de/8+c//AH6P+Fen5ozWX9oS/lNf7Nj/ADHmH9nXv/PnP/36P+FH9nXv/PnP/wB+j/hXp+aM0f2hL+UP7Nj/ADHlctvPb48+GSPd03qRn86jrd8WXwu9X8lDlLddn/Au/wDhWFXp05OcFJrc8qrFQm4xd7BRRRWhkdf4JhIgu5j0ZlQfgM/1rqayvDdp9k0KAMMNJmRs+/T9MVq187iJc9WTPp8NDkoxTOE8Yf8AIfP/AFxX+tb3gn/kEN/12b+QrB8Yf8h8/wDXFf61veCf+QQ3/XZv5Cu6t/ukfkefR/32XzOmoooryj2AooooAKrX1hBqNuYrlcj+Fh1U+oqzRTjJxd0KUVJWZwupaBd6eSyqZoezoOn1HasuvTqoXeiWF4S0sAVz/GnymvUpZhpaojya2XXd6b+TOAorqZ/B6E5trpl9pFz+orD1HTTpsgje4ilfuqE5X61308RSqO0XqedUw1WkryWhSooorc5wooooAKKKKACiiigAooooAKKKKACuq8OaIY9t9drh+sSHt7mo9B8P5K3d+nHWOIj9T/hXUV5WLxX/AC7h8z2MHhP+XlT5IKKKK8k9gKKKKACiiigAooooA5/xf/yAp/8AeT+dcp4Y/wCRjtv+Bf8AoJrq/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigClq1gNS0ua3/iIyh9GHSvNWVkYq4KspwQexr1euP8WaOY5TqNuvyP/rgOx/vfjXo4Gtyv2b6nl4+g5R9pHocvRRRXsHiFmwvpdOvUuYD8y9QejDuDXoem6nb6pbCW2bn+ND1Q+9eZ1Jb3E1rMJbaRonHRlOK5cRhlWV9mdmGxUqDtuj1SiuLtfGd3GoW6gjn/ANoHaf8ACrJ8brt+WxOfeT/61eW8HWT2PWWOoNXudXWHr/iCPToWt7Zg90wxxz5fuff2rnr7xXqF2pSIrbIf+ef3vzrEJJJJOSepNdVHAtPmqfcclfHprlpfeKSSSScknJJ70lFFeoeQFXtH086lqkUGPkzukPoo6/4VSALEBRkk4AHeu/8ADmkf2XY7ph/pE2C/+yOy1zYmsqUPNnXhaDrVPJbmuAFAAGABgCloor58+kOE8Yf8h8/9cV/rW94J/wCQQ3/XZv5CsHxh/wAh8/8AXFf61veCf+QQ3/XZv5CvVrf7pH5Hj0f99l8zpqKa8iR48x1XPTccZpPOi/56J/30K8uzPXuh9FRm5gX700Y+rCoX1Oxj+/dwj/gYpqMnshOcVuy1RWXL4k0yLpOZD6IpNZ1x4vQZFras3oZGx+graOGrS2iYSxVGO8jpaqXmqWdgv+kzKrdkHLH8K4+68QahdZBm8pT/AAxDH69azSSSSSST1Jrtp5e96j+44amZLamvvN3UfFFxc5jswYI/738R/wAKwiSSSTknqT3pKK9KnShTVoo8upVnVd5u4UUUVoZBRRRQAUUUUAFFFFABRRV/TtHutSbMS7Ys8yN0/D1qZSjBXk7FRhKb5Yq7KUcbyyKkal3Y4CqMk11ujeHFtttxfAPN1WPqE/xNaGm6PbaYn7pd8pHzSN1P+FX68fEY1z92noj28NgVD3qmrCiiivOPTCiiigAooooAKKKKACiiigDn/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmur8X/wDICn/3k/nXKeGP+Rjtv+Bf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigAproskbJIoZWGCCOCKdRQBwWveH5NNkM9sC9ox69TH7H296xK9XZQ6lWAKkYII61y+reEQ5abSyEPUwsePwPb6V62Hxia5an3njYnAtPmpfcchRUtxbTWspjuYmicdmGKir0001dHlNNOzCiiigQUUUUAFABJAAyT0Aq5YaTeak+LWEle8jcKPxrs9H8OW2mYlkxPc/wB8jhfoP61zVsTCktdX2OqhhalZ6aLuUvDnhw2xW9v1/fdY4z/B7n3rpqKK8OpUlVlzSPoKVKNKPLEKKKKzNThPGH/IfP8A1xX+tb3gn/kEN/12b+QrB8Yf8h8/9cV/rW94J/5BDf8AXZv5CvVrf7pH5Hj0f99l8zo5YY54zHMiyIeqsMiufv8AwnE+X09/LP8AzzflfwPUV0dFefTrTpP3WelVo06qtNHnV3p11Yti6gZB2bGVP41Wr01lDKVYAg9QR1rKu/Den3WWWMwOe8ZwPy6V6dPME9KiPLq5bJa0395w9Fb9z4Tu48m2lSYeh+U/4VlXGm3trnz7aRR67cj8xXdCtTn8Mjz50KtP4olWiiitTEKKKKACiiigAooooAKKtW+nXl1/qLaRx67cD8zWra+E7qTBupUhX0HzH/Csp1qcPiZtChVqfDEwKuWWl3l+3+jwkr3duFH411tn4dsLTDGMzOP4pef06VqgBQABgDoBXBUzBbU0ehSy5vWo/uMHT/C1vb4e8b7RJ/d6KP8AGt1VCqFUAAdAB0paK8ypVnUd5M9WnShSVoKwUUUVmahRRRQAUUUUAFFFFABRRRQAUUUUAc/4v/5AU/8AvJ/OuU8Mf8jHbf8AAv8A0E11fi//AJAU/wDvJ/OuU8MHHiK2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigAooooAKKKKAIp7aC6j2XMSSr6Ouaxbnwfp8xJgaS3J7Kcj8jW/RWkKs4fC7GU6NOp8auchJ4IlH+qvUP+8hFRDwTeZ5uoMfRv8K7Siuj65W7nP9RodvxOTi8Ec/v73j0SP/E1q2nhjTLU7jCZ29ZTn9Ola9FZyxNWW8jSGFow1URFUIoVAFUdABgCloornOkKKKKACiiigDhPGH/IfP8A1xX+tb3gn/kEN/12b+QrB8X/APIfP/XFf61veCf+QQ3/AF2b+Qr1a3+6R+R49H/fZfM6aiiivKPYCiiigAooooAglsbWf/XW8T+7IKpyeHdMk/5d9h/2GIrTorSNScfhbM5UqcviijDbwnYH7rzL/wACB/pUZ8IWva4mH5f4V0FFaLFVl9oyeEoP7Jz48IWve4m/T/CpF8J2A+887f8AAgP6VuUUfWqz+0CwlBfZMuPw5pkf/Lvv/wB9yauw2NpB/qbaJPcIKnorOVWct2zWNKnH4YoKKKKzNAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAM3WbP+0NOuLYfedfl+o5FebRSzWV4siZjmhfPI6EV6pJ/rDWLq3hy11RjKCYJ+7qMhvqK7sLiI07wnszz8ZhpVbThujOj8bR+WPOs33452OMfrTv+E2t/wDnzl/76FUm8FXYb5bqAj3BFJ/whV7/AM/MH6/4VvyYPv8Amc3Pju35F7/hNrf/AJ85f++hR/wm1v8A8+cv/fQqj/whV7/z8wfr/hR/whV7/wA/MH6/4UcmD7/mPnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KR/G0O0+XZSFu25xiqX/CFXv/AD8wfr/hSjwVeZ5uoAPoaOTB9/zDnx3b8jCvLubULx7ibmSQ9AOnoBXoXh2xbT9KghkGJGy7j0J7VS0rwvbadIJpm+0TrypIwq/QVvR/6wVjisRGaUIbI3wmGlTbqVN2T0UUVwHohRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//2Q==)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxj_Yq-iWJxb"
      },
      "source": [
        "This notebook is supposed to give an overview over the used functionalities. We will show how to use BERT - Bidirectional Encoder Representations from Transformers - with PyTorch library (huggingface) to fine-tune a pretrained model in tweet classification. \n",
        "\n",
        "The following pretrained BERT models can be used and are available in transformers huggingface: \n",
        "\n",
        "*   *bert-base-german-cased*\n",
        "*   *bert-base-german-dbmdz-cased*\n",
        "*   *bert-base-german-dbmdz-uncased*\n",
        "*   *distilbert-base-german-cased*\n",
        "\n",
        "After using these models to extract (hopefully) high quality features from our text data, we aim to fine-tune them on our specific task using a manually labeled sample of German tweets to gain state of the art predictions.\n",
        "\n",
        "All in all the tweets will be classified into *positive* and *negative* classes using a pretrained BERT model. We will take it, add an untrained layer of neurons on the end and train a new model specifically for classification task. \n",
        "\n",
        "\n",
        "Advantages of Fine-Tuning:  \n",
        "\n",
        "\n",
        "*   Quick because we have already hardly pretrained layers of the network (only 2-4 epochs after adding 1 fully-connected layer on top are enough to train as the authors recommend)\n",
        "*   Less data is sometimes enough to achieve good performance\n",
        "*   Usually preferable results: Because of task-specific adjustments of the weights\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGC297qbdzRf"
      },
      "source": [
        "**Prepare GPU:**\n",
        "\n",
        "1. Check: Edit --> Notebook settings -> Hardware accelerator -> *GPU* \n",
        "\n",
        "\n",
        "2. You will need access to the following files: *data-germeval-2017-train.tsv*, *data_labeled_processed.csv*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv04gWs2Yheg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240cc41e-b9fe-4075-961d-f45eaa95b208"
      },
      "source": [
        "# Where are you now?\n",
        "import os, sys\n",
        "print(\"My current working directory is in folder: \", os.getcwd(), \".\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My current working directory is in folder:  /content .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdHJ3jaZcM3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbed6fb9-6194-425c-cf13-37980ea1abac"
      },
      "source": [
        "# Set the path to the datasets' folder: \n",
        "print(\"The datasets needed for this exercise session are saved in the following folder: \", path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The datasets needed for this exercise session are saved in the following folder:  ./drive/MyDrive/BERT_Files/BERT_Fine-Tuning_pure/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26YQ5UYt1aGw"
      },
      "source": [
        "# Google Colab GPU Connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY5QDtKc4pCe"
      },
      "source": [
        "Otherwise training a large NN may take a very long time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpojrKi87B0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff0d3f7f-9ee6-4e30-fd63-75a45d605929"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLk647UpAUMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e65fad3-097f-4e79-e077-6dd798b257b7"
      },
      "source": [
        "# Identify and specify the GPU as the device\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLhki6Q67HB5"
      },
      "source": [
        "# Fine-Tuning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV4Ao1h59Tbj"
      },
      "source": [
        "Install Huggingface Library / transformers package and specify the pretrained transformer model. (Uncased means that the texts have only lowercase letters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtnIk5ybq1v6"
      },
      "source": [
        "## EXERCISE 1:\n",
        "*Try another pretrained model available in transformers library.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ynJrSjrQLQu"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "pretrained_model = \"bert-base-german-cased\"                                           # SOLUTION: i.e. \"distilbert-base-german-cased\"\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_model) # Additionally do lower case for pretrained uncased models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr-IYbltg_em"
      },
      "source": [
        "## EXERCISE 2:\n",
        "*Preprocess the Tweeter-Dataset.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKXUHB8CIoNV"
      },
      "source": [
        "Load and prepare the tweets and labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNnv3aRgczlM"
      },
      "source": [
        "# Prepare path to the dataset contaning tweets\n",
        "filename_tweets = \"data_labeled_processed.csv\"                                                    # SOLUTION"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ejwgMfT7D-x"
      },
      "source": [
        "# Load the dataset into a pandas dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv(filename_tweets, delimiter = ',', header = 0)                                    # SOLUTION "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeDjf_3ndl4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe8293dc-24b9-461b-cf69-54d35a741fd2"
      },
      "source": [
        "# Look at the shape of the dataframe\n",
        "df.shape                                                                                          # SOLUTION "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(498, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mryi3QOLdjQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "3aac9c26-505d-417a-8e04-0c7941c34ee9"
      },
      "source": [
        "# Look at the first rows of the dataframe\n",
        "df.head()                                                                                         # SOLUTION"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>twitter_username</th>\n",
              "      <th>twitter_available</th>\n",
              "      <th>twitter_created_at</th>\n",
              "      <th>twitter_full_text_topic</th>\n",
              "      <th>twitter_full_text</th>\n",
              "      <th>twitter_retweet_count</th>\n",
              "      <th>twitter_favorite_count</th>\n",
              "      <th>twitter_followers_count</th>\n",
              "      <th>twitter_location</th>\n",
              "      <th>twitter_word_count</th>\n",
              "      <th>twitter_year</th>\n",
              "      <th>twitter_month</th>\n",
              "      <th>twitter_week</th>\n",
              "      <th>twitter_time_index_month</th>\n",
              "      <th>twitter_time_index_week</th>\n",
              "      <th>twitter_emojis</th>\n",
              "      <th>twitter_hashtags</th>\n",
              "      <th>twitter_tags</th>\n",
              "      <th>label</th>\n",
              "      <th>topic</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABaerbock15156546001</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-01-11T07:10:00Z</td>\n",
              "      <td>Habe mir das Gro Ko-Sondierungspapier zu Klima...</td>\n",
              "      <td>Habe mir das Gro Ko-Sondierungspapier zu Klima...</td>\n",
              "      <td>111</td>\n",
              "      <td>233</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>32</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#GroKo|#Klima|#Klimadiplomatie|#Merkel|#kohlea...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>239</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABaerbock15210084001</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-03-14T06:20:00Z</td>\n",
              "      <td>Auch weltweit sieht man, dass Angela Merkel s ...</td>\n",
              "      <td>Auch weltweit sieht man, dass Angela Merkel s ...</td>\n",
              "      <td>24</td>\n",
              "      <td>96</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>27</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Merkel|#GroKo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>203</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABaerbock15216341401</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-03-21T12:09:00Z</td>\n",
              "      <td>Der groessten globalen Herausforderung, der Kl...</td>\n",
              "      <td>Der groessten globalen Herausforderung, der Kl...</td>\n",
              "      <td>39</td>\n",
              "      <td>153</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>38</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Klimakrise|#Regierungserklaerung|#Koalitionsv...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>284</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABaerbock15252349801</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-05-02T04:23:00Z</td>\n",
              "      <td>Wir brauchen eine andere Verkehrspolitik - weg...</td>\n",
              "      <td>Wir brauchen eine andere Verkehrspolitik - weg...</td>\n",
              "      <td>49</td>\n",
              "      <td>213</td>\n",
              "      <td>94139</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>38</td>\n",
              "      <td>2018</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Verkehrspolitik</td>\n",
              "      <td>25</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABaerbock15256297201</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-05-06T18:02:00Z</td>\n",
              "      <td>Das ist die Leistung von Hunderten Wahlkaempfe...</td>\n",
              "      <td>Das ist die Leistung von Hunderten Wahlkaempfe...</td>\n",
              "      <td>39</td>\n",
              "      <td>301</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>40</td>\n",
              "      <td>2018</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#kwsh|#kow18|#Kommunalwahl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>positive</td>\n",
              "      <td>Kommunalpolitik</td>\n",
              "      <td>251</td>\n",
              "      <td>266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 doc_id twitter_username  ...  from   to\n",
              "0  ABaerbock15156546001        ABaerbock  ...   239  251\n",
              "1  ABaerbock15210084001        ABaerbock  ...   203  215\n",
              "2  ABaerbock15216341401        ABaerbock  ...   284  296\n",
              "3  ABaerbock15252349801        ABaerbock  ...    25   40\n",
              "4  ABaerbock15256297201        ABaerbock  ...   251  266\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUb6n3OueE5u"
      },
      "source": [
        "# Convert labels to numeric: 1 for \"positive\", 0 for \"negative\" and call the column \"label_binary\"\n",
        "df['label_binary'] = [1 if label == \"positive\" else 0 for label in df.label]                      # SOLUTION"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWqiYQB_dlBw"
      },
      "source": [
        "# Drop NA values in the column \"label\"\n",
        "df = df.dropna(subset=['label'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrOvWVj0dolR"
      },
      "source": [
        "# Get the lists of tweets and their labels.\n",
        "tweets = df.twitter_full_text.values\n",
        "labels = df.label_binary.values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_4pZEWFfT90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d050f1fb-1ccf-43eb-bdab-e55b112b5477"
      },
      "source": [
        "# Print the second tweet in the dataframe (Take care of right indexing!)\n",
        "tweets[1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Auch weltweit sieht man, dass Angela Merkel s Gro Ko 3.0 nicht klimatauglich ist, sondern vielmehr das Pariser Abkommen unterlaeuft. Auch aussenpolitisch fatal. Daher Klimasofortprogramm jetzt auflegen!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QiOSbaOfkRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c91e55-3daa-4cc0-c095-25ff9bc8a347"
      },
      "source": [
        "# Is the sentiment expressed in this tweet negative or positive? Check by printing the label.\n",
        "labels[1]                                                                                         # SOLUTION"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow1HwkWUhPMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38596d4d-d139-442a-d794-2369d861c44c"
      },
      "source": [
        "# Count the occurrences of positive and negative tweets\n",
        "import numpy as np\n",
        "np.count_nonzero(labels == 1)                                                                     # SOLUTION"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugeeuOiwkJiF"
      },
      "source": [
        "GermEval Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm-y_1C6iFZE"
      },
      "source": [
        "# Prepare path to the dataset containg GermEval texts\n",
        "filename_germeval = \"data-germeval-2017-train.tsv\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKmrPBtTja5r"
      },
      "source": [
        "# Load the dataset into a pandas dataframe\n",
        "import pandas as pd\n",
        "germeval = pd.read_csv(filename_germeval, \n",
        "                   sep='\\t',\n",
        "                   header=None, \n",
        "                   names = [\"full_text\", \"0\", \"label\", \"2\"])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NHjRwmajlHC"
      },
      "source": [
        "# Further preprocessing\n",
        "germeval['label_binary'] = [1 if label == 'positive' else 0 for label in germeval.label]\n",
        "germeval = germeval.loc[lambda x: x['label'] != \"neutral\"]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-3Xsv0PJ0X0"
      },
      "source": [
        "# Get the lists of tweets and their labels -> Use only the first 99 rows\n",
        "tweets_germeval = germeval.full_text.values[0:99]\n",
        "labels_germeval = germeval.label_binary.values[0:99]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKWWD02IyBh"
      },
      "source": [
        "First, we need to tokenize our text to be able to feed it into the BERT model. \n",
        "\n",
        "Below an example of tokenized and raw tweet versions is shown. To tokenize the text we have to specify and use the pretrained BERT because each model has a fixed vocabulary (containing tokens, so wordpieces) and the BERT tokenizer handles words which are not in the certain vocabulary in a specific way.\n",
        "\n",
        "Each token is then mapped to their index in the tokenizer vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZL1eSQeVs6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74ae7324-8cca-44c2-fba1-3b3a6a6ded9f"
      },
      "source": [
        "# Print the raw tweet.\n",
        "print('Raw: ', tweets[0])\n",
        "\n",
        "# Print the tweet split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(tweets[0]))\n",
        "\n",
        "# Print the tweet mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw:  Habe mir das Gro Ko-Sondierungspapier zu Klima nochmal genau angeschaut. Krass: De facto wird sogar das Kyoto-Protokoll, der Meilenstein der Klimadiplomatie fuer nichtig erklaert! Frau Merkel, das geht so nicht! Nachbessern! kohleausstieg\n",
            "Tokenized:  ['Hab', '##e', 'mir', 'das', 'Gro', 'Ko', '-', 'Son', '##die', '##rung', '##sp', '##ap', '##ier', 'zu', 'Klima', 'noch', '##mal', 'genau', 'angesch', '##aut', '.', 'Kras', '##s', ':', 'De', 'fa', '##ct', '##o', 'wird', 'sogar', 'das', 'Ky', '##oto', '-', 'Protokoll', ',', 'der', 'Meilen', '##stein', 'der', 'Klima', '##di', '##plomat', '##ie', 'f', '##uer', 'nichtig', 'erk', '##la', '##ert', '!', 'Frau', 'Merkel', ',', 'das', 'geht', 'so', 'nicht', '!', 'Nach', '##besser', '##n', '!', 'ko', '##hle', '##auss', '##ti', '##eg']\n",
            "Token IDs:  [9689, 26897, 3667, 93, 951, 673, 26935, 1343, 2930, 23620, 168, 425, 97, 81, 6914, 357, 446, 2971, 16745, 956, 26914, 26237, 26902, 26964, 576, 20568, 1920, 26910, 292, 2215, 93, 13235, 9857, 26935, 10252, 26918, 21, 17930, 1407, 21, 6914, 3748, 13461, 12, 69, 667, 20719, 895, 129, 335, 26982, 946, 5654, 26918, 93, 1398, 181, 149, 26982, 326, 4379, 26898, 26982, 7424, 2039, 10685, 15099, 640]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZJe8-JoKAaL"
      },
      "source": [
        "In the next step we add special tokens to the start *CLS* and end of each tweet *SEP*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKR6G5w4dFsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb591972-9934-49ff-f70a-e7f1bd1beaa2"
      },
      "source": [
        "# Tokenize all of the tweets and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every tweet...\n",
        "for tweet in tweets:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded tweet to the list.\n",
        "    input_ids.append(encoded_tweet)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Habe mir das Gro Ko-Sondierungspapier zu Klima nochmal genau angeschaut. Krass: De facto wird sogar das Kyoto-Protokoll, der Meilenstein der Klimadiplomatie fuer nichtig erklaert! Frau Merkel, das geht so nicht! Nachbessern! kohleausstieg\n",
            "Token IDs: [3, 9689, 26897, 3667, 93, 951, 673, 26935, 1343, 2930, 23620, 168, 425, 97, 81, 6914, 357, 446, 2971, 16745, 956, 26914, 26237, 26902, 26964, 576, 20568, 1920, 26910, 292, 2215, 93, 13235, 9857, 26935, 10252, 26918, 21, 17930, 1407, 21, 6914, 3748, 13461, 12, 69, 667, 20719, 895, 129, 335, 26982, 946, 5654, 26918, 93, 1398, 181, 149, 26982, 326, 4379, 26898, 26982, 7424, 2039, 10685, 15099, 640, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ_QN3DKkUFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aa943e1-52e7-4cf2-e4c6-4e80d02f5f94"
      },
      "source": [
        "# Do the same for GermEval \n",
        "input_ids_germeval = []\n",
        "\n",
        "# For every tweet...\n",
        "for tweet_germeval in tweets_germeval:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet_germeval,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded tweet to the list.\n",
        "    input_ids_germeval.append(encoded_tweet)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets_germeval[0])\n",
        "print('Token IDs:', input_ids_germeval[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (664 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  @nordschaf theoretisch kannste dir überall im Kölner Stadtbereich was suchen. Mit der KVB + S-Bahn kommt man überall fix hin.\n",
            "Token IDs: [3, 26991, 3194, 17051, 23888, 479, 116, 14843, 10151, 106, 8104, 560, 1859, 961, 8083, 26914, 304, 21, 20578, 26925, 26986, 24, 26935, 1621, 1471, 478, 10151, 19004, 461, 26914, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk4o_F6XKIUF"
      },
      "source": [
        "Then we pad and truncate all tweets to a constant fixed length "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_tBkChIdyOC",
        "outputId": "b2ca7e8c-9f4c-4275-a5da-f4d7ffaff0ea"
      },
      "source": [
        "print('Max sentence length: ', max([len(tweet) for tweet in input_ids]))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTux34E5kYND",
        "outputId": "1ad0dc79-f1f0-4e73-d7b0-808fadc45713"
      },
      "source": [
        "print('Max sentence length for GermEval data: ', max([len(tweet_germeval) for tweet_germeval in input_ids_germeval]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length for GermEval data:  698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTtngalseGJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bd97dd-4af6-4dd5-a7ec-639c077d51b8"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# A bit larger than the maximum training tweet length of 91/110... (with germeval 3202/3300 -> bert has a max length limit of tokens = 512, we cut the longer texts off and only use the first 512 Tokens)\n",
        "MAX_LEN = 250\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" - pad and truncate at the end of the sequence, as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Pad our input tokens with value 0 for Germeval data \n",
        "input_ids_germeval = pad_sequences(input_ids_germeval, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 250 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vstmJJnvOEJ6"
      },
      "source": [
        "Create attention masks which indicates which tokens are words and which are padding (if token ID is 0 then it is padding and the attention mask is set to 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoRYw4_jg4QP"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for tweet in input_ids:\n",
        "    \n",
        "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
        "    \n",
        "    # Store the attention mask for each tweet.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yinz_P3vk1oJ"
      },
      "source": [
        "# Create attention masks for Germeval data \n",
        "attention_masks_germeval = []\n",
        "\n",
        "# For each sentence...\n",
        "for tweet_germeval in input_ids_germeval:\n",
        "    \n",
        "    att_mask = [int(token_id > 0) for token_id in tweet_germeval]\n",
        "    \n",
        "    # Store the attention mask for each tweet.\n",
        "    attention_masks_germeval.append(att_mask)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vp0fFEsOifw"
      },
      "source": [
        "Now, we use train_test_split to split our data into train, test sets first  and then split the initial train set further into a final train set and validation set for training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UT0FM31qLDR"
      },
      "source": [
        "## EXERCISE 3:\n",
        "*Split into Train Test Sets.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV4b99xCgEsu"
      },
      "source": [
        "# Without-GermEval-case\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "train_inputs2, test_inputs, train_labels2, test_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state = 2021, test_size = 0.2, stratify = labels)       # SOLUTION\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks2, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state = 2021, test_size = 0.2, stratify = labels)                      # SOLUTION\n",
        "\n",
        "\n",
        "# Use 20% of train set as validation set \n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs2, train_labels2, \n",
        "                                                                                    test_size = 0.2, random_state = 2021)  # SOLUTION\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(train_masks2, train_labels2,                                        # SOLUTION\n",
        "                                             random_state=2020, test_size=0.2)    "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPxoRdC5-7YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bdb806c-e4c6-4a6b-be49-0ca31965119b"
      },
      "source": [
        "# How many training tweets do you have? \n",
        "len(train_inputs)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lUovm-xmGbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac0abce-4a25-4918-9314-f134aef33791"
      },
      "source": [
        "# How many test tweets do you have? \n",
        "len(test_inputs)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTBu9v-qteI"
      },
      "source": [
        "## EXERCISE 4:\n",
        "*Additionally use Germeval Dataset for Training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHDnNsImhFKd"
      },
      "source": [
        "# Use additionall Germeval data for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "train_inputs1, test_inputs, train_labels1, test_labels = train_test_split(input_ids, labels,                                # SOLUTION\n",
        "                                                            random_state=42, test_size=0.2, stratify = labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks1, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=42, test_size=0.2, stratify = labels)\n",
        "\n",
        "# Mix train_inputs1, train_labels1, train_masks1 with germeval data\n",
        "train_inputs2 = np.concatenate((train_inputs1, input_ids_germeval), axis=0)\n",
        "train_labels2 = np.concatenate((train_labels1, labels_germeval), axis=None)\n",
        "train_masks2  = np.concatenate((train_masks1, attention_masks_germeval), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# Use 20% of train set as validation set \n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs2, train_labels2,           # SOLUTION\n",
        "                                                                                    test_size=0.2, random_state=2020) \n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(train_masks2, train_labels2,                                         # SOLUTION\n",
        "                                             random_state=2020, test_size=0.2)    "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTaFTXqFO080"
      },
      "source": [
        "Convert all inputs and labels into torch tensors, the required datatype \n",
        "for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg71HZ7qifpo"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFLnUkVxsCTS"
      },
      "source": [
        "## EXERCISE 5:\n",
        "*Try another set of hyperparameters recommended by BERT-authors.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDKmSSbxrwbg"
      },
      "source": [
        "\n",
        "We chose following values based on authors' recommendations:\n",
        "\n",
        "Batch size: 32 \n",
        "Learning rate (Adam): 2e-5\n",
        "Number of epochs: 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SQQwH_VrL63"
      },
      "source": [
        "# Define batch size here to let DataLoader know. \n",
        "# BERT-authors recommend a batch size of 16 or 32 for fine-tuning .\n",
        "batch_size = 16"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LXM1YHwrRQC"
      },
      "source": [
        "# Define the learning rate \n",
        "learning_rate = 2e-5"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJka_WQrms8"
      },
      "source": [
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeutTU9Hr0pB"
      },
      "source": [
        "The torch DataLoader class enables to create  an iterator for our data in order to save memory during training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBRWzCgriurl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIEy4SR4R6ch"
      },
      "source": [
        "Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "linear classification layer on top. This is the one for classification tasks in general. *(see for more details https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xILaX9ulICZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "95955dce3dc24593808009d06898abb7",
            "78a71bdbbbe14aa295c1a0e034ee551c",
            "7b93b2b2e9eb4af6ab7d7e6e9ab46922",
            "e2eaf2690510405fba3d50b68f204be7",
            "a8f20a1e25444e4f9643e720b1666dc4",
            "d6a708802fe54ae6b6b4abd8d779c1a4",
            "0dbb83e6294c488eabeee5c879a2fef2",
            "f5071e20e95a4ff886b798bad08b7f78",
            "154f2c1d04914a96a040ca62533aa748",
            "055a5f9146ac41a985914c77bfca9406",
            "69db14ae7e1a49e1be4c1872ab896512",
            "8e72f756a09a4872b107cdb15212eb35",
            "87c333568cdf44c58776827668195b4f",
            "4f9e04da47024e16a1f2fd204a8228ae",
            "2039b0a49e3e4e51874847fdb4acdae0",
            "9183019ccf524c4a99fc416025ca35f3"
          ]
        },
        "outputId": "ebe67e71-6875-43c8-a0d2-5ac12095f6dd"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    pretrained_model, \n",
        "    num_labels = 2, # The number of output labels--2 for binary classification. Can be increased for multiclass\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False \n",
        ")\n",
        "\n",
        "# Run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95955dce3dc24593808009d06898abb7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "154f2c1d04914a96a040ca62533aa748",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438869143.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wddbSBdwl6MM"
      },
      "source": [
        "# All of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOogCCNSS1_z"
      },
      "source": [
        "Get the optimizer after loading the model. \n",
        "\n",
        "*(see for more details on AdamW Optimizer https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5YMJeG7m1GW"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate, \n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TypGI2W5m5X9"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fgx-tuPnc8Z"
      },
      "source": [
        "# helper function for calculating accuracy\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcSWb-YhpNo4"
      },
      "source": [
        "# helper function for formatting elapsed times\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTwfA1dVrJFv"
      },
      "source": [
        "## EXERCISE 6:\n",
        "*Fine-tune your model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgc1fHkwTxaf"
      },
      "source": [
        "Let's start the actual training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acrG210Npcb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d93cb6b-8a26-467e-946d-e1df1d877f27"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 55\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch:\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    ## TRAIN\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # how long does the training epoch take.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Turn on the training mode for the model. \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data:\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack the batch and load onto the GPU.\n",
        "        # Each batch contains input ids, attention masks, labels. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Remove any previously calculated gradients before performing a\n",
        "        # backward pass. \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Do a forward pass. \n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. \n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Do a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0. \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step.\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Avg loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Need for plotting the learning curve later.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Avg training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Epoch time: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    ## VALIDATE\n",
        "    # After each training epoch, we measure performance on\n",
        "    # validation set.\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Turn on the evaluation mode of the model.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get logit values predicted for each class.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Accuracy for this batch of validation tweets.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation time: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.51\n",
            "  Epoch time: 0:00:16\n",
            "  Accuracy: 0.79\n",
            "  Validation time: 0:00:01\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.31\n",
            "  Epoch time: 0:00:16\n",
            "  Accuracy: 0.79\n",
            "  Validation time: 0:00:01\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.15\n",
            "  Epoch time: 0:00:17\n",
            "  Accuracy: 0.84\n",
            "  Validation time: 0:00:02\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.07\n",
            "  Epoch time: 0:00:17\n",
            "  Accuracy: 0.81\n",
            "  Validation time: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKJGT2uxqsNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "e38d9c9f-0bd3-41db-c7d8-21222f097ddb"
      },
      "source": [
        "# Visualize the training results\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVV9-_GMY76z"
      },
      "source": [
        "# Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tocnbPMDRN00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c69b1a5-3789-44bf-f767-af3972b9ed5e"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test tweets...'.format(len(test_inputs)))\n",
        "\n",
        "# Turn on the evaluation mode of the model\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Compute gradients, save memory and speed up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 100 test tweets...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOIrNxOukbY6",
        "outputId": "7cb42cae-cdc1-4a6a-9cda-4f1f18723194"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label_binary.sum(), len(df.label_binary), (df.label_binary.sum() / len(df.label_binary) * 100.0)))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 106 of 498 (21.29%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iNrCwTYa6cI"
      },
      "source": [
        "Performance measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YzWo-1qp3kn"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd4kOBthmifT"
      },
      "source": [
        "# List of keys of the highest scores, i.e. predictions (indices of the maximum values along an axis)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGWTUvMEmjqv"
      },
      "source": [
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x7g2bzgb-o9"
      },
      "source": [
        "Calculate F1-Score, Accuracy and Show the Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haL4-Mwpqm-i"
      },
      "source": [
        "## EXERCISE 7:\n",
        "*Print out the accuracy score.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAoOFsCUwsLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4a2cac-1ba2-41dc-ab9f-29e059d88223"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "# F1-Score (weighted)\n",
        "f1_value = f1_score(flat_predictions, flat_true_labels, average=\"weighted\")\n",
        "\n",
        "# Accuracy Score\n",
        "accuracy = accuracy_score(flat_predictions, flat_true_labels)                         # SOLUTION\n",
        "\n",
        "print(\"F1 Score (Weighted): {}\".format(f1_value))\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score (Weighted): 0.8909955514649487\n",
            "Accuracy: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s22lIKFxrOu"
      },
      "source": [
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    cm = confusion_matrix(y_true=true_labels, \n",
        "                                  y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "    cm_frame = pd.DataFrame(data=cm, \n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
        "                                                  codes=[[0,0],[0,1]]), \n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
        "                                                codes=[[0,0],[0,1]])) \n",
        "    return cm_frame   "
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aARx5G5vy5vZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "2fa8e6f7-41b5-4ef1-fa82-ef438936b7b8"
      },
      "source": [
        "confusion_mat = display_confusion_matrix(true_labels = flat_true_labels, predicted_labels = flat_predictions)\n",
        "confusion_mat"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Predicted:</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Actual:</th>\n",
              "      <th>1</th>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted:    \n",
              "                   1   0\n",
              "Actual: 1         15   6\n",
              "        0          5  74"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}