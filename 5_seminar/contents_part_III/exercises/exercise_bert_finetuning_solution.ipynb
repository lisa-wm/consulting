{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exercise_bert_finetuning_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2eb5e1c1bfc64bf1877ab1368333f15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8dec96fc80414898a7845a1d67ae211e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a244faa1d67c4d55a3987fffe2a803ae",
              "IPY_MODEL_9fcbc618ab2d4b2f8e2ab384585d9cb9"
            ]
          }
        },
        "8dec96fc80414898a7845a1d67ae211e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a244faa1d67c4d55a3987fffe2a803ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7cabb6345a814d61a0031b5d920257c0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b749ba92aa34bf7912620ad94057185"
          }
        },
        "9fcbc618ab2d4b2f8e2ab384585d9cb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ba580d08de234c12b4109e7b78c7aaef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.66kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2df10737c1c34f91bf3ac6462b0aa79f"
          }
        },
        "7cabb6345a814d61a0031b5d920257c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b749ba92aa34bf7912620ad94057185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba580d08de234c12b4109e7b78c7aaef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2df10737c1c34f91bf3ac6462b0aa79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "956e67eb161c4857a475de372038255b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_917d0c57fda847dcae8f6b20ca120a12",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b11ca002fce1405d943bfa34c6bcd25d",
              "IPY_MODEL_cba1ee86beff4a1299d1abdf501d0495"
            ]
          }
        },
        "917d0c57fda847dcae8f6b20ca120a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b11ca002fce1405d943bfa34c6bcd25d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ca8346678fc649959558f12ab1e54fa7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 438869143,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 438869143,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_922b33e932c04ff1be584ba62e90e6d9"
          }
        },
        "cba1ee86beff4a1299d1abdf501d0495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eff69413af5343cc8d02e8a25d5caf48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 439M/439M [00:11&lt;00:00, 37.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_794d15ec432942bfbf2e59f139f7f775"
          }
        },
        "ca8346678fc649959558f12ab1e54fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "922b33e932c04ff1be584ba62e90e6d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eff69413af5343cc8d02e8a25d5caf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "794d15ec432942bfbf2e59f139f7f775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09FrEZkpUv0F"
      },
      "source": [
        "***\n",
        "# Solution: BERT Fine-Tuning (pure)\n",
        "***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WrhLjZdVN49"
      },
      "source": [
        "*By Asmik Nalmpatian and Lisa Wimmer – for Intro to NLP*\n",
        "\n",
        "*Methodology based on: https://arxiv.org/pdf/1810.04805.pdf*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shmCbiSwlDNV"
      },
      "source": [
        "![Logo_Consulting.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYABgAAD/4RDgRXhpZgAATU0AKgAAAAgABAE7AAIAAAAHAAAISodpAAQAAAABAAAIUpydAAEAAAAOAAAQyuocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5BTE1QSQAAAAWQAwACAAAAFAAAEKCQBAACAAAAFAAAELSSkQACAAAAAzQ1AACSkgACAAAAAzQ1AADqHAAHAAAIDAAACJQAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIxOjAzOjIxIDIxOjQwOjE1ADIwMjE6MDM6MjEgMjE6NDA6MTUAAABOAEEATABNAFAASQAAAP/hCxlodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvADw/eHBhY2tldCBiZWdpbj0n77u/JyBpZD0nVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkJz8+DQo8eDp4bXBtZXRhIHhtbG5zOng9ImFkb2JlOm5zOm1ldGEvIj48cmRmOlJERiB4bWxuczpyZGY9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkvMDIvMjItcmRmLXN5bnRheC1ucyMiPjxyZGY6RGVzY3JpcHRpb24gcmRmOmFib3V0PSJ1dWlkOmZhZjViZGQ1LWJhM2QtMTFkYS1hZDMxLWQzM2Q3NTE4MmYxYiIgeG1sbnM6ZGM9Imh0dHA6Ly9wdXJsLm9yZy9kYy9lbGVtZW50cy8xLjEvIi8+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iPjx4bXA6Q3JlYXRlRGF0ZT4yMDIxLTAzLTIxVDIxOjQwOjE1LjQ0OTwveG1wOkNyZWF0ZURhdGU+PC9yZGY6RGVzY3JpcHRpb24+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iPjxkYzpjcmVhdG9yPjxyZGY6U2VxIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpsaT5OQUxNUEk8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgA9QHmAwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+jy6g4Jo8xfX9KhmYKzMxwoGST2rg9Z8TXF7M0VnI0NsDgFThn9yf6VvRoSrO0Tnr4iFCN5HoJmjHVwKTz4v+ei/nXkZZiclmJ+tGW9TXb/Z/wDe/A8/+0v7v4/8A9c8+L/nov50efF/z0X868jy3qaMt6mn/Z/978A/tL+7+P8AwD1zz4v+ei/nR58X/PRfzryPLepoy3qaP7P/AL34B/aX938f+AeuefF/z0X86PPi/wCei/nXkeW9TRlvU0f2f/e/AP7S/u/j/wAA9c8+L/nov50efF/z0X868jy3qaMt6mj+z/734B/aX938f+AeuefF/wA9F/Ojz4v+ei/nXkeW9TRlvU0f2f8A3vwD+0v7v4/8A9c8+L/nov50efF/z0X868jy3qaMt6mj+z/734B/aX938f8AgHrnnxf89F/Ojz4v+ei/nXkeW9TRlvU0f2f/AHvwD+0v7v4/8A9c8+L/AJ6L+dHnxf8APRfzryPLepoy3qaP7P8A734B/aX938f+AeuefF/z0X86PPi/56L+deR5b1NGW9TR/Z/978A/tL+7+P8AwD1zz4v+ei/nR58X/PRfzryPLepoy3qaP7P/AL34B/aX938f+AeuefF/z0X86PPi/wCei/nXkeW9TRlvU0f2f/e/AP7S/u/j/wAA9c8+L/nov50vnxHo4/OvIst6mjcw7kfjS/s/+9+Af2l/d/H/AIB695i+v6UB1JwDXnGk+I7rT5VWZ2nt+jIxyVHqDXoFtKk6xyxMGRxuUjuMVx1qEqL1O+hiIV1puWaKKK5zpCiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAMPxTM0Oh3RQ4LAJn2JGa4fR7Nb/AFa3tpPuO3zY7gDJ/lXaeL/+QFP/ALyfzrlPDH/Ix23/AAL/ANBNethXy4eUl5/keNi1zYqEXtp+Z3sdtBDGI4oY0RRgAKOKf5Uf9xf++RTqK8q7PYshvlR/3F/75FHlR/3F/wC+RTqKLsLIb5Uf9xf++RR5Uf8AcX/vkU6ii7CyG+VH/cX/AL5FHlR/3F/75FOoouwshvlR/wBxf++RR5Uf9xf++RTqKLsLIb5Uf9xf++RR5Uf9xf8AvkU6ii7CyG+VH/cX/vkUeVH/AHF/75FOoouwshvlR/3F/wC+RR5Uf9xf++RTqKLsLIb5Uf8AcX/vkUeVH/cX/vkU6ii7CyG+VH/cX/vkUeVH/cX/AL5FOoouwshvlR/3F/75FHlR/wBxf++RTqKLsLIb5Uf9xf8AvkUeVH/cX/vkU6ii7CyG+VH/AHF/75FNeCGRCrxIykYIKg5qSii7CyPOvEFjHp2sSQwDEbAOo/u57V1ng2ZpdFRW58uRlH06/wBa53xh/wAh8/8AXFf61veCf+QQ3/XZv5CvVrtywsW/I8fDpRxckttTpqKKK8k9kKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA5/xf/yAp/8AeT+dcp4Y/wCRjtv+Bf8AoJrq/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAqOe4htojJcSLEg/iY4rH1rxLDpu6C3Amue4/hT6/4Vxd5fXN/MZbuVpG7Z6D6DtXbQwk6nvS0RwYjGwpPljqzrbzxlaRErZxPcH+8flX/GsefxfqcufL8qEf7KZP61hUV6UMLRj0ueVPGVp9behpN4h1ZjzeyD6AD+lKniPVkPF45/3gD/SsyitvZU/5V9xj7ar/ADP7zorfxlfRkfaIoph3wNprasfFen3ZCzFrZz2k+7+dcHRWE8HSlsrHRTxtaG7v6nq6sGUMpDKeQQetLXm+ma1eaW48h90WeYn5U/4V3OlaxbatDugO2RR88TdV/wAR715dfCzpa7o9bD4uFbTZl+iiiuU7AooooAKKKKACiiigAooooAKKKKAOE8Yf8h8/9cV/rW94J/5BDf8AXZv5CsHxh/yHz/1xX+tb3gn/AJBDf9dm/kK9Wt/ukfkePR/32XzOmoooryj2AorM1bWo9LmgRl3mQ5cDqq+taEM0c8KywsHRhkMO9W6clFSa0ZEakZScU9UPoooqCwooooAKKKKACiiigAooooAKKKKACiisDV/EqWzNBY4klHBkPKr/AImtKdKdWXLFGVWrClHmmzauLmG1j33Eqxr6scVjXPiy0iJFtHJOfX7orlLi5mupTJcSNI57sair1qeAgvjdzx6uYzfwKx0Eni+6P+rt4VHuSaYPFt8DzFAf+An/ABrCorp+q0f5Tl+t1/5jpofGDZ/f2gI9Uf8AxrVtPEOn3ZCiXynP8Mox+vSuEorKeBoy20NoY+tHfU9OByMjkUVwOn6zeacwEUm+PvG/I/8ArV12mazbamuEPlzAfNGx5/D1rzK2EnS13R6tDGU62mzNCioJ721th+/uI4/ZmGay7rxVZQ5FuHuG9htH5msYUak/hRvOtTp/FI26jFxE1wYFkUyqMlQckD3ri73xHfXeVV/Ij/ux9fzrofDunGysPMmGJpzubPUDsK3qYZ0oc03r2OenilWqctNadWa9FFFcZ2nP+L/+QFP/ALyfzrlPDH/Ix23/AAL/ANBNdX4v/wCQFP8A7yfzrlPDH/Ix23/Av/QTXq4f/dZ/P8jx8V/vcPl+Z6FRRRXlHsBXOeJPEBslNnZN/pDD53H/ACzHp9a0tb1MaVprTDBlb5YlPc+v4V507tLIzyMWdjlie5r0MHh1N88tjzcbiXTXs4bsaSSSSck9SaKKK9k8IKKKKACiiigAooooAKltrmW0uFmt3KSKcgioqKGk1ZjTad0ejaLrEer2m4YSZOJE9Pce1aVeY6bfy6bfJcw/w8Mv95e4r0q3njureOeE7kkUMprwsVQ9lK62Z9Dg8R7aNpbokooorjO0KKKKACiiigAooooAKKKKAOE8Yf8AIfP/AFxX+tb3gn/kEN/12b+QrB8Yf8h8/wDXFf61veCf+QQ3/XZv5CvVrf7pH5Hj0f8AfZfM6aiiorqTybOaQfwIzfkK8tK7seu3ZXOF1m7+2atPJnKq2xfoOKk0fWZdLl2tl7dj8yenuKzM55PWivpnSi4eza0PlVWmqntE9T0m3uYruBZrdw6N0IqWvPdO1O40ybfA2VP34z0au103VbbU4swttkA+aNuo/wAa8TEYWVJ3WqPew2LjWVnoy7RRRXGdoUUUUAFFFFABRRRQAUUVn61qH9naa8in963yx/X1/CqhFzkorqROahFyfQyfEWtlWaxs2wekrg9P9kVy9KSWJJOSTkk96SvpKNKNKPLE+YrVpVp80gooorUxCiiigAooooAKUEg5BwfUUlFABRRWrpv9lW22e/laaQciFEJA+vrUzlyq9rlwhzu17F3w/oRmdby8XEQ5jQ/xH1PtXWVzk3i+FRi3tXb03kL/AI1UTW9W1W5FvZ7Ii3XYv3R6kmvIq0a9aXPPRHs0q2HoR5Iavy6nXUVBZ232W3CGRpX6vI5yWNFec7J6Hpq7WpjeL/8AkBT/AO8n865Twx/yMdt/wL/0E11fi/8A5AU/+8n865Twx/yMdt/wL/0E16mH/wB1n8/yPIxX+9w+X5noVFFQ3k/2WymnP/LNC35CvLSu7HrtpK7OH8U3/wBs1ho1OYrf5F579z/n0rFpWYuxZuWY5J96SvpacFCCiuh8rUm6k3J9QoooqzM3fDehJqkjz3Wfs8ZxtBxvPp9Kv+IPDVvBZNd6ehQxDLx5JBHqK1vC8YTw7blR97cx+uTWnNGJYJI26MpU/iK8WpiZqu2nome9SwlN0EmtWtzyqlVS7BVGWY4AHc0hGCR6Vo6BGsuv2ivyPMzj6DNexKXLFy7HhwjzSUe51Fj4TsY7MLeoZZ2HzNuI2n0GK5XWdMbStQaAktGRujY9xXpNct43iHk2kv8AEGZfwxmvJwuInKraT3PaxeGpxo3irWOQooor2Dwwrr/Bl+WjlsZD9z95H9O4/wA+tchV/Q7r7JrVtJnCl9jfQ8VhiKftKTR0Yap7Oqmek0UUV86fThRRRQAUUUUAFFFFABRRRQBwnjD/AJD5/wCuK/1re8E/8ghv+uzfyFYPjD/kPn/riv8AWt7wT/yCG/67N/IV6tb/AHSPyPHo/wC+y+Z01VtRUvpdyo6mJv5VZpGUMpVuhGDXlxdmmetJXTR5lRU11A1rdywP1jYrUNfVJpq6PkmmnZhT45HhkWSJ2R1OQynBFMooFsdRpnioHbFqQwennKP5j/CukilSaMPE6uh6MpyDXmdWbO/ubGTfaysnqOoP1FedWwMZaw0f4Hp0MwlDSpqvxPRaK5yx8WRPhb+Ixt/fTkfl1ret7qC6j320qSL6qc15dSjUp/Ej16denVXuMlooorE2CiiigArj/FdyZNSSAH5YU6e5/wDrYrsK4DW2L65dE9nx+Qr0MBG9W/ZHnZjJqkl3ZQooor2zwAooooAKKKKACiiigAooooAKKK1NG0V9VZnLiOFDhj3J9BUznGEeaWxcISqS5YrUqWNhPqFwIrdcn+Jj0UepruNM0yHTLfy4huc/fkI5Y1NaWcFjAIraMIo/M+5qevCxGKlW0WiPfwuEjRXM9ZBRRRXGdxz/AIv/AOQFP/vJ/OuU8Mf8jHbf8C/9BNdX4v8A+QFP/vJ/OuU8Mf8AIx23/Av/AEE16uH/AN1n8/yPHxX+9w+X5noVZHiiQx+HrjH8W1fzIrXrE8W/8i/J/wBdF/nXBQ1qx9T0cQ7UZejOCooor6M+XCiiigB6zSquFkdR6BiKXz5v+e0n/fZqOilZDuwpQxVsqSCOhBxU0djdyrmO1mYeojJpstrcQf6+CSMf7aEUc0XpcfLJK9hPPm/57Sf99mmtI7/fdmx03MTTaKLIV2FFABJAAyT0A71vab4TvLsCS6P2aI9mGWP4dvxqZ1IU1eTLp0p1HaCuYNTW9tcTODbQSSEHI2ITXfWXhzTbLBEAlcfxy/N+nStNQFUKoCgdABivPnj47RR6VPLpbzlYEJKKSMEgZBpaKK8k9kKKKKACiiigAooooAKKKKAOE8Yf8h8/9cV/rW94J/5BDf8AXZv5CsHxh/yHz/1xX+tb3gn/AJBDf9dm/kK9Wt/ukfkePR/32XzOmoooryj2Dl/FWmnct/EOOFlx29D/AE/KuZr0ySNJY2jkUMjDBB7iuG1nR5NMnyuWt3PyP6exr2cFiFJezlv0PDx2GcZe1js9zMooor0jywooooAKfHI8Th4nZGHQqcGmUUAbFt4m1C3wJGWdf+mg5/MVrW/i62fi5gkiPqvzCuRormnhaM90dcMZWhs/vPQINa064x5d3GD6Odp/WrqurjKMGHqDmvMqckjxnMbsp/2TiuWWXR+zI645lL7UT0yuE8QxGLXJ/R8OPxFQR6rfxfcvJh7F8/zqK6vJ72QSXUnmOo2gkAcVphsLOjPmvdGeKxcK9PlSsyCiiiu880KKKKACiiigAooooAKKKKACuv8ACK402Y+sv9BXIV2vhZNuig/3pGP9P6VxY52o/M78vV6/yNmiiivBPoQooooA5/xf/wAgKf8A3k/nXKeGP+Rjtv8AgX/oJrq/F/8AyAp/95P51ynhj/kY7b/gX/oJr1cP/us/n+R4+K/3uHy/M9CrM8Rwmfw/dAdVUP8Akc1p0yaJZ4Xif7rqVP0NebCXLJS7Hq1I88HHueVUVJPC1vcSQyDDRsVP4VHX0yd9T5Rqzswoop0cbSyLHGMs5CqPUmgRc0vSrjVrryoBtVeXkPRRXcadoNjpyjy4hJL3lkGSf8Km0vTo9M09LeMDcBl2/vN3NXK8LEYqVR2jsfQ4bCRpRvJXkFIwDKVYBgeoIzmlorjO4wdV8LWt4rSWYFvP14+631Hb8K5KHSb2bUTZLCRMp+YHoo9SfSvS6QKoYsFAY8E45NdlLGVKcWnqcNbBU6klJadzK0jw/a6WocgTXHeRh0+g7VrVFdXUNnbtNcyCONepNcVq3im5vS0VmWt4OmQfmb6ntUwp1cTK/wCJdSrSwseX8Dqb/XbDTsrPMGk/55x/M3/1qwbnxrISRZ2iqP70rZP5CuWor0qeCpR+LU8qpj6svh0NiTxVqznidU9ljFRjxJqwP/H43/fK/wCFZdFdHsaS+yvuOb29V/af3m5D4t1SM/O0co9GTH8q1LTxrExC3ts0f+3Gdw/KuPorOWFoy6GkMXWh9r7z1C0v7W/j32kyyDuAeR9RVivKoZpLeUSQSNG69GU4NdZo3iwSMsGqYVjwsw4B+vp9a8+tgpQ1hqj06GPjN8s9H+B1NFAORkcg9DRXnnpBRRRQBwnjD/kPn/riv9a3vBP/ACCG/wCuzfyFYPjD/kPn/riv9a3vBP8AyCG/67N/IV6tb/dI/I8ej/vsvmdNUV0WFnMYzhxG20jscVLQRkEHoa8tOzueu1dWOQtPFl1GALqJZx/eHyt/hWl/wkel3kJiu0dVYYZXTI/SuUu4DbXk0LdY3K1DXvywlGfvJW9D52OMrw91u/qXtRtrSGTfYXSzQseF6Mv+NUaKK6oppWbuckmpO6VgooopkhRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABXf6HF5OiWqnglN358/1rg44zLKka9XYKPxr0mNBFEka9FUKPwrzMwl7sYnrZbH3pSHUUUV457QUUUUAc/4v/5AU/8AvJ/OuU8Mf8jHbf8AAv8A0E11fi//AJAU/wDvJ/OuU8Mf8jHbf8C/9BNerh/91n8/yPHxX+9w+X5noVFFFeUewcX4w04w3q3sY+Sbh/Zh/iP5VzdeoX1nHqFlJbTD5XHX+6exrza9s5bC8e3uBh0PXsR6ivbwdZThyPdHg46g4T51s/zIKs6ddrY6hFcvF5oiO4JnGT2qtRXa0pKzPPi3F3R1v/CcD/nwP/f3/wCtR/wnA/58D/39/wDrVyVFc31Oh2/M6/rtf+b8Edb/AMJwP+fA/wDf3/61A8bbmCrp5JJwAJev6VyVdD4R00XN813KMx2/3c93/wDrVnUw9CnBya/M1pYnE1ZqClv5I7SFneFGlTy3IyyZztPpmmXV1FZWr3Fw22NBkn19qmrhPE+rm/vjbwt/o8Bxx/E3c/0rzKFF1p26Hq4iuqFO/Upavq8+rXW+QlYlP7uPPCj/ABrPoor34xUVyxPm5SlOXNLcKKKKokKKKKACiiigAooooA6Pw54hNo62d6+YGOEcn/Vn0+n8q7WvJ67bwpq5u7Y2Vw2ZYRlCf4l/+tXlYzDpL2kfmexgcS2/ZT+X+R0VFFFeWeucJ4w/5D5/64r/AFre8E/8ghv+uzfyFYPjD/kPn/riv9a3vBP/ACCG/wCuzfyFerW/3SPyPHo/77L5nTUUUV5R7ByXiuxMd0l4g+SQbX9mHT9P5Vz1ekXdrHe2r28wyjjH0964C/sZtPu2gnHI5VuzD1Fe5gq6nDke6PAx1Bwn7RbP8ytRRRXeecFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFAGp4dtvtOtRZHyxZkP4dP1xXdVz/hO08uzkumHMrbV+g/+v/KugrwcbU56rXY+iwNPkopvrqFFFFcR3BRRRQBz/i//AJAU/wDvJ/OuU8Mf8jHbf8C/9BNdX4v/AOQFP/vJ/OuU8Mf8jHbf8C/9BNerh/8AdZ/P8jx8V/vcPl+Z6FRRRXlHsBWZreixavbY4S4Qfu5P6H2rToqoylCXNHcicIzjyy2PLLq1ms7hoLlCki9Qf51FXpmo6Va6pD5d0nI+644ZfpXF6n4avdPJeNTcQj+NByPqK9uhi4VFaWjPBxGDnSd46ox6KKK7DhCvR9Bs/sOiwRkfOy73+p5rgdPt/tWpW8HXzJFB+mea9P8ApXmZhPRQPWy2Gsp/IzPEF/8A2fo8rocSyfu0+p7/AJV51XS+NLrffQWwPEabyPc//WFc1W+Dp8tK/c58dU561uwUUUV2HCFXYtH1Ce1+0RWsjRYyGA6j2HejSLMX+rW9u/3GbLfQcmvSlAVQqgAAYAHauLE4l0WoxWp34XCKunKT0PKKK3PFditpq/mRrhLhd+B/e71h11U5qpBSXU5KkHTm4PoSQQS3MyxQRtJI3RVHJqa802708r9sgaLd0J6H8a6nwbZLHYyXjDMkrFFPoo/+vW1qlkmoabNbuASykqfRh0NcVTGclXktod9PA89Hnvq9jzKijGOD1or0DzAqxYXj2F9Fcx9Y2yR6juPyqvRSaTVmNNp3R6tHIssSSRnKuoZT6g06sXwrdG40KNW+9Cxj/DqP51tV81UjyTcex9VTn7SCl3OE8Yf8h8/9cV/rW94J/wCQQ3/XZv5CsHxh/wAh8/8AXFf61veCf+QQ3/XZv5CvSrf7pH5Hl0f99l8zpqKKK8o9gKqahp0GpW/lTjkcq46qat0VUZOLuiZRUlaWxwOpaPdaaxMi74s8SqOPx9Kz69EGo2Mu5PtMJIJVlZgPwway73RtHny6zx2zeqSDH5V69LGParE8WrgVvSkrHH0VcvrO3tWxBfR3PPRVPH49Kp16MZKSujzZRcXZhRRRTJCiiigAooooAKKKKACiiigAooooAKKKKACiiigAqSCF7m4jhjGXkYKKjrpfCmn7ne+lXhfljz69z/T86yrVFSg5G1Ck6tRQR0ltAlraxwR/djUKKloor5ptt3Z9SkkrIKKKKQwooooA5/xf/wAgKf8A3k/nXKeGP+Rjtv8AgX/oJrq/F/8AyAp/95P51ynhj/kY7b/gX/oJr1cP/us/n+R4+K/3uHy/M9Coooryj2AooooAKKKKAKF5oun3xJuLZd5/jX5W/MVkT+CrdmJt7qSMejqG/wAK6aitoV6sPhZhPD0qmsonNaZ4Vl0/VIrprmORIyTtCkHpiulooqalWVV3kVSpQpLlged+JJPN8Q3X+ywX8gKy6v65n+3rzP8Az1NUK+hpK1OK8kfNVnepJ+bCiiitDIv6LqCaXqS3MsbSKFI2qeea6P8A4Ta1/wCfOb/voVxtFc9TD06kuaSOmliatKPLB6Gxr+tRaw0BiheLygQd5BznHpWPRRWsIRhHljsY1JyqScpbnS6R4og03TI7WS2kdkJyysMHJzV3/hNrX/nzm/76FcbRWEsJSk22jpjjK0YqKew523SMw4BJOKbRRXUcYUUUUAdb4IkO28izxlWA/MV1dcf4J/4+bv8A3F/ma7CvBxitWZ9HgnehH+upwnjD/kPn/riv9a3vBP8AyCG/67N/IVg+MP8AkPn/AK4r/Wt7wT/yCG/67N/IV1Vv90j8jjo/77L5nTUUUV5R7AUUUUAcd4o077Pffao1/dz9fZv/AK/+NYWK9HvLSK+tXt5hlXHX0PrXBX9hNp100M491bsw9RXuYOupw5HujwMdh3TnzrZlWiiiu884KKKKACiiigAooooAKKKKACiiigAooooAKKKKACiilALMAoJJOAB3oAsWNnJf3iW8XVjyf7o7mvQbeBLW3SGEYRBgCs7QdJGm2m+Uf6RKMv8A7I9K1a8HGV/az5Y7I+hwWH9lDmluwoooriO8KKKKACiiigDn/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmur8X/wDICn/3k/nXKeGP+Rjtv+Bf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigDz3xPF5XiG4/29rj8RWTXVeNbQiS2u1HBBjY+/Uf1rla+iw0ualFnzOKhyVpIKKKK3OYnSyupUDxW0zqejLGSDTv7Ovf8Anzn/AO/R/wAK63wdfCXTntGPzwNkDPVT/wDXros15tXGTpzcXE9WjgYVYKalueYf2de/8+c//fo/4Uf2de/8+c//AH6P+Fen5ozWX9oS/lNf7Nj/ADHmH9nXv/PnP/36P+FH9nXv/PnP/wB+j/hXp+aM0f2hL+UP7Nj/ADHlctvPb48+GSPd03qRn86jrd8WXwu9X8lDlLddn/Au/wDhWFXp05OcFJrc8qrFQm4xd7BRRRWhkdf4JhIgu5j0ZlQfgM/1rqayvDdp9k0KAMMNJmRs+/T9MVq187iJc9WTPp8NDkoxTOE8Yf8AIfP/AFxX+tb3gn/kEN/12b+QrB8Yf8h8/wDXFf61veCf+QQ3/XZv5Cu6t/ukfkefR/32XzOmoooryj2AooooAKrX1hBqNuYrlcj+Fh1U+oqzRTjJxd0KUVJWZwupaBd6eSyqZoezoOn1HasuvTqoXeiWF4S0sAVz/GnymvUpZhpaojya2XXd6b+TOAorqZ/B6E5trpl9pFz+orD1HTTpsgje4ilfuqE5X61308RSqO0XqedUw1WkryWhSooorc5wooooAKKKKACiiigAooooAKKKKACuq8OaIY9t9drh+sSHt7mo9B8P5K3d+nHWOIj9T/hXUV5WLxX/AC7h8z2MHhP+XlT5IKKKK8k9gKKKKACiiigAooooA5/xf/yAp/8AeT+dcp4Y/wCRjtv+Bf8AoJrq/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigClq1gNS0ua3/iIyh9GHSvNWVkYq4KspwQexr1euP8WaOY5TqNuvyP/rgOx/vfjXo4Gtyv2b6nl4+g5R9pHocvRRRXsHiFmwvpdOvUuYD8y9QejDuDXoem6nb6pbCW2bn+ND1Q+9eZ1Jb3E1rMJbaRonHRlOK5cRhlWV9mdmGxUqDtuj1SiuLtfGd3GoW6gjn/ANoHaf8ACrJ8brt+WxOfeT/61eW8HWT2PWWOoNXudXWHr/iCPToWt7Zg90wxxz5fuff2rnr7xXqF2pSIrbIf+ef3vzrEJJJJOSepNdVHAtPmqfcclfHprlpfeKSSSScknJJ70lFFeoeQFXtH086lqkUGPkzukPoo6/4VSALEBRkk4AHeu/8ADmkf2XY7ph/pE2C/+yOy1zYmsqUPNnXhaDrVPJbmuAFAAGABgCloor58+kOE8Yf8h8/9cV/rW94J/wCQQ3/XZv5CsHxh/wAh8/8AXFf61veCf+QQ3/XZv5CvVrf7pH5Hj0f99l8zpqKa8iR48x1XPTccZpPOi/56J/30K8uzPXuh9FRm5gX700Y+rCoX1Oxj+/dwj/gYpqMnshOcVuy1RWXL4k0yLpOZD6IpNZ1x4vQZFras3oZGx+graOGrS2iYSxVGO8jpaqXmqWdgv+kzKrdkHLH8K4+68QahdZBm8pT/AAxDH69azSSSSSST1Jrtp5e96j+44amZLamvvN3UfFFxc5jswYI/738R/wAKwiSSSTknqT3pKK9KnShTVoo8upVnVd5u4UUUVoZBRRRQAUUUUAFFFFABRRV/TtHutSbMS7Ys8yN0/D1qZSjBXk7FRhKb5Yq7KUcbyyKkal3Y4CqMk11ujeHFtttxfAPN1WPqE/xNaGm6PbaYn7pd8pHzSN1P+FX68fEY1z92noj28NgVD3qmrCiiivOPTCiiigAooooAKKKKACiiigDn/F//ACAp/wDeT+dcp4Y/5GO2/wCBf+gmur8X/wDICn/3k/nXKeGP+Rjtv+Bf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigAproskbJIoZWGCCOCKdRQBwWveH5NNkM9sC9ox69TH7H296xK9XZQ6lWAKkYII61y+reEQ5abSyEPUwsePwPb6V62Hxia5an3njYnAtPmpfcchRUtxbTWspjuYmicdmGKir0001dHlNNOzCiiigQUUUUAFABJAAyT0Aq5YaTeak+LWEle8jcKPxrs9H8OW2mYlkxPc/wB8jhfoP61zVsTCktdX2OqhhalZ6aLuUvDnhw2xW9v1/fdY4z/B7n3rpqKK8OpUlVlzSPoKVKNKPLEKKKKzNThPGH/IfP8A1xX+tb3gn/kEN/12b+QrB8Yf8h8/9cV/rW94J/5BDf8AXZv5CvVrf7pH5Hj0f99l8zo5YY54zHMiyIeqsMiufv8AwnE+X09/LP8AzzflfwPUV0dFefTrTpP3WelVo06qtNHnV3p11Yti6gZB2bGVP41Wr01lDKVYAg9QR1rKu/Den3WWWMwOe8ZwPy6V6dPME9KiPLq5bJa0395w9Fb9z4Tu48m2lSYeh+U/4VlXGm3trnz7aRR67cj8xXdCtTn8Mjz50KtP4olWiiitTEKKKKACiiigAooooAKKtW+nXl1/qLaRx67cD8zWra+E7qTBupUhX0HzH/Csp1qcPiZtChVqfDEwKuWWl3l+3+jwkr3duFH411tn4dsLTDGMzOP4pef06VqgBQABgDoBXBUzBbU0ehSy5vWo/uMHT/C1vb4e8b7RJ/d6KP8AGt1VCqFUAAdAB0paK8ypVnUd5M9WnShSVoKwUUUVmahRRRQAUUUUAFFFFABRRRQAUUUUAc/4v/5AU/8AvJ/OuU8Mf8jHbf8AAv8A0E11fi//AJAU/wDvJ/OuU8MHHiK2/wCBf+gmvVw/+6z+f5Hj4r/e4fL8z0KiiivKPYCiiigAooooAKKKKACiiigAooooAKKKKAIp7aC6j2XMSSr6Ouaxbnwfp8xJgaS3J7Kcj8jW/RWkKs4fC7GU6NOp8auchJ4IlH+qvUP+8hFRDwTeZ5uoMfRv8K7Siuj65W7nP9RodvxOTi8Ec/v73j0SP/E1q2nhjTLU7jCZ29ZTn9Ola9FZyxNWW8jSGFow1URFUIoVAFUdABgCloornOkKKKKACiiigDhPGH/IfP8A1xX+tb3gn/kEN/12b+QrB8X/APIfP/XFf61veCf+QQ3/AF2b+Qr1a3+6R+R49H/fZfM6aiiivKPYCiiigAooooAglsbWf/XW8T+7IKpyeHdMk/5d9h/2GIrTorSNScfhbM5UqcviijDbwnYH7rzL/wACB/pUZ8IWva4mH5f4V0FFaLFVl9oyeEoP7Jz48IWve4m/T/CpF8J2A+887f8AAgP6VuUUfWqz+0CwlBfZMuPw5pkf/Lvv/wB9yauw2NpB/qbaJPcIKnorOVWct2zWNKnH4YoKKKKzNAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKAM3WbP+0NOuLYfedfl+o5FebRSzWV4siZjmhfPI6EV6pJ/rDWLq3hy11RjKCYJ+7qMhvqK7sLiI07wnszz8ZhpVbThujOj8bR+WPOs33452OMfrTv+E2t/wDnzl/76FUm8FXYb5bqAj3BFJ/whV7/AM/MH6/4VvyYPv8Amc3Pju35F7/hNrf/AJ85f++hR/wm1v8A8+cv/fQqj/whV7/z8wfr/hR/whV7/wA/MH6/4UcmD7/mPnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KP+E2t/8Anzl/76FUf+EKvf8An5g/X/Cj/hCr3/n5g/X/AAo5MH3/ADDnx3b8i9/wm1v/AM+cv/fQo/4Ta3/585f++hVH/hCr3/n5g/X/AAo/4Qq9/wCfmD9f8KOTB9/zDnx3b8i9/wAJtb/8+cv/AH0KR/G0O0+XZSFu25xiqX/CFXv/AD8wfr/hSjwVeZ5uoAPoaOTB9/zDnx3b8jCvLubULx7ibmSQ9AOnoBXoXh2xbT9KghkGJGy7j0J7VS0rwvbadIJpm+0TrypIwq/QVvR/6wVjisRGaUIbI3wmGlTbqVN2T0UUVwHohRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQB//2Q==)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxj_Yq-iWJxb"
      },
      "source": [
        "This notebook is supposed to give an overview over the used functionalities. We will show how to use BERT - Bidirectional Encoder Representations from Transformers - with PyTorch library (huggingface) to fine-tune a pretrained model in tweet classification. \n",
        "\n",
        "The following pretrained BERT models can be used and are available in transformers huggingface: \n",
        "\n",
        "*   *bert-base-german-cased*\n",
        "*   *bert-base-german-dbmdz-cased*\n",
        "*   *bert-base-german-dbmdz-uncased*\n",
        "*   *distilbert-base-german-cased*\n",
        "\n",
        "After using these models to extract (hopefully) high quality features from our text data, we aim to fine-tune them on our specific task using a manually labeled sample of German tweets to gain state of the art predictions.\n",
        "\n",
        "All in all the tweets will be classified into *positive* and *negative* classes using a pretrained BERT model. We will take it, add an untrained layer of neurons on the end and train a new model specifically for the classification task. \n",
        "\n",
        "\n",
        "Advantages of fine-tuning:  \n",
        "\n",
        "*   Fast, because we already have pretrained layers of the network (only 2-4 epochs after adding 1 fully connected layer on top are enough to train as the authors recommend)\n",
        "*   Less data is sometimes enough to achieve good performance\n",
        "*   Usually preferable results: because of task-specific adjustments of the weights\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGC297qbdzRf"
      },
      "source": [
        "## Prepare GPU\n",
        "\n",
        "1. Check: Edit --> Notebook settings -> Hardware accelerator -> *GPU* \n",
        "\n",
        "\n",
        "2. You will need access to the following files: *data_germeval_2017.tsv*, *data_labeled_processed.csv*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdvrFazAMeEG"
      },
      "source": [
        "## Data\n",
        "\n",
        "1. On the left command pane, move to the `Files` section.\n",
        "2. Select 'Upload to the session storage'.\n",
        "3. Upload the `data_germeval_2017.tsv` and `data_labeled_processed.csv` data from the course website (the data will vanish as soon as you terminate the colab session)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv04gWs2Yheg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fe07f1-e324-4c01-9d7a-80e54351aac7"
      },
      "source": [
        "# Where are you now?\n",
        "import os, sys\n",
        "print(\"My current working directory is in folder: \", os.getcwd(), \".\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My current working directory is in folder:  /content .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26YQ5UYt1aGw"
      },
      "source": [
        "## Google Colab GPU Connection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY5QDtKc4pCe"
      },
      "source": [
        "Otherwise training a large NN may take a very long time. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpojrKi87B0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64452966-0177-4638-dd24-3691ff0046e9"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLk647UpAUMZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53cf0a4-9789-4c9f-8d11-2b88de0caab1"
      },
      "source": [
        "# Identify and specify the GPU as the device\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLhki6Q67HB5"
      },
      "source": [
        "## Fine-Tuning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV4Ao1h59Tbj"
      },
      "source": [
        "Install Huggingface Library / transformers package and specify the pretrained transformer model. (Uncased means that the texts have only lowercase letters)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtnIk5ybq1v6"
      },
      "source": [
        "### Exercise 1\n",
        "*Try another pretrained model available in transformers library.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ynJrSjrQLQu"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "pretrained_model = \"bert-base-german-cased\"                                           # SOLUTION: i.e. \"distilbert-base-german-cased\"\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained(pretrained_model) # Additionally do lower case for pretrained uncased models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr-IYbltg_em"
      },
      "source": [
        "### Exercise 2\n",
        "*Pre-process the Twitter data set.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKXUHB8CIoNV"
      },
      "source": [
        "Load and prepare the tweets and labels "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNnv3aRgczlM"
      },
      "source": [
        "# Prepare path to the dataset contaning tweets\n",
        "filename_tweets = \"data_labeled_processed.csv\"                                                    # SOLUTION"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ejwgMfT7D-x"
      },
      "source": [
        "# Load the dataset into a pandas dataframe\n",
        "import pandas as pd\n",
        "df = pd.read_csv(filename_tweets, delimiter = ',', header = 0)                                    # SOLUTION "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeDjf_3ndl4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df289bb4-4c88-4a81-c07b-67e12a587533"
      },
      "source": [
        "# Look at the shape of the dataframe\n",
        "df.shape                                                                                          # SOLUTION "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(498, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mryi3QOLdjQK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "0fa66224-c0ab-4c9a-b13e-0918a661fb51"
      },
      "source": [
        "# Look at the first rows of the dataframe\n",
        "df.head()                                                                                         # SOLUTION"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc_id</th>\n",
              "      <th>twitter_username</th>\n",
              "      <th>twitter_available</th>\n",
              "      <th>twitter_created_at</th>\n",
              "      <th>twitter_full_text_topic</th>\n",
              "      <th>twitter_full_text</th>\n",
              "      <th>twitter_retweet_count</th>\n",
              "      <th>twitter_favorite_count</th>\n",
              "      <th>twitter_followers_count</th>\n",
              "      <th>twitter_location</th>\n",
              "      <th>twitter_word_count</th>\n",
              "      <th>twitter_year</th>\n",
              "      <th>twitter_month</th>\n",
              "      <th>twitter_week</th>\n",
              "      <th>twitter_time_index_month</th>\n",
              "      <th>twitter_time_index_week</th>\n",
              "      <th>twitter_emojis</th>\n",
              "      <th>twitter_hashtags</th>\n",
              "      <th>twitter_tags</th>\n",
              "      <th>label</th>\n",
              "      <th>topic</th>\n",
              "      <th>from</th>\n",
              "      <th>to</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ABaerbock15156546001</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-01-11T07:10:00Z</td>\n",
              "      <td>Habe mir das Gro Ko-Sondierungspapier zu Klima...</td>\n",
              "      <td>Habe mir das Gro Ko-Sondierungspapier zu Klima...</td>\n",
              "      <td>111</td>\n",
              "      <td>233</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>32</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#GroKo|#Klima|#Klimadiplomatie|#Merkel|#kohlea...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>239</td>\n",
              "      <td>251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ABaerbock15210084001</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-03-14T06:20:00Z</td>\n",
              "      <td>Auch weltweit sieht man, dass Angela Merkel s ...</td>\n",
              "      <td>Auch weltweit sieht man, dass Angela Merkel s ...</td>\n",
              "      <td>24</td>\n",
              "      <td>96</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>27</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Merkel|#GroKo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>203</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ABaerbock15216341401</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-03-21T12:09:00Z</td>\n",
              "      <td>Der groessten globalen Herausforderung, der Kl...</td>\n",
              "      <td>Der groessten globalen Herausforderung, der Kl...</td>\n",
              "      <td>39</td>\n",
              "      <td>153</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>38</td>\n",
              "      <td>2018</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>27</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#Klimakrise|#Regierungserklaerung|#Koalitionsv...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Klimapolitik</td>\n",
              "      <td>284</td>\n",
              "      <td>296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ABaerbock15252349801</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-05-02T04:23:00Z</td>\n",
              "      <td>Wir brauchen eine andere Verkehrspolitik - weg...</td>\n",
              "      <td>Wir brauchen eine andere Verkehrspolitik - weg...</td>\n",
              "      <td>49</td>\n",
              "      <td>213</td>\n",
              "      <td>94139</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>38</td>\n",
              "      <td>2018</td>\n",
              "      <td>5</td>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>negative</td>\n",
              "      <td>Verkehrspolitik</td>\n",
              "      <td>25</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ABaerbock15256297201</td>\n",
              "      <td>ABaerbock</td>\n",
              "      <td>True</td>\n",
              "      <td>2018-05-06T18:02:00Z</td>\n",
              "      <td>Das ist die Leistung von Hunderten Wahlkaempfe...</td>\n",
              "      <td>Das ist die Leistung von Hunderten Wahlkaempfe...</td>\n",
              "      <td>39</td>\n",
              "      <td>301</td>\n",
              "      <td>107693</td>\n",
              "      <td>Brandenburg</td>\n",
              "      <td>40</td>\n",
              "      <td>2018</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>9</td>\n",
              "      <td>34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#kwsh|#kow18|#Kommunalwahl</td>\n",
              "      <td>NaN</td>\n",
              "      <td>positive</td>\n",
              "      <td>Kommunalpolitik</td>\n",
              "      <td>251</td>\n",
              "      <td>266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 doc_id twitter_username  ...  from   to\n",
              "0  ABaerbock15156546001        ABaerbock  ...   239  251\n",
              "1  ABaerbock15210084001        ABaerbock  ...   203  215\n",
              "2  ABaerbock15216341401        ABaerbock  ...   284  296\n",
              "3  ABaerbock15252349801        ABaerbock  ...    25   40\n",
              "4  ABaerbock15256297201        ABaerbock  ...   251  266\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUb6n3OueE5u"
      },
      "source": [
        "# Convert labels to numeric: 1 for \"positive\", 0 for \"negative\" and call the column \"label_binary\"\n",
        "df['label_binary'] = [1 if label == \"positive\" else 0 for label in df.label]                      # SOLUTION"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWqiYQB_dlBw"
      },
      "source": [
        "# Drop NA values in the column \"label\"\n",
        "df = df.dropna(subset=['label'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrOvWVj0dolR"
      },
      "source": [
        "# Get the lists of tweets and their labels.\n",
        "tweets = df.twitter_full_text.values\n",
        "labels = df.label_binary.values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_4pZEWFfT90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "81ed9cc5-900f-47a7-8e88-f94b40fbe24f"
      },
      "source": [
        "# Print the second tweet in the dataframe (Take care of right indexing!)\n",
        "tweets[1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Auch weltweit sieht man, dass Angela Merkel s Gro Ko 3.0 nicht klimatauglich ist, sondern vielmehr das Pariser Abkommen unterlaeuft. Auch aussenpolitisch fatal. Daher Klimasofortprogramm jetzt auflegen!'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QiOSbaOfkRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec26ff9c-bab4-4d05-ba9a-eebb8c5d6aa1"
      },
      "source": [
        "# Is the sentiment expressed in this tweet negative or positive? Check by printing the label.\n",
        "labels[1]                                                                                         # SOLUTION"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow1HwkWUhPMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd167b5a-1f81-4c56-9a1b-887d623a6902"
      },
      "source": [
        "# Count the occurrences of positive and negative tweets\n",
        "import numpy as np\n",
        "np.count_nonzero(labels == 1)                                                                     # SOLUTION"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugeeuOiwkJiF"
      },
      "source": [
        "GermEval Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm-y_1C6iFZE"
      },
      "source": [
        "# Prepare path to the dataset containg GermEval texts\n",
        "filename_germeval = \"data_labeled_processed.csv\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKmrPBtTja5r"
      },
      "source": [
        "# Load the dataset into a pandas dataframe\n",
        "import pandas as pd\n",
        "germeval = pd.read_csv(filename_germeval, \n",
        "                   sep='\\t',\n",
        "                   header=None, \n",
        "                   names = [\"full_text\", \"0\", \"label\", \"2\"])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NHjRwmajlHC"
      },
      "source": [
        "# Further preprocessing\n",
        "germeval['label_binary'] = [1 if label == 'positive' else 0 for label in germeval.label]\n",
        "germeval = germeval.loc[lambda x: x['label'] != \"neutral\"]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-3Xsv0PJ0X0"
      },
      "source": [
        "# Get the lists of tweets and their labels -> Use only the first 99 rows\n",
        "tweets_germeval = germeval.full_text.values[0:99]\n",
        "labels_germeval = germeval.label_binary.values[0:99]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utKWWD02IyBh"
      },
      "source": [
        "First, we need to tokenize our text to be able to feed it into the BERT model. \n",
        "\n",
        "Below an example of tokenized and raw tweet versions is shown. To tokenize the text we have to specify and use the pretrained BERT because each model has a fixed vocabulary (containing tokens, so wordpieces) and the BERT tokenizer handles words which are not in the certain vocabulary in a specific way.\n",
        "\n",
        "Each token is then mapped to its index in the tokenizer vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZL1eSQeVs6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64301f9e-66c5-4d7c-cac8-d7afacef4fc2"
      },
      "source": [
        "# Print the raw tweet.\n",
        "print('Raw: ', tweets[0])\n",
        "\n",
        "# Print the tweet split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(tweets[0]))\n",
        "\n",
        "# Print the tweet mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[0])))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw:  Habe mir das Gro Ko-Sondierungspapier zu Klima nochmal genau angeschaut. Krass: De facto wird sogar das Kyoto-Protokoll, der Meilenstein der Klimadiplomatie fuer nichtig erklaert! Frau Merkel, das geht so nicht! Nachbessern! kohleausstieg\n",
            "Tokenized:  ['Hab', '##e', 'mir', 'das', 'Gro', 'Ko', '-', 'Son', '##die', '##rung', '##sp', '##ap', '##ier', 'zu', 'Klima', 'noch', '##mal', 'genau', 'angesch', '##aut', '.', 'Kras', '##s', ':', 'De', 'fa', '##ct', '##o', 'wird', 'sogar', 'das', 'Ky', '##oto', '-', 'Protokoll', ',', 'der', 'Meilen', '##stein', 'der', 'Klima', '##di', '##plomat', '##ie', 'f', '##uer', 'nichtig', 'erk', '##la', '##ert', '!', 'Frau', 'Merkel', ',', 'das', 'geht', 'so', 'nicht', '!', 'Nach', '##besser', '##n', '!', 'ko', '##hle', '##auss', '##ti', '##eg']\n",
            "Token IDs:  [9689, 26897, 3667, 93, 951, 673, 26935, 1343, 2930, 23620, 168, 425, 97, 81, 6914, 357, 446, 2971, 16745, 956, 26914, 26237, 26902, 26964, 576, 20568, 1920, 26910, 292, 2215, 93, 13235, 9857, 26935, 10252, 26918, 21, 17930, 1407, 21, 6914, 3748, 13461, 12, 69, 667, 20719, 895, 129, 335, 26982, 946, 5654, 26918, 93, 1398, 181, 149, 26982, 326, 4379, 26898, 26982, 7424, 2039, 10685, 15099, 640]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZJe8-JoKAaL"
      },
      "source": [
        "In the next step we add special tokens to the start *CLS* and end of each tweet *SEP*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKR6G5w4dFsy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8fc64f0-767a-4ada-b926-04fe9c4e808c"
      },
      "source": [
        "# Tokenize all of the tweets and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every tweet...\n",
        "for tweet in tweets:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet, # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded tweet to the list.\n",
        "    input_ids.append(encoded_tweet)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets[0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Habe mir das Gro Ko-Sondierungspapier zu Klima nochmal genau angeschaut. Krass: De facto wird sogar das Kyoto-Protokoll, der Meilenstein der Klimadiplomatie fuer nichtig erklaert! Frau Merkel, das geht so nicht! Nachbessern! kohleausstieg\n",
            "Token IDs: [3, 9689, 26897, 3667, 93, 951, 673, 26935, 1343, 2930, 23620, 168, 425, 97, 81, 6914, 357, 446, 2971, 16745, 956, 26914, 26237, 26902, 26964, 576, 20568, 1920, 26910, 292, 2215, 93, 13235, 9857, 26935, 10252, 26918, 21, 17930, 1407, 21, 6914, 3748, 13461, 12, 69, 667, 20719, 895, 129, 335, 26982, 946, 5654, 26918, 93, 1398, 181, 149, 26982, 326, 4379, 26898, 26982, 7424, 2039, 10685, 15099, 640, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ_QN3DKkUFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4e7b27-140a-4964-dbf2-87e88d80caa9"
      },
      "source": [
        "# Do the same for GermEval \n",
        "input_ids_germeval = []\n",
        "\n",
        "# For every tweet...\n",
        "for tweet_germeval in tweets_germeval:\n",
        "    encoded_tweet = tokenizer.encode(\n",
        "                        tweet_germeval,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded tweet to the list.\n",
        "    input_ids_germeval.append(encoded_tweet)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets_germeval[0])\n",
        "print('Token IDs:', input_ids_germeval[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  doc_id,twitter_username,twitter_available,twitter_created_at,twitter_full_text_topic,twitter_full_text,twitter_retweet_count,twitter_favorite_count,twitter_followers_count,twitter_location,twitter_word_count,twitter_year,twitter_month,twitter_week,twitter_time_index_month,twitter_time_index_week,twitter_emojis,twitter_hashtags,twitter_tags,label,topic,from,to\n",
            "Token IDs: [3, 13463, 26909, 26983, 46, 26904, 26918, 209, 9170, 26983, 11838, 212, 1431, 26918, 209, 9170, 26983, 18, 4973, 9758, 6180, 26918, 209, 9170, 26983, 1350, 26836, 25110, 26983, 5563, 26918, 209, 9170, 26983, 69, 2701, 26983, 25059, 26983, 21769, 434, 26918, 209, 9170, 26983, 69, 2701, 26983, 25059, 26918, 209, 9170, 26983, 19638, 384, 75, 26983, 1350, 1504, 4053, 26918, 209, 9170, 26983, 20568, 511, 1182, 26983, 1350, 1504, 4053, 26918, 209, 9170, 26983, 790, 9931, 355, 26983, 1350, 1504, 4053, 26918, 209, 9170, 26983, 9087, 2856, 15099, 23, 26918, 209, 9170, 26983, 5883, 26904, 26983, 1350, 1504, 4053, 26918, 209, 9170, 26983, 9560, 26897, 33, 26918, 209, 9170, 26983, 14837, 26905, 26918, 209, 9170, 26983, 12412, 1752, 26918, 209, 9170, 26983, 209, 3739, 26983, 2519, 3244, 26983, 14837, 26905, 26918, 209, 9170, 26983, 209, 3739, 26983, 2519, 3244, 26983, 12412, 1752, 26918, 209, 9170, 26983, 2408, 26910, 9600, 26902, 26918, 209, 9170, 26983, 312, 3653, 12037, 26918, 209, 9170, 26983, 22208, 26918, 2094, 2033, 26918, 21769, 434, 26918, 19464, 26918, 6187, 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk4o_F6XKIUF"
      },
      "source": [
        "Then we pad and truncate all tweets to a constant fixed length "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_tBkChIdyOC",
        "outputId": "50d3a773-ea17-40ec-9b28-c6bd57d5f3fa"
      },
      "source": [
        "print('Max sentence length: ', max([len(tweet) for tweet in input_ids]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  84\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTux34E5kYND",
        "outputId": "f091cee8-463e-4a76-861f-f53536eb4933"
      },
      "source": [
        "print('Max sentence length for GermEval data: ', max([len(tweet_germeval) for tweet_germeval in input_ids_germeval]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length for GermEval data:  267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTtngalseGJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bede2e6-df10-4db0-82e7-624e944bf418"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# A bit larger than the maximum training tweet length of 91/110... (with germeval 3202/3300 -> bert has a max length limit of tokens = 512, we cut the longer texts off and only use the first 512 Tokens)\n",
        "MAX_LEN = 250\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" - pad and truncate at the end of the sequence, as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Pad our input tokens with value 0 for Germeval data \n",
        "input_ids_germeval = pad_sequences(input_ids_germeval, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 250 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vstmJJnvOEJ6"
      },
      "source": [
        "Create attention masks which indicates which tokens are words and which are padding (if token ID is 0 then it is padding and the attention mask is set to 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoRYw4_jg4QP"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for tweet in input_ids:\n",
        "    \n",
        "    att_mask = [int(token_id > 0) for token_id in tweet]\n",
        "    \n",
        "    # Store the attention mask for each tweet.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yinz_P3vk1oJ"
      },
      "source": [
        "# Create attention masks for Germeval data \n",
        "attention_masks_germeval = []\n",
        "\n",
        "# For each sentence...\n",
        "for tweet_germeval in input_ids_germeval:\n",
        "    \n",
        "    att_mask = [int(token_id > 0) for token_id in tweet_germeval]\n",
        "    \n",
        "    # Store the attention mask for each tweet.\n",
        "    attention_masks_germeval.append(att_mask)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vp0fFEsOifw"
      },
      "source": [
        "Now, we use train_test_split to split our data into train, test sets first  and then split the initial train set further into a final train set and validation set for training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UT0FM31qLDR"
      },
      "source": [
        "### Exercise 3\n",
        "*Split into train and test sets.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV4b99xCgEsu"
      },
      "source": [
        "# Without-GermEval-case\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "train_inputs2, test_inputs, train_labels2, test_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state = 2021, test_size = 0.2, stratify = labels)       # SOLUTION\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks2, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state = 2021, test_size = 0.2, stratify = labels)                      # SOLUTION\n",
        "\n",
        "\n",
        "# Use 20% of train set as validation set \n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs2, train_labels2, \n",
        "                                                                                    test_size = 0.2, random_state = 2021)  # SOLUTION\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(train_masks2, train_labels2,                                        # SOLUTION\n",
        "                                             random_state=2020, test_size=0.2)    "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPxoRdC5-7YD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1c24f6-b4f3-478e-e9e5-51dce41a968d"
      },
      "source": [
        "# How many training tweets do you have? \n",
        "len(train_inputs)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lUovm-xmGbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b54026aa-cb7d-41ad-9ff5-2705484c778f"
      },
      "source": [
        "# How many test tweets do you have? \n",
        "len(test_inputs)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LTBu9v-qteI"
      },
      "source": [
        "### Exercise 4\n",
        "*Additionally use GermEval data set for training.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHDnNsImhFKd"
      },
      "source": [
        "# Use additional Germeval data for training\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Use 80% for training and 20% for validation.\n",
        "train_inputs1, test_inputs, train_labels1, test_labels = train_test_split(input_ids, labels,                                # SOLUTION\n",
        "                                                            random_state=42, test_size=0.2, stratify = labels)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks1, test_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=42, test_size=0.2, stratify = labels)\n",
        "\n",
        "# Mix train_inputs1, train_labels1, train_masks1 with germeval data\n",
        "train_inputs2 = np.concatenate((train_inputs1, input_ids_germeval), axis=0)\n",
        "train_labels2 = np.concatenate((train_labels1, labels_germeval), axis=None)\n",
        "train_masks2  = np.concatenate((train_masks1, attention_masks_germeval), axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# Use 20% of train set as validation set \n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(train_inputs2, train_labels2,           # SOLUTION\n",
        "                                                                                    test_size=0.2, random_state=2020) \n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(train_masks2, train_labels2,                                         # SOLUTION\n",
        "                                             random_state=2020, test_size=0.2)    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTaFTXqFO080"
      },
      "source": [
        "Convert all inputs and labels into torch tensors, the required datatype \n",
        "for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg71HZ7qifpo"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "test_inputs = torch.tensor(test_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "test_masks = torch.tensor(test_masks)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFLnUkVxsCTS"
      },
      "source": [
        "### Exercise 5\n",
        "*Try another set of hyperparameters recommended by BERT authors.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SQQwH_VrL63"
      },
      "source": [
        "# Define batch size here to let DataLoader know. \n",
        "# BERT-authors recommend a batch size of 16 or 32 for fine-tuning.\n",
        "batch_size = 32"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LXM1YHwrRQC"
      },
      "source": [
        "# Define the learning rate \n",
        "learning_rate = 5e-5"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJka_WQrms8"
      },
      "source": [
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 2 "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeutTU9Hr0pB"
      },
      "source": [
        "The torch DataLoader class enables to create  an iterator for our data in order to save memory during training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBRWzCgriurl"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIEy4SR4R6ch"
      },
      "source": [
        "Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "linear classification layer on top. This is the one for classification tasks in general. *(see for more details https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xILaX9ulICZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2eb5e1c1bfc64bf1877ab1368333f15c",
            "8dec96fc80414898a7845a1d67ae211e",
            "a244faa1d67c4d55a3987fffe2a803ae",
            "9fcbc618ab2d4b2f8e2ab384585d9cb9",
            "7cabb6345a814d61a0031b5d920257c0",
            "6b749ba92aa34bf7912620ad94057185",
            "ba580d08de234c12b4109e7b78c7aaef",
            "2df10737c1c34f91bf3ac6462b0aa79f",
            "956e67eb161c4857a475de372038255b",
            "917d0c57fda847dcae8f6b20ca120a12",
            "b11ca002fce1405d943bfa34c6bcd25d",
            "cba1ee86beff4a1299d1abdf501d0495",
            "ca8346678fc649959558f12ab1e54fa7",
            "922b33e932c04ff1be584ba62e90e6d9",
            "eff69413af5343cc8d02e8a25d5caf48",
            "794d15ec432942bfbf2e59f139f7f775"
          ]
        },
        "outputId": "4f0662fb-ff4d-4a21-b1d2-5b1f77dcbec4"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    pretrained_model, \n",
        "    num_labels = 2, # The number of output labels--2 for binary classification. Can be increased for multiclass\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False \n",
        ")\n",
        "\n",
        "# Run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2eb5e1c1bfc64bf1877ab1368333f15c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "956e67eb161c4857a475de372038255b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=438869143.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wddbSBdwl6MM"
      },
      "source": [
        "# All of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOogCCNSS1_z"
      },
      "source": [
        "Get the optimizer after loading the model. \n",
        "\n",
        "*(see for more details on AdamW Optimizer https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5YMJeG7m1GW"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate, \n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TypGI2W5m5X9"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fgx-tuPnc8Z"
      },
      "source": [
        "# helper function for calculating accuracy\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcSWb-YhpNo4"
      },
      "source": [
        "# helper function for formatting elapsed times\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTwfA1dVrJFv"
      },
      "source": [
        "### Exercise 6\n",
        "*Fine-tune your model.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dgc1fHkwTxaf"
      },
      "source": [
        "Let's start the actual training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acrG210Npcb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "987c455a-1b9c-4666-95fd-76cb0db07c88"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "seed_val = 55\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch:\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    ## TRAIN\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # how long does the training epoch take.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Turn on the training mode for the model. \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data:\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack the batch and load onto the GPU.\n",
        "        # Each batch contains input ids, attention masks, labels. \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Remove any previously calculated gradients before performing a\n",
        "        # backward pass. \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Do a forward pass. \n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. \n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Do a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0. \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step.\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Avg loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Need for plotting the learning curve later.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Avg training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Epoch time: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    ## VALIDATE\n",
        "    # After each training epoch, we measure performance on\n",
        "    # validation set.\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Turn on the evaluation mode of the model.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get logit values predicted for each class.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Accuracy for this batch of validation tweets.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation time: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.40\n",
            "  Epoch time: 0:00:17\n",
            "  Accuracy: 0.88\n",
            "  Validation time: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "\n",
            "  Avg training loss: 0.19\n",
            "  Epoch time: 0:00:17\n",
            "  Accuracy: 0.93\n",
            "  Validation time: 0:00:02\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKJGT2uxqsNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "97245646-3e44-4eb6-8fe5-ab543c9103be"
      },
      "source": [
        "# Visualize the training results\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVV9-_GMY76z"
      },
      "source": [
        "# Evaluation on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tocnbPMDRN00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bef014d-60f5-4d20-f720-ab1ed1846bfc"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test tweets...'.format(len(test_inputs)))\n",
        "\n",
        "# Turn on the evaluation mode of the model\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Compute gradients, save memory and speed up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 100 test tweets...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOIrNxOukbY6",
        "outputId": "6271be8f-83d3-427a-ef0d-1c25a9fb3f63"
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label_binary.sum(), len(df.label_binary), (df.label_binary.sum() / len(df.label_binary) * 100.0)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 106 of 498 (21.29%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iNrCwTYa6cI"
      },
      "source": [
        "Performance measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YzWo-1qp3kn"
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd4kOBthmifT"
      },
      "source": [
        "# List of keys of the highest scores, i.e. predictions (indices of the maximum values along an axis)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGWTUvMEmjqv"
      },
      "source": [
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x7g2bzgb-o9"
      },
      "source": [
        "F1 score, accuracy and confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haL4-Mwpqm-i"
      },
      "source": [
        "### Exercise 7\n",
        "*Print out the accuracy score.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAoOFsCUwsLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21b9f60-1bae-468d-8d55-9a68b074e95e"
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "\n",
        "# F1-Score (weighted)\n",
        "f1_value = f1_score(flat_predictions, flat_true_labels, average=\"weighted\")\n",
        "\n",
        "# Accuracy Score\n",
        "accuracy = accuracy_score(flat_predictions, flat_true_labels)                         # SOLUTION\n",
        "\n",
        "print(\"F1 Score (Weighted): {}\".format(f1_value))\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 Score (Weighted): 0.8890712487038958\n",
            "Accuracy: 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s22lIKFxrOu"
      },
      "source": [
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\n",
        "    \n",
        "    cm = confusion_matrix(y_true=true_labels, \n",
        "                                  y_pred=predicted_labels, \n",
        "                                  labels=classes)\n",
        "    cm_frame = pd.DataFrame(data=cm, \n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \n",
        "                                                  codes=[[0,0],[0,1]]), \n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \n",
        "                                                codes=[[0,0],[0,1]])) \n",
        "    return cm_frame   "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aARx5G5vy5vZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "3f24cb67-dbd6-40e7-e7d5-61e8a5947a09"
      },
      "source": [
        "confusion_mat = display_confusion_matrix(true_labels = flat_true_labels, predicted_labels = flat_predictions)\n",
        "confusion_mat"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"2\" halign=\"left\">Predicted:</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Actual:</th>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Predicted:    \n",
              "                   1   0\n",
              "Actual: 1         16   5\n",
              "        0          6  73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}