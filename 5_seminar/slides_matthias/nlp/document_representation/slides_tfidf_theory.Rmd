## TF-IDF weighting
```{r, include=FALSE, cache=FALSE}
ap = adjust_path(paste0(getwd(), "/figure"))
```

__Shortcomings of Bag-of-words/n-grams:__

- Some words occur overly frequent in the corpus
- Information content decreases with increasing occurence
- Raw Bag-of-words approaches don't adress this problem

__Term frequency inverse document frequency (TF-IDF):__

- Re-weights entrys of the DTM
- Captures information content more accurately

## TF-IDF weighting

__Term frequencey:__
\vspace{-.3cm}
$$tf(word_i, document_j) = \#(word_i, document_j)$$
\vspace{.5cm}
__Inverse document frequency:__
\vspace{-.3cm}
$$idf(word_i) = \log(\frac{n}{\sum_{d|w_i \in d} 1})$$
\vspace{.5cm}
__TF-IDF:__
\vspace{-.3cm}
$$ tf(word_i, document_j) \cdot idf(word_i)$$

## TF-IDF weighting

__Different variants of the $tf$, e.g. sublinear scaling:__

$$tf(word_i, document_j) = 1 + \log(\#(word_i, document_j))$$

\vspace{.5cm}

__Different variants of the $idf$, e.g. smoothing:__

$$idf(word_i) = \log(\frac{n}{\sum_{d|w_i \in d} 1} + 1)$$
