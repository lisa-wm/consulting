{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the official Bundestag website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import urllib.request\n",
    "import requests\n",
    "import re\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# see https://stackoverflow.com/questions/2134706/hitting-maximum-recursion-depth-using-pickle-cpickle/2135176#2135176\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\data\\\\web_scraping'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up working directory\n",
    "os.path.abspath(os.getcwd()) # initial working directory (should be equal to source file directory if using Jupyter Notebook)\n",
    "os.chdir('../../data/web_scraping') # change to directory where all data files are stored\n",
    "# check working directory\n",
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up selenium web driver\n",
    "chdriver_path = r'D:\\UNI\\01_Master\\3. Semester\\Consulting\\chromedriver.exe' # download chromedriver, save locally\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(chdriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize selenium web driver\n",
    "website = \"https://www.bundestag.de/abgeordnete\"\n",
    "driver.get(website)\n",
    "\n",
    "# switching to list view\n",
    "element = driver.find_element_by_class_name('icon-list-bullet') # find list button\n",
    "webdriver.ActionChains(driver).move_to_element(element).click(element).perform() # click\n",
    "time.sleep(random.randint(5,10)) # wait for list view to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many MPs are listed on the website (includes dropouts and successors)\n",
    "len(driver.find_element_by_class_name('bt-list-holder').find_elements_by_tag_name('li'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up a dictionary with MP name and party only (from list)\n",
    "\n",
    "abg_dict = {}\n",
    "abg_count = 0\n",
    "for link in driver.find_element_by_class_name('bt-list-holder').find_elements_by_tag_name('li'):\n",
    "    name = link.find_element_by_class_name('bt-teaser-person-text').find_element_by_tag_name('h3').text\n",
    "    partei = link.find_element_by_class_name('bt-teaser-person-text').find_element_by_tag_name('p').text\n",
    "    value = [name, partei] # value: name & partei\n",
    "    abg_dict[abg_count] = value\n",
    "    abg_count += 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-8844806fad5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# wait for list view to load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bt-list-holder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements_by_tag_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'li'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mabg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# click to open individual page\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# wait for page to load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# for each MP, retrieve all information (except name and party) from individual page\n",
    "# note that timeout errors might occur when waiting for a site to load\n",
    "# in that case, rerun the loop below for the missing parts, then append to output already generated\n",
    "for abg in abg_dict:\n",
    "    \n",
    "    # (re-)load list view (for all iterations)\n",
    "    driver.get(website)\n",
    "    element = driver.find_element_by_class_name('icon-list-bullet')\n",
    "    webdriver.ActionChains(driver).move_to_element(element).click(element).perform() # click to change to list view\n",
    "    time.sleep(random.randint(8,10)) # wait for list view to load\n",
    "    \n",
    "    driver.find_element_by_class_name('bt-list-holder').find_elements_by_tag_name('li')[abg].click() # click to open individual page\n",
    "    time.sleep(random.randint(8,10)) # wait for page to load\n",
    "\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml') # convert page to soup\n",
    "    \n",
    "    # extract election mode (wahlart), state (bundesland), and electoral district (wahlkreis)\n",
    "    wahlart = soup.find_all('h4')[4].text\n",
    "    bundesland = soup.find('div', attrs = {'class': 'col-xs-12 col-sm-6 bt-standard-content'}).h5.text\n",
    "    wahlkreis = soup.find('div', attrs = {'class': 'col-xs-12 col-sm-6 bt-standard-content'}).a.text \\\n",
    "        if soup.find('div', attrs = {'class': 'col-xs-12 col-sm-6 bt-standard-content'}).a is not None else \"n.a.\"   \n",
    "\n",
    "    # extract committee memberships (ausschuesse)\n",
    "    ausschuesse = {}\n",
    "\n",
    "    ## keys: position within committee (e.g., ordentliches mitglied, stellvertretendes mitglied)\n",
    "    keys = []\n",
    "    for heading in soup.find_all(class_ = 'bt-collapse-padding-bottom')[4].find_all('h5'):\n",
    "        key = heading.text.strip('\\n').strip() \n",
    "        keys.append(key)\n",
    "\n",
    "    ## values: the actual committees\n",
    "    values = []\n",
    "    for ul in soup.find_all(class_ = 'bt-collapse-padding-bottom')[4].find_all('ul'):\n",
    "        entries = []\n",
    "        for x in ul.find_all('a'):\n",
    "            entries.append(x['title'])\n",
    "        values.append(entries)\n",
    "\n",
    "    ## in case of memberships in other (non-Bundestag) bodies\n",
    "    if len(soup.find_all('h4', string = 'Mitgliedschaften in sonstigen Gremien')) == 1:\n",
    "        for heading in soup.find_all(class_ = 'bt-collapse-padding-bottom')[5].find_all('h5'):\n",
    "            interim_key = heading.text.strip('\\n').strip()\n",
    "            key = f'{interim_key} (sonstige Gremien)'\n",
    "            keys.append(key)\n",
    "\n",
    "        for ul in soup.find_all(class_ = 'bt-collapse-padding-bottom')[5].find_all('ul'):\n",
    "            entries = []\n",
    "            for x in ul.find_all('a'):\n",
    "                entries.append(x['title'])\n",
    "            values.append(entries)\n",
    "    \n",
    "    if len(soup.find_all('h4', string = 'Funktion')) == 0:\n",
    "        for i in range(len(keys)):\n",
    "            ausschuesse[keys[i]] = values[i]\n",
    "    else:\n",
    "        for i in range(len(keys)):\n",
    "            ausschuesse[keys[i]] = []  \n",
    "\n",
    "    # exctract social media accounts(soziale medien)\n",
    "    social_media = {}\n",
    "\n",
    "    if len(soup.find_all('h5', string = 'Profile im Internet')) == 1:\n",
    "        for link in soup.find_all(class_ = 'bt-linkliste')[0].find_all('a'):\n",
    "            social_media[link['title']] = link.get('href')\n",
    "\n",
    "    # extract biography (briografie)   \n",
    "    biografie = str()\n",
    "    for p in soup.find(class_ = 'bt-collapse-padding-bottom').find_all('p'):\n",
    "        biografie += p.text.strip('\\n').replace(u'\\xa0', u' ')\n",
    "\n",
    "    abg_dict[abg].append(wahlart)\n",
    "    abg_dict[abg].append(bundesland)\n",
    "    abg_dict[abg].append(wahlkreis)\n",
    "    abg_dict[abg].append(ausschuesse)\n",
    "    abg_dict[abg].append(social_media)\n",
    "    abg_dict[abg].append(biografie)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw MP dictionary\n",
    "with open('abg_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(abg_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# list(abg_dict.values())[733]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Partei</th>\n",
       "      <th>Wahlart</th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>Wahlkreis</th>\n",
       "      <th>Ausschuesse</th>\n",
       "      <th>Soziale Medien</th>\n",
       "      <th>Biografie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abercron, Dr. Michael von</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>Direkt gewählt</td>\n",
       "      <td>Schleswig-Holstein</td>\n",
       "      <td>Wahlkreis 007: Pinneberg</td>\n",
       "      <td>{'Ordentliches Mitglied': ['Ausschuss für Bild...</td>\n",
       "      <td>{'von-abercron.de/': 'http://www.von-abercron....</td>\n",
       "      <td>Geboren am 17. November 1952 in Ehlers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Achelwilm, Doris</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>Gewählt über Landesliste</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>n.a.</td>\n",
       "      <td>{'Ordentliches Mitglied': ['Ausschuss für Fami...</td>\n",
       "      <td>{'doris-achelwilm.de': 'http://www.doris-achel...</td>\n",
       "      <td>Geboren am 30. November 1976 in Thuine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aggelidis, Grigorios</td>\n",
       "      <td>FDP</td>\n",
       "      <td>Gewählt über Landesliste</td>\n",
       "      <td>Niedersachsen</td>\n",
       "      <td>Wahlkreis 043: Hannover-Land I</td>\n",
       "      <td>{'Ordentliches Mitglied': ['Ausschuss für Umwe...</td>\n",
       "      <td>{'grigorios-aggelidis.de': 'http://www.grigori...</td>\n",
       "      <td>Geboren am 19. August 1965 in Hannover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbulut, Gökay</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>Gewählt über Landesliste</td>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>Wahlkreis 275: Mannheim</td>\n",
       "      <td>{'Ordentliches Mitglied': ['Unterausschuss Eur...</td>\n",
       "      <td>{'goekay-akbulut.de': 'https://goekay-akbulut....</td>\n",
       "      <td>Geboren 1982 in Pinarbasi/ Türkei; ledig.Juni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albani, Stephan</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>Gewählt über Landesliste</td>\n",
       "      <td>Niedersachsen</td>\n",
       "      <td>Wahlkreis 027: Oldenburg – Ammerland</td>\n",
       "      <td>{'Obmann': ['Ausschuss für Bildung, Forschung ...</td>\n",
       "      <td>{'stephan-albani.de': 'http://www.stephan-alba...</td>\n",
       "      <td>Geboren am 3. Juni 1968 in Göttingen; verheira...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name     Partei                   Wahlart  \\\n",
       "0  Abercron, Dr. Michael von    CDU/CSU            Direkt gewählt   \n",
       "1           Achelwilm, Doris  Die Linke  Gewählt über Landesliste   \n",
       "2       Aggelidis, Grigorios        FDP  Gewählt über Landesliste   \n",
       "3             Akbulut, Gökay  Die Linke  Gewählt über Landesliste   \n",
       "4            Albani, Stephan    CDU/CSU  Gewählt über Landesliste   \n",
       "\n",
       "           Bundesland                             Wahlkreis  \\\n",
       "0  Schleswig-Holstein              Wahlkreis 007: Pinneberg   \n",
       "1              Bremen                                  n.a.   \n",
       "2       Niedersachsen        Wahlkreis 043: Hannover-Land I   \n",
       "3   Baden-Württemberg               Wahlkreis 275: Mannheim   \n",
       "4       Niedersachsen  Wahlkreis 027: Oldenburg – Ammerland   \n",
       "\n",
       "                                         Ausschuesse  \\\n",
       "0  {'Ordentliches Mitglied': ['Ausschuss für Bild...   \n",
       "1  {'Ordentliches Mitglied': ['Ausschuss für Fami...   \n",
       "2  {'Ordentliches Mitglied': ['Ausschuss für Umwe...   \n",
       "3  {'Ordentliches Mitglied': ['Unterausschuss Eur...   \n",
       "4  {'Obmann': ['Ausschuss für Bildung, Forschung ...   \n",
       "\n",
       "                                      Soziale Medien  \\\n",
       "0  {'von-abercron.de/': 'http://www.von-abercron....   \n",
       "1  {'doris-achelwilm.de': 'http://www.doris-achel...   \n",
       "2  {'grigorios-aggelidis.de': 'http://www.grigori...   \n",
       "3  {'goekay-akbulut.de': 'https://goekay-akbulut....   \n",
       "4  {'stephan-albani.de': 'http://www.stephan-alba...   \n",
       "\n",
       "                                           Biografie  \n",
       "0          Geboren am 17. November 1952 in Ehlers...  \n",
       "1          Geboren am 30. November 1976 in Thuine...  \n",
       "2          Geboren am 19. August 1965 in Hannover...  \n",
       "3  Geboren 1982 in Pinarbasi/ Türkei; ledig.Juni ...  \n",
       "4  Geboren am 3. Juni 1968 in Göttingen; verheira...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert into dataframe, add headers\n",
    "#df = pd.DataFrame(abg_dict).transpose()\n",
    "df = pd.DataFrame.from_dict(abg_dict, orient='index')\n",
    "df.columns = ['Name', 'Partei', 'Wahlart', 'Bundesland', 'Wahlkreis', 'Ausschuesse', 'Soziale Medien', 'Biografie']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Wahlkreis into number and name\n",
    "#df['Wahlkreis-Nr.'] = df['Wahlkreis'].apply(lambda x: int(x.split(':')[0].strip('Wahlkreis').strip('')) if x != \"n.a.\" else \"\")\n",
    "#df['Wahlkreis'] = df['Wahlkreis'].apply(lambda x: x.split(':')[1].strip(' ') if x != \"n.a.\" else \"\")\n",
    "\n",
    "df['Wahlkreis-Nr.'] = df['Wahlkreis'].apply(lambda x: int(x.split(':')[0].strip('Wahlkreis').strip('')) if x not in [\"n.a.\", None] else \"\")\n",
    "df['Wahlkreis'] = df['Wahlkreis'].apply(lambda x: x.split(':')[1].strip(' ') if x not in [\"n.a.\", None] else \"\")\n",
    "\n",
    "df['Ausschuesse'] = df['Ausschuesse'].apply(lambda x: x if x not in [\"n.a.\", None] else \"\")\n",
    "df['Biografie'] = df['Biografie'].apply(lambda x: x if x not in [\"n.a.\", None] else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "columns_titles = ['Name', 'Partei', 'Wahlart', 'Bundesland', 'Wahlkreis', 'Wahlkreis-Nr.', 'Ausschuesse', 'Soziale Medien', 'Biografie']\n",
    "df=df.reindex(columns=columns_titles)\n",
    "df.tail()\n",
    "abg_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving final dataframe\n",
    "with open('abg_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(abg_df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
