++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
NOTES - MEETING MIT MATTHIAS AM 09.10.2020
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

TECHNISCHES ------------------------------------------------------------------------------------------------------------------------------------------------

- Geht rstudio.lrz.de?

- Vorschlag für Zusammenarbeit:
  - Für größere Änderungen, die man tracken möchte (nicht, wenn man ein neues Paper zur Literatur hinzufügt)
  - Arbeit auf Feature Branch
  - Anschließender Pull Request
  - Im PR kurz notieren, was geändert wurde
  - Selber in den Master mergen

- R vs Python?! --> müssen wir entscheiden, ggf. Präferenzen von Christian & Thurner erfragen

GENERELL ---------------------------------------------------------------------------------------------------------------------------------------------------

- Generell: Projekt eher explorativ gedacht
  - Vermutlich, nochmal mit Thurner/Sandra klären!
  - Prädiktionen wären natürlich auch cool, aber Fokus vermutlich eher darauf, was über Sentiments in bestehender Twitter-Landschaft auszusagen

- Wird methodisch herausfordernd --> wird wohl gerade Kern dieses Projekts sein

- Zu Aspects.
  - Aspects vorab definieren (einige schon in Projektvereinbarung)? Oder generieren? --> im Termin klären
  - Interessant wird erstmal, Tweets oder sogar Teile von Tweets dann bestimmten Aspects zuzuordnen
  - Im ersten Schritt versuchen, das Modell der Jungs da drauf laufen zu lassen, evtl. ergibt sich da was über Topic-Verteilung

- Start erstmal mit dictionary-based learning (evtl. da schon paar Begriffe manuell hinzufügen)
- Im Internet mal suchen, was vielleicht schon an Modellen vorhanden ist

- Grundsätzlich werden wir Modelle wohl nur durch eigene Beurteilung evaluieren können (jedenfalls anfangs)

NEXT STEPS -------------------------------------------------------------------------------------------------------------------------------------------------

- Gefühl für die Daten kriegen - bisschen deskriptiv analysieren, paar Tweets einfach anschauen, ...
- Versuchen herauszufinden, ob es reicht, auf Tweet-Ebene zu klassifizieren, oder ob es wirklich aspect-based Satz für Satz sein muss
- Schon mal so was wie n-grams, tf-idf erzeugen?
- Recherchieren, ob schon fertige Modelle rumschwirren
- Topics-Modell der Jungs auf unsere Daten anwenden und schauen, ob da was Sinnvolles rauskommt
- Dictionaries suchen und erste Versuche damit starten (vielleicht auch erstmal ohne Fokus auf eine bestimmte Issue?)

IRGENDWANN MAL ---------------------------------------------------------------------------------------------------------------------------------------------

- Perspektivisch sollten wir den Datensatz der Jungs fortführen
  - Betrifft nicht direkt unser Projekt, wir haben auch leicht andere Spalten
  - Fraglich, wie man das handhabt?
    - Regelmäßiges Update? --> Scheduling?
    - Was passiert, wenn MdB hinzukommen / wegfallen? 
    - Ist die 3200-Tweets-Grenze da problematisch? Bzw. beachten, dass man keine Duplikate erzeugt, indem man Tweets erneut hinzufügt
    - Wohin mit dem Ding? Wird ja immer riesiger
    - Wie lang laufen unsere Twitter-Keys überhaupt?

- Austausch mit NLP-Channel
- Elisabeth und Naiwen machen auch aspect-based SA
