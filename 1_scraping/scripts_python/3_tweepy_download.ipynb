{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping MPs' tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import tweepy_helpers as th\n",
    "import ctypes\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wimme\\\\Documents\\\\1_uni\\\\2_master\\\\consulting\\\\project_II\\\\stat_consulting\\\\1_scraping\\\\toy_data_lisa'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define user path (comment out the irrelevant one) and set working directory\n",
    "\n",
    "my_path = 'C:\\\\Users\\\\wimme\\\\Documents\\\\1_uni\\\\2_master\\\\consulting\\\\project_II\\\\stat_consulting\\\\1_scraping\\\\toy_data_lisa'\n",
    "# my_path = 'Asmiks path'\n",
    "os.chdir(my_path)\n",
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bundestag data\n",
    "\n",
    "with open('abg_twitter_df.pickle', 'rb') as handle:\n",
    "    abg_twitter_df = pickle.load(handle)\n",
    "    \n",
    "# Select name, party and username for each member and store in table called twitter_account\n",
    "\n",
    "names = abg_twitter_df['name_matching']\n",
    "twitter_usernames = abg_twitter_df['twitter']\n",
    "twitter_usernames.rename('username', inplace = True)\n",
    "twitter_account = pd.concat([names, twitter_usernames], axis = 1)\n",
    "\n",
    "# Drop usernames that are nan or empty (i.e. parliamentarians with no account)\n",
    "\n",
    "usr_nan = twitter_account.username.isna()\n",
    "twitter_account = twitter_account[~(usr_nan)]\n",
    "twitter_account.reset_index(drop = True, inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for user doris_achelwilm cannot be downloaded\n",
      "Data for user Manfredbehrens cannot be downloaded\n",
      "Data for user BystronAfD cannot be downloaded\n",
      "Data for user Siegbert_Droese cannot be downloaded\n",
      "Data for user EspendillerM cannot be downloaded\n",
      "Data for user FechnerJohannes cannot be downloaded\n",
      "Data for user UweFe cannot be downloaded\n",
      "Data for user Axel_Fischer cannot be downloaded\n",
      "Data for user friedhoff_afd cannot be downloaded\n",
      "Data for user HPFriedrichCSU cannot be downloaded\n",
      "Data for user manfred_grund cannot be downloaded\n",
      "Data for user FGuentzler cannot be downloaded\n",
      "Data for user ChristianHaase6 cannot be downloaded\n",
      "Data for user frankheinrich cannot be downloaded\n",
      "Data for user GabiHillerOhm cannot be downloaded\n",
      "Data for user HilseMdb cannot be downloaded\n",
      "Data for user fjunge cannot be downloaded\n",
      "Data for user uwe_kamann cannot be downloaded\n",
      "Data for user KirstenKappert cannot be downloaded\n",
      "Data for user AnjaKarliczek cannot be downloaded\n",
      "Data for user AchimKessler cannot be downloaded\n",
      "Data for user VolkmarKlein cannot be downloaded\n",
      "Data for user pascalkober cannot be downloaded\n",
      "Data for user koobmar cannot be downloaded\n",
      "Data for user BabettesChefin cannot be downloaded\n",
      "Data for user guenterkrings cannot be downloaded\n",
      "Data for user UlrichLange cannot be downloaded\n",
      "Data for user Team_GLoetzsch cannot be downloaded\n",
      "Data for user thlutze cannot be downloaded\n",
      "Data for user AMattfeldt cannot be downloaded\n",
      "Data for user SiemtjeMoeller cannot be downloaded\n",
      "Data for user MdBMonstadt cannot be downloaded\n",
      "Data for user Neumann_AfD cannot be downloaded\n",
      "Data for user Ulrich_Oehme cannot be downloaded\n",
      "Data for user WilfriedOellers cannot be downloaded\n",
      "Data for user ttte94 cannot be downloaded\n",
      "Data for user #! cannot be downloaded\n",
      "Data for user paul_podolay cannot be downloaded\n",
      "Data for user ProtschkaStepha cannot be downloaded\n",
      "Data for user martinrabanus cannot be downloaded\n",
      "Data for user ManuelaRottmann cannot be downloaded\n",
      "Data for user SchaeferCDU cannot be downloaded\n",
      "Data for user UdoSchiefner cannot be downloaded\n",
      "Data for user drrobbyschlund cannot be downloaded\n",
      "Data for user swenschulz cannot be downloaded\n",
      "Data for user UweSchummer cannot be downloaded\n",
      "Data for user SpringerRen cannot be downloaded\n",
      "Data for user #! cannot be downloaded\n",
      "Data for user MdBMarkusUhl cannot be downloaded\n",
      "Data for user haraldweinberg cannot be downloaded\n",
      "Data for user PeterWeissMdB cannot be downloaded\n",
      "Data for user Heiko_Wildberg cannot be downloaded\n",
      "Data for user zierke cannot be downloaded\n",
      "Data for user JensZimmermann1 cannot be downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download most recent tweets using tweepy (at most 3200 tweets per user)\n",
    "\n",
    "tweepy_df = pd.DataFrame()\n",
    "\n",
    "for username in twitter_account['username']:\n",
    "    tweepy_df = pd.concat([tweepy_df, th.download_tweets_tweepy(username)])\n",
    "    \n",
    "tweepy_df = twitter_account.merge(tweepy_df, on = 'username')\n",
    "\n",
    "ctypes.windll.user32.MessageBoxW(0, \"Twitter data successfully scraped\", \"Progress Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_matching</th>\n",
       "      <th>username</th>\n",
       "      <th>available</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>quoted_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>retweet_full_text</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>location</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael Abercron</td>\n",
       "      <td>mvabercron</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-09 09:34:10</td>\n",
       "      <td>Der feige Anschlag auf eine Synagoge und die d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>807.0</td>\n",
       "      <td>Pinneberg, Deutschland</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Abercron</td>\n",
       "      <td>mvabercron</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-10-08 17:23:42</td>\n",
       "      <td>Die Weltmeere mit ihrer Artenvielfalt sind mas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>807.0</td>\n",
       "      <td>Pinneberg, Deutschland</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Michael Abercron</td>\n",
       "      <td>mvabercron</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-09-29 20:59:07</td>\n",
       "      <td>RT @TimoKuentzle: @BurtscherHelmut In Deutschl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>@BurtscherHelmut In Deutschland hat @oekotest ...</td>\n",
       "      <td>807.0</td>\n",
       "      <td>Pinneberg, Deutschland</td>\n",
       "      <td>[Glyphosat]</td>\n",
       "      <td>[TimoKuentzle, BurtscherHelmut, oekotest]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Abercron</td>\n",
       "      <td>mvabercron</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-09-14 14:51:36</td>\n",
       "      <td>Ich kann mich den Ausführungen meines Kollegen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>807.0</td>\n",
       "      <td>Pinneberg, Deutschland</td>\n",
       "      <td>[Moria]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Michael Abercron</td>\n",
       "      <td>mvabercron</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-09-09 14:47:42</td>\n",
       "      <td>Es muss schnellstmöglich ein Umdenken in den R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>807.0</td>\n",
       "      <td>Pinneberg, Deutschland</td>\n",
       "      <td>[örR]</td>\n",
       "      <td>[NDRrecherche]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name_matching    username  available          created_at  \\\n",
       "0  Michael Abercron  mvabercron       True 2020-10-09 09:34:10   \n",
       "1  Michael Abercron  mvabercron       True 2020-10-08 17:23:42   \n",
       "2  Michael Abercron  mvabercron       True 2020-09-29 20:59:07   \n",
       "3  Michael Abercron  mvabercron       True 2020-09-14 14:51:36   \n",
       "4  Michael Abercron  mvabercron       True 2020-09-09 14:47:42   \n",
       "\n",
       "                                           full_text quoted_status  \\\n",
       "0  Der feige Anschlag auf eine Synagoge und die d...           NaN   \n",
       "1  Die Weltmeere mit ihrer Artenvielfalt sind mas...           NaN   \n",
       "2  RT @TimoKuentzle: @BurtscherHelmut In Deutschl...           NaN   \n",
       "3  Ich kann mich den Ausführungen meines Kollegen...           NaN   \n",
       "4  Es muss schnellstmöglich ein Umdenken in den R...           NaN   \n",
       "\n",
       "   retweet_count  favorite_count  is_retweet  \\\n",
       "0            0.0             1.0         0.0   \n",
       "1            1.0             6.0         0.0   \n",
       "2           47.0             0.0         1.0   \n",
       "3           33.0           130.0         0.0   \n",
       "4            0.0             2.0         0.0   \n",
       "\n",
       "                                   retweet_full_text  followers_count  \\\n",
       "0                                                               807.0   \n",
       "1                                                               807.0   \n",
       "2  @BurtscherHelmut In Deutschland hat @oekotest ...            807.0   \n",
       "3                                                               807.0   \n",
       "4                                                               807.0   \n",
       "\n",
       "                 location     hashtags  \\\n",
       "0  Pinneberg, Deutschland           []   \n",
       "1  Pinneberg, Deutschland           []   \n",
       "2  Pinneberg, Deutschland  [Glyphosat]   \n",
       "3  Pinneberg, Deutschland      [Moria]   \n",
       "4  Pinneberg, Deutschland        [örR]   \n",
       "\n",
       "                                    mentions  \n",
       "0                                         []  \n",
       "1                                         []  \n",
       "2  [TimoKuentzle, BurtscherHelmut, oekotest]  \n",
       "3                                         []  \n",
       "4                             [NDRrecherche]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweepy_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random subset of tweepy_df to have smaller data to try methods on\n",
    "\n",
    "tweepy_df_subset = tweepy_df.sample(frac = 0.1, replace = False, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "\n",
    "with open('tweepy_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(tweepy_df, handle, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('tweepy_df_subset.pickle', 'wb') as handle:\n",
    "    pickle.dump(tweepy_df_subset, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
