{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Twitter accounts from party websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In case of the AfD party, Twitter accounts are not available on the official party website and must thus be gathered manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd # data wrangling\n",
    "import numpy as np # math operations\n",
    "import math # math operations\n",
    "import os # directories\n",
    "import time # system time\n",
    "import random # random number generation\n",
    "import pickle # data compression\n",
    "import re # regular expressions\n",
    "import unidecode # regular expressions\n",
    "\n",
    "import urllib.request # scraping\n",
    "import requests # scraping\n",
    "from bs4 import BeautifulSoup # scraping\n",
    "import ctypes # interface to C\n",
    "import tweepy # twitter \n",
    "\n",
    "import sys # system limit (preventing infinite running)\n",
    "sys.setrecursionlimit(100000)\n",
    "\n",
    "import selenium # chrome driver\n",
    "from selenium import webdriver # chrome driver\n",
    "import selenium.common.exceptions as selexcept # exception handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access party websites and convert into soups \n",
    "\n",
    "fdp = \"https://www.fdpbt.de/fraktion/abgeordnete\"\n",
    "source_fdp = requests.get(fdp).text\n",
    "soup_fdp = BeautifulSoup(source_fdp, 'html.parser')\n",
    "\n",
    "cdu = \"https://www.cducsu.de/hier-stellt-die-cducsu-bundestagsfraktion-ihre-abgeordneten-vor\"\n",
    "source_cdu = requests.get(cdu).text\n",
    "soup_cdu = BeautifulSoup(source_cdu, 'html.parser')\n",
    "\n",
    "spd = \"https://www.spdfraktion.de/abgeordnete/alle?wp=19&view=list&old=19\"\n",
    "source_spd = requests.get(spd).text\n",
    "soup_spd = BeautifulSoup(source_spd, 'html.parser')\n",
    "\n",
    "gruene = \"https://www.gruene-bundestag.de/abgeordnete\"\n",
    "source_gruene = requests.get(gruene).text\n",
    "soup_gruene = BeautifulSoup(source_gruene, 'html.parser')\n",
    "\n",
    "# For Die Linke, one needs to extract Twitter accounts from each individual MP website\n",
    "\n",
    "linke_base = \"https://www.linksfraktion.de/fraktion/abgeordnete/\"\n",
    "\n",
    "# Website contains bins of MPs, according to last name\n",
    "\n",
    "letters = [['a', 'e'], ['f', 'j'], ['k', 'o'], ['p', 't'], ['u', 'z']] \n",
    "linke_name_bins = []\n",
    "\n",
    "for letter in letters:\n",
    "    extension = f'{letter[0]}-bis-{letter[1]}/' \n",
    "    linke_name_bins.append(linke_base + extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each party, find appropriate parent node in soup\n",
    "\n",
    "all_abg_cdu = soup_cdu.find_all(class_='teaser delegates')\n",
    "\n",
    "all_abg_spd = soup_spd.find_all(class_='views-row')\n",
    "\n",
    "extensions_gruene = soup_gruene.find_all('a', class_=\"abgeordneteTeaser__wrapper\")\n",
    "urlbase_gruene = 'https://www.gruene-bundestag.de'\n",
    "all_abg_gruene = []\n",
    "\n",
    "for a in extensions_gruene:\n",
    "    \n",
    "    extension = a['href']\n",
    "    link = urlbase_gruene + str(extension)\n",
    "    all_abg_gruene.append(link)\n",
    "    \n",
    "all_abg_linke = []\n",
    "\n",
    "for name_bin in linke_name_bins:\n",
    "    \n",
    "    source = requests.get(name_bin).text\n",
    "    soup = BeautifulSoup(source, 'html.parser')\n",
    "    \n",
    "    for abg in soup.find_all('div', attrs={'class': 'col-xs-12 col-sm-12 col-md-6 col-lg-6'}):\n",
    "        extension = abg.find('h2').find('a')['href'].lstrip('/fraktion/abgeordnete/')\n",
    "        all_abg_linke.append(linke_base + extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape accounts from soups \n",
    "\n",
    "twitter_list = []\n",
    "\n",
    "# CDU/CSU\n",
    "\n",
    "for abg in all_abg_cdu:\n",
    "    \n",
    "    twitter = abg.find(class_ = 'twitter')\n",
    "    \n",
    "    twitter_list.append({\n",
    "        'party': \"CDU/CSU\",\n",
    "        'name': abg.find('h2').find('span').text.strip(' '),\n",
    "        'twitter_ext': twitter.find('a', href=True)['href'] if twitter is not None else \"\"\n",
    "    })\n",
    "\n",
    "# Gruene\n",
    "\n",
    "for abg in all_abg_gruene:\n",
    "    \n",
    "    abg_source = requests.get(abg).text\n",
    "    abg_soup = BeautifulSoup(abg_source, 'html.parser')\n",
    "    hrefss = []\n",
    "    twitter = \"\"\n",
    "    \n",
    "    for x in abg_soup.find_all(class_=\"weitereInfoTeaser\"):\n",
    "        \n",
    "        for y in x.find_all('a', href=True):\n",
    "            \n",
    "            z = y['href']\n",
    "            hrefss.append(z)\n",
    "            \n",
    "            for i in hrefss:\n",
    "                \n",
    "                if \"twitter\" not in i:\n",
    "                    continue \n",
    "                else:\n",
    "                    twitter = i\n",
    "                    \n",
    "    twitter_list.append({\n",
    "        'party': \"Bündnis 90/Die Grünen\",\n",
    "        'name': abg_soup.find('h1').text,\n",
    "        'twitter_ext': twitter\n",
    "    })\n",
    "    \n",
    "# Linke\n",
    "\n",
    "for abg in all_abg_linke:\n",
    "    \n",
    "    abg_source = requests.get(abg).text\n",
    "    abg_soup = BeautifulSoup(abg_source, 'html.parser')\n",
    "    twitter = abg_soup.find('a', text=re.compile('Twitter-Profil'))\n",
    "    \n",
    "    twitter_list.append({\n",
    "        'party': \"Die Linke\",\n",
    "        'name': abg_soup.find('h1').text.strip(' '),\n",
    "        'twitter_ext': twitter['href'] if twitter is not None else \"\"\n",
    "    })\n",
    "\n",
    "# SPD\n",
    "\n",
    "for abg in all_abg_spd:\n",
    "    \n",
    "    twitter = abg.find(class_='ico_twitter')\n",
    "    \n",
    "    twitter_list.append({\n",
    "        'party': \"SPD\",\n",
    "        'name': abg.find('h3').find('a').get_text().strip(' '),\n",
    "        'twitter_ext': twitter['href'] if twitter is not None else \"\"\n",
    "    })\n",
    "    \n",
    "# Convert to data frame    \n",
    "    \n",
    "twitter_df = pd.DataFrame(twitter_list)    \n",
    "\n",
    "ctypes.windll.user32.MessageBoxW(0, \"Twitter accounts successfully scraped\", \"Progress Report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>name</th>\n",
       "      <th>twitter_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Luise  Amtsberg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Lisa  Badum</td>\n",
       "      <td>https://twitter.com/badulrichmartha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Annalena  Baerbock</td>\n",
       "      <td>https://twitter.com/ABaerbock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Margarete  Bause</td>\n",
       "      <td>https://twitter.com/MargareteBause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Dr. Danyal  Bayaz</td>\n",
       "      <td>https://twitter.com/derdanyal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   party                 name  \\\n",
       "0  Bündnis 90/Die Grünen      Luise  Amtsberg   \n",
       "1  Bündnis 90/Die Grünen          Lisa  Badum   \n",
       "2  Bündnis 90/Die Grünen   Annalena  Baerbock   \n",
       "3  Bündnis 90/Die Grünen     Margarete  Bause   \n",
       "4  Bündnis 90/Die Grünen    Dr. Danyal  Bayaz   \n",
       "\n",
       "                           twitter_ext  \n",
       "0                                       \n",
       "1  https://twitter.com/badulrichmartha  \n",
       "2        https://twitter.com/ABaerbock  \n",
       "3   https://twitter.com/MargareteBause  \n",
       "4        https://twitter.com/derdanyal  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add list of manually collected account names for AfD\n",
    "\n",
    "afd_df = pd.read_csv('../1_input/afd_twitter_accounts.csv', encoding=\"ISO-8859-1\", delimiter=';')\n",
    "afd_df.columns = ['name', 'party', 'twitter_ext']\n",
    "columns_titles = ['party', 'name', 'twitter_ext']\n",
    "afd_df = afd_df.reindex(columns=columns_titles)\n",
    "\n",
    "twitter_df = twitter_df.append(afd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>party</th>\n",
       "      <th>name</th>\n",
       "      <th>twitter_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Luise  Amtsberg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Lisa  Badum</td>\n",
       "      <td>https://twitter.com/badulrichmartha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Annalena  Baerbock</td>\n",
       "      <td>https://twitter.com/ABaerbock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Margarete  Bause</td>\n",
       "      <td>https://twitter.com/MargareteBause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "      <td>Dr. Danyal  Bayaz</td>\n",
       "      <td>https://twitter.com/derdanyal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>AfD</td>\n",
       "      <td>Prof. Dr. Harald Weyel</td>\n",
       "      <td>h_weyel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>AfD</td>\n",
       "      <td>Wolfgang Wiehle</td>\n",
       "      <td>WolfgangWiehle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>AfD</td>\n",
       "      <td>Dr. Heiko Wildberg</td>\n",
       "      <td>Heiko_Wildberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>AfD</td>\n",
       "      <td>Dr. Christian Wirth</td>\n",
       "      <td>ChrWirthMdB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>AfD</td>\n",
       "      <td>Uwe Witt</td>\n",
       "      <td>Witt_Uwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    party                    name  \\\n",
       "0   Bündnis 90/Die Grünen         Luise  Amtsberg   \n",
       "1   Bündnis 90/Die Grünen             Lisa  Badum   \n",
       "2   Bündnis 90/Die Grünen      Annalena  Baerbock   \n",
       "3   Bündnis 90/Die Grünen        Margarete  Bause   \n",
       "4   Bündnis 90/Die Grünen       Dr. Danyal  Bayaz   \n",
       "..                    ...                     ...   \n",
       "84                    AfD  Prof. Dr. Harald Weyel   \n",
       "85                    AfD         Wolfgang Wiehle   \n",
       "86                    AfD      Dr. Heiko Wildberg   \n",
       "87                    AfD     Dr. Christian Wirth   \n",
       "88                    AfD                Uwe Witt   \n",
       "\n",
       "                            twitter_ext  \n",
       "0                                        \n",
       "1   https://twitter.com/badulrichmartha  \n",
       "2         https://twitter.com/ABaerbock  \n",
       "3    https://twitter.com/MargareteBause  \n",
       "4         https://twitter.com/derdanyal  \n",
       "..                                  ...  \n",
       "84                              h_weyel  \n",
       "85                       WolfgangWiehle  \n",
       "86                       Heiko_Wildberg  \n",
       "87                          ChrWirthMdB  \n",
       "88                             Witt_Uwe  \n",
       "\n",
       "[391 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save twitter_df\n",
    "\n",
    "with open('../3_output/twitter_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(twitter_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# load back in\n",
    "\n",
    "with open('../3_output/twitter_df.pickle', 'rb') as handle:\n",
    "    twitter_df=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging accounts data into principal MP data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "\n",
    "with open('../3_output/abg_df.pickle', 'rb') as handle:\n",
    "    abg_df=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare MP names from Twitter df for name-based matching\n",
    "\n",
    "def name_prep(name, twitter=True):\n",
    "    \n",
    "    interim = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", name).strip(' ')\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = re.sub(r'(^\\w{1,6}\\. ?)', r'', interim)\n",
    "    interim = unidecode.unidecode(interim).strip(' ')\n",
    "    interim = re.sub(' +', ' ', interim)\n",
    "    \n",
    "    if twitter:\n",
    "    \n",
    "        if len(interim.split()) > 2:\n",
    "\n",
    "            if interim.split()[0].endswith(('.', 'med', 'forest')):\n",
    "                first_name = interim.split()[1]\n",
    "            else:\n",
    "                first_name = interim.split()[0]   \n",
    "\n",
    "            last_name = interim.split()[-1]\n",
    "            return (first_name + ' ' + last_name)\n",
    "\n",
    "            if interim.split()[-1] == 'von':\n",
    "                first_name = interim.split()[0:-1]     \n",
    "\n",
    "        else:\n",
    "            return interim\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        if len(interim.split()) > 1:     \n",
    "            return(interim.split()[0])\n",
    "        else:\n",
    "            return interim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare MP names from Twitter df for name-based matching\n",
    "\n",
    "twitter_df['name_matching'] = twitter_df['name'].apply(name_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare MP names from MP df for name-based matching\n",
    "\n",
    "abg_df['name_matching'] = abg_df['first_name'].apply(name_prep, twitter = False) + ' ' + \\\n",
    "abg_df['last_name'].apply(name_prep, twitter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Twitter df and MP df\n",
    "\n",
    "abg_twitter_df = pd.merge(\n",
    "    abg_df, \n",
    "    twitter_df[['name_matching', 'twitter_ext']], \n",
    "    how='left', \n",
    "    left_on='name_matching', \n",
    "    right_on='name_matching'\n",
    ")\n",
    "\n",
    "abg_twitter_df['twitter'] = np.where(\n",
    "    abg_twitter_df['twitter'] != '', \n",
    "    abg_twitter_df['twitter'], \n",
    "    np.nan\n",
    ")\n",
    "\n",
    "abg_twitter_df['twitter_ext'] = np.where(\n",
    "    abg_twitter_df['twitter_ext'] != '', \n",
    "    abg_twitter_df['twitter_ext'], \n",
    "    np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute account name from Bundestag website where necessary and available\n",
    "\n",
    "abg_twitter_df['twitter'] = np.where(\n",
    "    abg_twitter_df['twitter_ext'].notnull(), \n",
    "    abg_twitter_df['twitter_ext'], \n",
    "    abg_twitter_df['twitter'])\n",
    "\n",
    "abg_twitter_df = abg_twitter_df.drop('twitter_ext', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Twitter URL to Twitter username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to username (helper function)\n",
    "\n",
    "def get_username(url):\n",
    "    \n",
    "    if url.startswith('http'):\n",
    "        return(url.split('/')[3].split('?')[0])\n",
    "    \n",
    "    else:\n",
    "        return(url.split('?')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to username\n",
    "\n",
    "mask = abg_twitter_df['twitter'].notnull()\n",
    "abg_twitter_df['twitter'] = abg_twitter_df['twitter'][mask].apply(get_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>party</th>\n",
       "      <th>bundesland</th>\n",
       "      <th>wahlkreis_name</th>\n",
       "      <th>wahlkreis_nr</th>\n",
       "      <th>wahlkreis</th>\n",
       "      <th>twitter</th>\n",
       "      <th>name_matching</th>\n",
       "      <th>twitter_ext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abercron</td>\n",
       "      <td>Dr. Michael von</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n  Schleswig-Holstein\\n\\n</td>\n",
       "      <td>Pinneberg</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Wahlkreis 007: Pinneberg</td>\n",
       "      <td>mvabercron</td>\n",
       "      <td>Michael Abercron</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Achelwilm</td>\n",
       "      <td>Doris</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>Bremen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>n.a.</td>\n",
       "      <td>DorisAchelwilm</td>\n",
       "      <td>Doris Achelwilm</td>\n",
       "      <td>https://twitter.com/doris_achelwilm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aggelidis</td>\n",
       "      <td>Grigorios</td>\n",
       "      <td>FDP</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n  Niedersachsen\\n\\n</td>\n",
       "      <td>Hannover-Land I</td>\n",
       "      <td>43</td>\n",
       "      <td>Wahlkreis 043: Hannover-Land I</td>\n",
       "      <td>aggelidis_fdp</td>\n",
       "      <td>Grigorios Aggelidis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Akbulut</td>\n",
       "      <td>Gökay</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n  Baden-Württemberg\\n\\n</td>\n",
       "      <td>Mannheim</td>\n",
       "      <td>275</td>\n",
       "      <td>Wahlkreis 275: Mannheim</td>\n",
       "      <td>akbulutgokay</td>\n",
       "      <td>Gokay Akbulut</td>\n",
       "      <td>https://twitter.com/akbulutgokay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albani</td>\n",
       "      <td>Stephan</td>\n",
       "      <td>CDU/CSU</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n  Niedersachsen\\n\\n</td>\n",
       "      <td>Oldenburg – Ammerland</td>\n",
       "      <td>27</td>\n",
       "      <td>Wahlkreis 027: Oldenburg – Ammerland</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stephan Albani</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_name       first_name      party  \\\n",
       "0   Abercron  Dr. Michael von    CDU/CSU   \n",
       "1  Achelwilm            Doris  Die Linke   \n",
       "2  Aggelidis        Grigorios        FDP   \n",
       "3    Akbulut            Gökay  Die Linke   \n",
       "4     Albani          Stephan    CDU/CSU   \n",
       "\n",
       "                               bundesland         wahlkreis_name wahlkreis_nr  \\\n",
       "0  \\n\\n\\n\\n\\n\\n\\n  Schleswig-Holstein\\n\\n              Pinneberg          7.0   \n",
       "1                                  Bremen                                       \n",
       "2       \\n\\n\\n\\n\\n\\n\\n  Niedersachsen\\n\\n        Hannover-Land I           43   \n",
       "3   \\n\\n\\n\\n\\n\\n\\n  Baden-Württemberg\\n\\n               Mannheim          275   \n",
       "4       \\n\\n\\n\\n\\n\\n\\n  Niedersachsen\\n\\n  Oldenburg – Ammerland           27   \n",
       "\n",
       "                              wahlkreis         twitter        name_matching  \\\n",
       "0              Wahlkreis 007: Pinneberg      mvabercron     Michael Abercron   \n",
       "1                                  n.a.  DorisAchelwilm      Doris Achelwilm   \n",
       "2        Wahlkreis 043: Hannover-Land I   aggelidis_fdp  Grigorios Aggelidis   \n",
       "3               Wahlkreis 275: Mannheim    akbulutgokay        Gokay Akbulut   \n",
       "4  Wahlkreis 027: Oldenburg – Ammerland             NaN       Stephan Albani   \n",
       "\n",
       "                           twitter_ext  \n",
       "0                                  NaN  \n",
       "1  https://twitter.com/doris_achelwilm  \n",
       "2                                  NaN  \n",
       "3     https://twitter.com/akbulutgokay  \n",
       "4                                  NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abg_twitter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "\n",
    "with open('../3_output/abg_twitter_df.pickle', 'wb') as handle:\n",
    "    pickle.dump(abg_twitter_df, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "abg_twitter_df.to_csv('../3_output/abg_twitter_df.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
